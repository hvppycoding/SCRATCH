{
  "metadata": {
    "ðŸš¨ Note": "This log may contain personal information such as the contents of your files or terminal output. Please review the contents carefully before sharing.",
    "requestType": "ChatResponses",
    "model": "oswe-vscode-prime",
    "maxPromptTokens": 199997,
    "maxResponseTokens": 64000,
    "location": 7,
    "otherOptions": {
      "stream": true,
      "store": false
    },
    "reasoning": {
      "effort": "medium",
      "summary": "detailed"
    },
    "intent": null,
    "startTime": "2025-12-15T15:41:00.838Z",
    "endTime": "2025-12-15T15:41:39.327Z",
    "duration": "38489ms",
    "ourRequestId": "eda967ce-9b31-42fe-9289-3ce1054602f3",
    "requestId": "eda967ce-9b31-42fe-9289-3ce1054602f3",
    "serverRequestId": "eda967ce-9b31-42fe-9289-3ce1054602f3",
    "timeToFirstToken": "5373ms",
    "resolved model": "capi-noe-ptuc-h200-oswe-vscode-prime",
    "usage": {
      "prompt_tokens": 58074,
      "completion_tokens": 4983,
      "total_tokens": 63057,
      "prompt_tokens_details": {
        "cached_tokens": 5504
      },
      "completion_tokens_details": {
        "reasoning_tokens": 2816,
        "accepted_prediction_tokens": 0,
        "rejected_prediction_tokens": 0
      }
    },
    "tools": "["
  },
  "content": "",
  "raw_content": "tools            : [\n    {\n        \"name\": \"apply_patch\",\n        \"description\": \"Edit text files. Do not use this tool to edit Jupyter notebooks. `apply_patch` allows you to execute a diff/patch against a text file, but the format of the diff specification is unique to this task, so pay careful attention to these instructions. To use the `apply_patch` command, you should pass a message of the following structure as \\\"input\\\":\\n\\n*** Begin Patch\\n[YOUR_PATCH]\\n*** End Patch\\n\\nWhere [YOUR_PATCH] is the actual content of your patch, specified in the following V4A diff format.\\n\\n*** [ACTION] File: [/absolute/path/to/file] -> ACTION can be one of Add, Update, or Delete.\\nAn example of a message that you might pass as \\\"input\\\" to this function, in order to apply a patch, is shown below.\\n\\n*** Begin Patch\\n*** Update File: /Users/someone/pygorithm/searching/binary_search.py\\n@@class BaseClass\\n@@    def search():\\n-        pass\\n+        raise NotImplementedError()\\n\\n@@class Subclass\\n@@    def search():\\n-        pass\\n+        raise NotImplementedError()\\n\\n*** End Patch\\nDo not use line numbers in this diff format.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"input\": {\n                    \"type\": \"string\",\n                    \"description\": \"The edit patch to apply.\"\n                },\n                \"explanation\": {\n                    \"type\": \"string\",\n                    \"description\": \"A short description of what the tool call is aiming to achieve.\"\n                }\n            },\n            \"required\": [\n                \"input\",\n                \"explanation\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"create_directory\",\n        \"description\": \"Create a new directory structure in the workspace. Will recursively create all directories in the path, like mkdir -p. You do not need to use this tool before using create_file, that tool will automatically create the needed directories.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"dirPath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The absolute path to the directory to create.\"\n                }\n            },\n            \"required\": [\n                \"dirPath\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"create_file\",\n        \"description\": \"This is a tool for creating a new file in the workspace. The file will be created with the specified content. The directory will be created if it does not already exist. Never use this tool to edit a file that already exists.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The absolute path to the file to create.\"\n                },\n                \"content\": {\n                    \"type\": \"string\",\n                    \"description\": \"The content to write to the file.\"\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"content\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"create_new_jupyter_notebook\",\n        \"description\": \"Generates a new Jupyter Notebook (.ipynb) in VS Code. Jupyter Notebooks are interactive documents commonly used for data exploration, analysis, visualization, and combining code with narrative text. Prefer creating plain Python files or similar unless a user explicitly requests creating a new Jupyter Notebook or already has a Jupyter Notebook opened or exists in the workspace.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to use to generate the jupyter notebook. This should be a clear and concise description of the notebook the user wants to create.\"\n                }\n            },\n            \"required\": [\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"create_new_workspace\",\n        \"description\": \"Get comprehensive setup steps to help the user create complete project structures in a VS Code workspace. This tool is designed for full project initialization and scaffolding, not for creating individual files.\\n\\nWhen to use this tool:\\n- User wants to create a new complete project from scratch\\n- Setting up entire project frameworks (TypeScript projects, React apps, Node.js servers, etc.)\\n- Initializing Model Context Protocol (MCP) servers with full structure\\n- Creating VS Code extensions with proper scaffolding\\n- Setting up Next.js, Vite, or other framework-based projects\\n- User asks for \\\"new project\\\", \\\"create a workspace\\\", \\\"set up a [framework] project\\\"\\n- Need to establish complete development environment with dependencies, config files, and folder structure\\n\\nWhen NOT to use this tool:\\n- Creating single files or small code snippets\\n- Adding individual files to existing projects\\n- Making modifications to existing codebases\\n- User asks to \\\"create a file\\\" or \\\"add a component\\\"\\n- Simple code examples or demonstrations\\n- Debugging or fixing existing code\\n\\nThis tool provides complete project setup including:\\n- Folder structure creation\\n- Package.json and dependency management\\n- Configuration files (tsconfig, eslint, etc.)\\n- Initial boilerplate code\\n- Development environment setup\\n- Build and run instructions\\n\\nUse other file creation tools for individual files within existing projects.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to use to generate the new workspace. This should be a clear and concise description of the workspace the user wants to create.\"\n                }\n            },\n            \"required\": [\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"edit_notebook_file\",\n        \"description\": \"This is a tool for editing an existing Notebook file in the workspace. Generate the \\\"explanation\\\" property first.\\nThe system is very smart and can understand how to apply your edits to the notebooks.\\nWhen updating the content of an existing cell, ensure newCode preserves whitespace and indentation exactly and does NOT include any code markers such as (...existing code...).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"An absolute path to the notebook file to edit, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.\"\n                },\n                \"cellId\": {\n                    \"type\": \"string\",\n                    \"description\": \"Id of the cell that needs to be deleted or edited. Use the value `TOP`, `BOTTOM` when inserting a cell at the top or bottom of the notebook, else provide the id of the cell after which a new cell is to be inserted. Remember, if a cellId is provided and editType=insert, then a cell will be inserted after the cell with the provided cellId.\"\n                },\n                \"newCode\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\",\n                            \"description\": \"The code for the new or existing cell to be edited. Code should not be wrapped within <VSCode.Cell> tags. Do NOT include code markers such as (...existing code...) to indicate existing code.\"\n                        },\n                        {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"string\",\n                                \"description\": \"The code for the new or existing cell to be edited. Code should not be wrapped within <VSCode.Cell> tags\"\n                            }\n                        }\n                    ]\n                },\n                \"language\": {\n                    \"type\": \"string\",\n                    \"description\": \"The language of the cell. `markdown`, `python`, `javascript`, `julia`, etc.\"\n                },\n                \"editType\": {\n                    \"type\": \"string\",\n                    \"enum\": [\n                        \"insert\",\n                        \"delete\",\n                        \"edit\"\n                    ],\n                    \"description\": \"The operation peformed on the cell, whether `insert`, `delete` or `edit`.\\nUse the `editType` field to specify the operation: `insert` to add a new cell, `edit` to modify an existing cell's content, and `delete` to remove a cell.\"\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"editType\",\n                \"cellId\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"fetch_webpage\",\n        \"description\": \"Fetches the main content from a web page. This tool is useful for summarizing or analyzing the content of a webpage. You should use this tool when you think the user is looking for information from a specific webpage.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"urls\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    },\n                    \"description\": \"An array of URLs to fetch content from.\"\n                },\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to search for in the web page's content. This should be a clear and concise description of the content you want to find.\"\n                }\n            },\n            \"required\": [\n                \"urls\",\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"file_search\",\n        \"description\": \"Search for files in the workspace by glob pattern. This only returns the paths of matching files. Use this tool when you know the exact filename pattern of the files you're searching for. Glob patterns match from the root of the workspace folder. Examples:\\n- **/*.{js,ts} to match all js/ts files in the workspace.\\n- src/** to match all files under the top-level src folder.\\n- **/foo/**/*.js to match all js files under any foo folder in the workspace.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"Search for files with names or paths matching this glob pattern.\"\n                },\n                \"maxResults\": {\n                    \"type\": \"number\",\n                    \"description\": \"The maximum number of results to return. Do not use this unless necessary, it can slow things down. By default, only some matches are returned. If you use this and don't see what you're looking for, you can try again with a more specific query or a larger maxResults.\"\n                }\n            },\n            \"required\": [\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"grep_search\",\n        \"description\": \"Do a fast text search in the workspace. Use this tool when you want to search with an exact string or regex. If you are not sure what words will appear in the workspace, prefer using regex patterns with alternation (|) or character classes to search for multiple potential words at once instead of making separate searches. For example, use 'function|method|procedure' to look for all of those words at once. Use includePattern to search within files matching a specific pattern, or in a specific file, using a relative path. Use 'includeIgnoredFiles' to include files normally ignored by .gitignore, other ignore files, and `files.exclude` and `search.exclude` settings. Warning: using this may cause the search to be slower, only set it when you want to search in ignored folders like node_modules or build outputs. Use this tool when you want to see an overview of a particular file, instead of using read_file many times to look for code within a file.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The pattern to search for in files in the workspace. Use regex with alternation (e.g., 'word1|word2|word3') or character classes to find multiple potential words in a single search. Be sure to set the isRegexp property properly to declare whether it's a regex or plain text pattern. Is case-insensitive.\"\n                },\n                \"isRegexp\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether the pattern is a regex.\"\n                },\n                \"includePattern\": {\n                    \"type\": \"string\",\n                    \"description\": \"Search files matching this glob pattern. Will be applied to the relative path of files within the workspace. To search recursively inside a folder, use a proper glob pattern like \\\"src/folder/**\\\". Do not use | in includePattern.\"\n                },\n                \"maxResults\": {\n                    \"type\": \"number\",\n                    \"description\": \"The maximum number of results to return. Do not use this unless necessary, it can slow things down. By default, only some matches are returned. If you use this and don't see what you're looking for, you can try again with a more specific query or a larger maxResults.\"\n                },\n                \"includeIgnoredFiles\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether to include files that would normally be ignored according to .gitignore, other ignore files and `files.exclude` and `search.exclude` settings. Warning: using this may cause the search to be slower. Only set it when you want to search in ignored folders like node_modules or build outputs.\"\n                }\n            },\n            \"required\": [\n                \"query\",\n                \"isRegexp\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_changed_files\",\n        \"description\": \"Get git diffs of current file changes in a git repository. Don't forget that you can use run_in_terminal to run git commands in a terminal as well.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"repositoryPath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The absolute path to the git repository to look for changes in. If not provided, the active git repository will be used.\"\n                },\n                \"sourceControlState\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\",\n                        \"enum\": [\n                            \"staged\",\n                            \"unstaged\",\n                            \"merge-conflicts\"\n                        ]\n                    },\n                    \"description\": \"The kinds of git state to filter by. Allowed values are: 'staged', 'unstaged', and 'merge-conflicts'. If not provided, all states will be included.\"\n                }\n            }\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_errors\",\n        \"description\": \"Get any compile or lint errors in a specific file or across all files. If the user mentions errors or problems in a file, they may be referring to these. Use the tool to see the same errors that the user is seeing. If the user asks you to analyze all errors, or does not specify a file, use this tool to gather errors for all files. Also use this tool after editing a file to validate the change.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePaths\": {\n                    \"description\": \"The absolute paths to the files or folders to check for errors. Omit 'filePaths' when retrieving all errors.\",\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    }\n                }\n            }\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"copilot_getNotebookSummary\",\n        \"description\": \"This is a tool returns the list of the Notebook cells along with the id, cell types, line ranges, language, execution information and output mime types for each cell. This is useful to get Cell Ids when executing a notebook or determine what cells have been executed and what order, or what cells have outputs. If required to read contents of a cell use this to determine the line range of a cells, and then use read_file tool to read a specific line range. Requery this tool if the contents of the notebook change.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb\"\n                }\n            },\n            \"required\": [\n                \"filePath\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_project_setup_info\",\n        \"description\": \"Do not call this tool without first calling the tool to create a workspace. This tool provides a project setup information for a Visual Studio Code workspace based on a project type and programming language.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"projectType\": {\n                    \"type\": \"string\",\n                    \"description\": \"The type of project to create. Supported values are: 'python-script', 'python-project', 'mcp-server', 'model-context-protocol-server', 'vscode-extension', 'next-js', 'vite' and 'other'\"\n                }\n            },\n            \"required\": [\n                \"projectType\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_search_view_results\",\n        \"description\": \"The results from the search view\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_vscode_api\",\n        \"description\": \"Get comprehensive VS Code API documentation and references for extension development. This tool provides authoritative documentation for VS Code's extensive API surface, including proposed APIs, contribution points, and best practices. Use this tool for understanding complex VS Code API interactions.\\n\\nWhen to use this tool:\\n- User asks about specific VS Code APIs, interfaces, or extension capabilities\\n- Need documentation for VS Code extension contribution points (commands, views, settings, etc.)\\n- Questions about proposed APIs and their usage patterns\\n- Understanding VS Code extension lifecycle, activation events, and packaging\\n- Best practices for VS Code extension development architecture\\n- API examples and code patterns for extension features\\n- Troubleshooting extension-specific issues or API limitations\\n\\nWhen NOT to use this tool:\\n- Creating simple standalone files or scripts unrelated to VS Code extensions\\n- General programming questions not specific to VS Code extension development\\n- Questions about using VS Code as an editor (user-facing features)\\n- Non-extension related development tasks\\n- File creation or editing that doesn't involve VS Code extension APIs\\n\\nCRITICAL usage guidelines:\\n1. Always include specific API names, interfaces, or concepts in your query\\n2. Mention the extension feature you're trying to implement\\n3. Include context about proposed vs stable APIs when relevant\\n4. Reference specific contribution points when asking about extension manifest\\n5. Be specific about the VS Code version or API version when known\\n\\nScope: This tool is for EXTENSION DEVELOPMENT ONLY - building tools that extend VS Code itself, not for general file creation or non-extension programming tasks.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to search vscode documentation for. Should contain all relevant context.\"\n                }\n            },\n            \"required\": [\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"github_repo\",\n        \"description\": \"Searches a GitHub repository for relevant source code snippets. Only use this tool if the user is very clearly asking for code snippets from a specific GitHub repository. Do not use this tool for Github repos that the user has open in their workspace.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"repo\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the Github repository to search for code in. Should must be formatted as '<owner>/<repo>'.\"\n                },\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to search for repo. Should contain all relevant context.\"\n                }\n            },\n            \"required\": [\n                \"repo\",\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"install_extension\",\n        \"description\": \"Install an extension in VS Code. Use this tool to install an extension in Visual Studio Code as part of a new workspace creation process only.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ID of the extension to install. This should be in the format <publisher>.<extension>.\"\n                },\n                \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the extension to install. This should be a clear and concise description of the extension.\"\n                }\n            },\n            \"required\": [\n                \"id\",\n                \"name\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"list_code_usages\",\n        \"description\": \"Request to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc. Use this tool when \\n1. Looking for a sample implementation of an interface or class\\n2. Checking how a function is used throughout the codebase.\\n3. Including and updating all usages when changing a function, method, or constructor\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"symbolName\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the symbol, such as a function name, class name, method name, variable name, etc.\"\n                },\n                \"filePaths\": {\n                    \"type\": \"array\",\n                    \"description\": \"One or more file paths which likely contain the definition of the symbol. For instance the file which declares a class or function. This is optional but will speed up the invocation of this tool and improve the quality of its output.\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"symbolName\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"list_dir\",\n        \"description\": \"List the contents of a directory. Result will have the name of the child. If the name ends in /, it's a folder, otherwise a file\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"path\": {\n                    \"type\": \"string\",\n                    \"description\": \"The absolute path to the directory to list.\"\n                }\n            },\n            \"required\": [\n                \"path\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"multi_replace_string_in_file\",\n        \"description\": \"This tool allows you to apply multiple replace_string_in_file operations in a single call, which is more efficient than calling replace_string_in_file multiple times. It takes an array of replacement operations and applies them sequentially. Each replacement operation has the same parameters as replace_string_in_file: filePath, oldString, newString, and explanation. This tool is ideal when you need to make multiple edits across different files or multiple edits in the same file. The tool will provide a summary of successful and failed operations.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"explanation\": {\n                    \"type\": \"string\",\n                    \"description\": \"A brief explanation of what the multi-replace operation will accomplish.\"\n                },\n                \"replacements\": {\n                    \"type\": \"array\",\n                    \"description\": \"An array of replacement operations to apply sequentially.\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"explanation\": {\n                                \"type\": \"string\",\n                                \"description\": \"A brief explanation of this specific replacement operation.\"\n                            },\n                            \"filePath\": {\n                                \"type\": \"string\",\n                                \"description\": \"An absolute path to the file to edit.\"\n                            },\n                            \"oldString\": {\n                                \"type\": \"string\",\n                                \"description\": \"The exact literal text to replace, preferably unescaped. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string is not the exact literal text or does not match exactly, this replacement will fail.\"\n                            },\n                            \"newString\": {\n                                \"type\": \"string\",\n                                \"description\": \"The exact literal text to replace `oldString` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic.\"\n                            }\n                        },\n                        \"required\": [\n                            \"explanation\",\n                            \"filePath\",\n                            \"oldString\",\n                            \"newString\"\n                        ]\n                    },\n                    \"minItems\": 1\n                }\n            },\n            \"required\": [\n                \"explanation\",\n                \"replacements\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"open_simple_browser\",\n        \"description\": \"Preview a website or open a URL in the editor's Simple Browser. Useful for quickly viewing locally hosted websites, demos, or resources without leaving the coding environment.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"url\": {\n                    \"type\": \"string\",\n                    \"description\": \"The website URL to preview or open in the Simple Browser inside the editor. Must be either an http or https URL\"\n                }\n            },\n            \"required\": [\n                \"url\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"read_file\",\n        \"description\": \"Read the contents of a file.\\n\\nYou must specify the line range you're interested in. Line numbers are 1-indexed. If the file contents returned are insufficient for your task, you may call this tool again to retrieve more content. Prefer reading larger ranges over doing many small reads.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"description\": \"The absolute path of the file to read.\",\n                    \"type\": \"string\"\n                },\n                \"startLine\": {\n                    \"type\": \"number\",\n                    \"description\": \"The line number to start reading from, 1-based.\"\n                },\n                \"endLine\": {\n                    \"type\": \"number\",\n                    \"description\": \"The inclusive line number to end reading at, 1-based.\"\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"startLine\",\n                \"endLine\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"read_notebook_cell_output\",\n        \"description\": \"This tool will retrieve the output for a notebook cell from its most recent execution or restored from disk. The cell may have output even when it has not been run in the current kernel session. This tool has a higher token limit for output length than the runNotebookCell tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb\"\n                },\n                \"cellId\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ID of the cell for which output should be retrieved.\"\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"cellId\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"replace_string_in_file\",\n        \"description\": \"This is a tool for making edits in an existing file in the workspace. For moving or renaming files, use run in terminal tool with the 'mv' command instead. For larger edits, split them into smaller edits and call the edit tool multiple times to ensure accuracy. Before editing, always ensure you have the context to understand the file's contents and context. To edit a file, provide: 1) filePath (absolute path), 2) oldString (MUST be the exact literal text to replace including all whitespace, indentation, newlines, and surrounding code etc), and 3) newString (MUST be the exact literal text to replace \\\\`oldString\\\\` with (also including all whitespace, indentation, newlines, and surrounding code etc.). Ensure the resulting code is correct and idiomatic.). Each use of this tool replaces exactly ONE occurrence of oldString.\\n\\nCRITICAL for \\\\`oldString\\\\`: Must uniquely identify the single instance to change. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string matches multiple locations, or does not match exactly, the tool will fail. Never use 'Lines 123-456 omitted' from summarized documents or ...existing code... comments in the oldString or newString.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"An absolute path to the file to edit.\"\n                },\n                \"oldString\": {\n                    \"type\": \"string\",\n                    \"description\": \"The exact literal text to replace, preferably unescaped. For single replacements (default), include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. For multiple replacements, specify expected_replacements parameter. If this string is not the exact literal text (i.e. you escaped it) or does not match exactly, the tool will fail.\"\n                },\n                \"newString\": {\n                    \"type\": \"string\",\n                    \"description\": \"The exact literal text to replace `old_string` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic.\"\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"oldString\",\n                \"newString\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"run_notebook_cell\",\n        \"description\": \"This is a tool for running a code cell in a notebook file directly in the notebook editor. The output from the execution will be returned. Code cells should be run as they are added or edited when working through a problem to bring the kernel state up to date and ensure the code executes successfully. Code cells are ready to run and don't require any pre-processing. If asked to run the first cell in a notebook, you should run the first code cell since markdown cells cannot be executed. NOTE: Avoid executing Markdown cells or providing Markdown cell IDs, as Markdown cells cannot be  executed.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb\"\n                },\n                \"reason\": {\n                    \"type\": \"string\",\n                    \"description\": \"An optional explanation of why the cell is being run. This will be shown to the user before the tool is run and is not necessary if it's self-explanatory.\"\n                },\n                \"cellId\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ID for the code cell to execute. Avoid providing markdown cell IDs as nothing will be executed.\"\n                },\n                \"continueOnError\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether or not execution should continue for remaining cells if an error is encountered. Default to false unless instructed otherwise.\"\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"cellId\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"run_vscode_command\",\n        \"description\": \"Run a command in VS Code. Use this tool to run a command in Visual Studio Code as part of a new workspace creation process only.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"commandId\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ID of the command to execute. This should be in the format <command>.\"\n                },\n                \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the command to execute. This should be a clear and concise description of the command.\"\n                },\n                \"args\": {\n                    \"type\": \"array\",\n                    \"description\": \"The arguments to pass to the command. This should be an array of strings.\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"commandId\",\n                \"name\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"semantic_search\",\n        \"description\": \"Run a natural language search for relevant code or documentation comments from the user's current workspace. Returns relevant code snippets from the user's current workspace if it is large, or the full contents of the workspace if it is small.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The query to search the codebase for. Should contain all relevant context. Should ideally be text that might appear in the codebase, such as function names, variable names, or comments.\"\n                }\n            },\n            \"required\": [\n                \"query\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"test_failure\",\n        \"description\": \"Includes test failure information in the prompt.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"vscode_searchExtensions_internal\",\n        \"description\": \"This is a tool for browsing Visual Studio Code Extensions Marketplace. It allows the model to search for extensions and retrieve detailed information about them. The model should use this tool whenever it needs to discover extensions or resolve information about known ones. To use the tool, the model has to provide the category of the extensions, relevant search keywords, or known extension IDs. Note that search results may include false positives, so reviewing and filtering is recommended.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"category\": {\n                    \"type\": \"string\",\n                    \"description\": \"The category of extensions to search for\",\n                    \"enum\": [\n                        \"AI\",\n                        \"Azure\",\n                        \"Chat\",\n                        \"Data Science\",\n                        \"Debuggers\",\n                        \"Extension Packs\",\n                        \"Education\",\n                        \"Formatters\",\n                        \"Keymaps\",\n                        \"Language Packs\",\n                        \"Linters\",\n                        \"Machine Learning\",\n                        \"Notebooks\",\n                        \"Programming Languages\",\n                        \"SCM Providers\",\n                        \"Snippets\",\n                        \"Testing\",\n                        \"Themes\",\n                        \"Visualization\",\n                        \"Other\"\n                    ]\n                },\n                \"keywords\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    },\n                    \"description\": \"The keywords to search for\"\n                },\n                \"ids\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    },\n                    \"description\": \"The ids of the extensions to search for\"\n                }\n            }\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"create_and_run_task\",\n        \"description\": \"Creates and runs a build, run, or custom task for the workspace by generating or adding to a tasks.json file based on the project structure (such as package.json or README.md). If the user asks to build, run, launch and they have no tasks.json file, use this tool. If they ask to create or add a task, use this tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"workspaceFolder\": {\n                    \"type\": \"string\",\n                    \"description\": \"The absolute path of the workspace folder where the tasks.json file will be created.\"\n                },\n                \"task\": {\n                    \"type\": \"object\",\n                    \"description\": \"The task to add to the new tasks.json file.\",\n                    \"properties\": {\n                        \"label\": {\n                            \"type\": \"string\",\n                            \"description\": \"The label of the task.\"\n                        },\n                        \"type\": {\n                            \"type\": \"string\",\n                            \"description\": \"The type of the task. The only supported value is 'shell'.\",\n                            \"enum\": [\n                                \"shell\"\n                            ]\n                        },\n                        \"command\": {\n                            \"type\": \"string\",\n                            \"description\": \"The shell command to run for the task. Use this to specify commands for building or running the application.\"\n                        },\n                        \"args\": {\n                            \"type\": \"array\",\n                            \"description\": \"The arguments to pass to the command.\",\n                            \"items\": {\n                                \"type\": \"string\"\n                            }\n                        },\n                        \"isBackground\": {\n                            \"type\": \"boolean\",\n                            \"description\": \"Whether the task runs in the background without blocking the UI or other tasks. Set to true for long-running processes like watch tasks or servers that should continue executing without requiring user attention. When false, the task will block the terminal until completion.\"\n                        },\n                        \"problemMatcher\": {\n                            \"type\": \"array\",\n                            \"description\": \"The problem matcher to use to parse task output for errors and warnings. Can be a predefined matcher like '$tsc' (TypeScript), '$eslint - stylish', '$gcc', etc., or a custom pattern defined in tasks.json. This helps VS Code display errors in the Problems panel and enables quick navigation to error locations.\",\n                            \"items\": {\n                                \"type\": \"string\"\n                            }\n                        },\n                        \"group\": {\n                            \"type\": \"string\",\n                            \"description\": \"The group to which the task belongs.\"\n                        }\n                    },\n                    \"required\": [\n                        \"label\",\n                        \"type\",\n                        \"command\"\n                    ]\n                }\n            },\n            \"required\": [\n                \"task\",\n                \"workspaceFolder\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_task_output\",\n        \"description\": \"Get the output of a task\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": {\n                    \"type\": \"string\",\n                    \"description\": \"The task ID for which to get the output.\"\n                },\n                \"workspaceFolder\": {\n                    \"type\": \"string\",\n                    \"description\": \"The workspace folder path containing the task\"\n                }\n            },\n            \"required\": [\n                \"id\",\n                \"workspaceFolder\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_terminal_output\",\n        \"description\": \"Get the output of a terminal command previously started with run_in_terminal\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"id\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ID of the terminal to check.\"\n                }\n            },\n            \"required\": [\n                \"id\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"manage_todo_list\",\n        \"description\": \"Updates the task plan.\\nProvide an optional explanation and a list of plan items, each with a step and status.\\nAt most one step can be in_progress at a time.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"todoList\": {\n                    \"type\": \"array\",\n                    \"description\": \"Complete array of all todo items (required for write operation, ignored for read). Must include ALL items - both existing and new.\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"id\": {\n                                \"type\": \"number\",\n                                \"description\": \"Unique identifier for the todo. Use sequential numbers starting from 1.\"\n                            },\n                            \"title\": {\n                                \"type\": \"string\",\n                                \"description\": \"Concise action-oriented todo label (3-7 words). Displayed in UI.\"\n                            },\n                            \"status\": {\n                                \"type\": \"string\",\n                                \"enum\": [\n                                    \"not-started\",\n                                    \"in-progress\",\n                                    \"completed\"\n                                ],\n                                \"description\": \"not-started: Not begun | in-progress: Currently working (max 1) | completed: Fully finished with no blockers\"\n                            }\n                        },\n                        \"required\": [\n                            \"id\",\n                            \"title\",\n                            \"status\"\n                        ]\n                    }\n                },\n                \"operation\": {\n                    \"type\": \"string\",\n                    \"enum\": [\n                        \"write\",\n                        \"read\"\n                    ],\n                    \"description\": \"write: Replace entire todo list with new content. read: Retrieve current todo list. ALWAYS provide complete list when writing - partial updates not supported.\"\n                }\n            },\n            \"required\": [\n                \"operation\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"run_in_terminal\",\n        \"description\": \"This tool allows you to execute shell commands in a persistent bash terminal session, preserving environment variables, working directory, and other context across multiple commands.\\n\\nCommand Execution:\\n- Use && to chain simple commands on one line\\n- Prefer pipelines | over temporary files for data flow\\n- Never create a sub-shell (eg. bash -c \\\"command\\\") unless explicitly asked\\n\\nDirectory Management:\\n- Must use absolute paths to avoid navigation issues\\n- Use $PWD for current directory references\\n- Consider using pushd/popd for directory stack management\\n- Supports directory shortcuts like ~ and -\\n\\nProgram Execution:\\n- Supports Python, Node.js, and other executables\\n- Install packages via package managers (brew, apt, etc.)\\n- Use which or command -v to verify command availability\\n\\nBackground Processes:\\n- For long-running tasks (e.g., servers), set isBackground=true\\n- Returns a terminal ID for checking status and runtime later\\n\\nOutput Management:\\n- Output is automatically truncated if longer than 60KB to prevent context overflow\\n- Use head, tail, grep, awk to filter and limit output size\\n- For pager commands, disable paging: git --no-pager or add | cat\\n- Use wc -l to count lines before displaying large outputs\\n\\nBest Practices:\\n- Quote variables: \\\"$var\\\" instead of $var to handle spaces\\n- Use find with -exec or xargs for file operations\\n- Be specific with commands to avoid excessive output\\n- Use [[ ]] for conditional tests instead of [ ]\\n- Prefer $() over backticks for command substitution\\n- Use set -e at start of complex commands to exit on errors\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"command\": {\n                    \"type\": \"string\",\n                    \"description\": \"The command to run in the terminal.\"\n                },\n                \"explanation\": {\n                    \"type\": \"string\",\n                    \"description\": \"A one-sentence description of what the command does. This will be shown to the user before the command is run.\"\n                },\n                \"isBackground\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Whether the command starts a background process. If true, the command will run in the background and you will not see the output. If false, the tool call will block on the command finishing, and then you will get the output. Examples of background processes: building in watch mode, starting a server. You can check the output of a background process later on by using get_terminal_output.\"\n                }\n            },\n            \"required\": [\n                \"command\",\n                \"explanation\",\n                \"isBackground\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"run_task\",\n        \"description\": \"Runs a VS Code task.\\n\\n- If you see that an appropriate task exists for building or running code, prefer to use this tool to run the task instead of using the run_in_terminal tool.\\n- Make sure that any appropriate build or watch task is running before trying to run tests or execute code.\\n- If the user asks to run a task, use this tool to do so.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"workspaceFolder\": {\n                    \"type\": \"string\",\n                    \"description\": \"The workspace folder path containing the task\"\n                },\n                \"id\": {\n                    \"type\": \"string\",\n                    \"description\": \"The task ID to run.\"\n                }\n            },\n            \"required\": [\n                \"workspaceFolder\",\n                \"id\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"runSubagent\",\n        \"description\": \"Launch a new agent to handle complex, multi-step tasks autonomously. This tool is good at researching complex questions, searching for code, and executing multi-step tasks. When you are searching for a keyword or file and are not confident that you will find the right match in the first few tries, use this agent to perform the search for you.\\n\\n- Agents do not run async or in the background, you will wait for the agent's result.\\n- When the agent is done, it will return a single message back to you. The result returned by the agent is not visible to the user. To show the user the result, you should send a text message back to the user with a concise summary of the result.\\n- Each agent invocation is stateless. You will not be able to send additional messages to the agent, nor will the agent be able to communicate with you outside of its final report. Therefore, your prompt should contain a highly detailed task description for the agent to perform autonomously and you should specify exactly what information the agent should return back to you in its final and only message to you.\\n- The agent's outputs should generally be trusted\\n- Clearly tell the agent whether you expect it to write code or just to do research (search, file reads, web fetches, etc.), since it is not aware of the user's intent\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"prompt\": {\n                    \"type\": \"string\",\n                    \"description\": \"A detailed description of the task for the agent to perform\"\n                },\n                \"description\": {\n                    \"type\": \"string\",\n                    \"description\": \"A short (3-5 word) description of the task\"\n                }\n            },\n            \"required\": [\n                \"prompt\",\n                \"description\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"terminal_last_command\",\n        \"description\": \"Get the last command run in the active terminal.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"terminal_selection\",\n        \"description\": \"Get the current selection in the active terminal.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"configure_notebook\",\n        \"description\": \"Tool used to configure a Notebook. ALWAYS use this tool before running/executing any Notebook Cells for the first time or before listing/installing packages in Notebooks for the first time. I.e. there is no need to use this tool more than once for the same notebook.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"description\": \"The absolute path of the notebook with the active kernel.\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"filePath\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"notebook_install_packages\",\n        \"description\": \"Install a list of packages on a notebook kernel to be used within that notebook. This tool should be used when working with a jupyter notebook with python code cells. Do not use this tool if not already working with a notebook, or for a language other than python. If the tool configure_notebooks exists, then ensure to call configure_notebooks before using this tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"description\": \"The absolute path of the notebook with the active kernel.\",\n                    \"type\": \"string\"\n                },\n                \"packageList\": {\n                    \"description\": \"A list of packages to install.\",\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"filePath\",\n                \"packageList\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"notebook_list_packages\",\n        \"description\": \"List the installed packages that are currently available in the selected kernel for a notebook editor. This tool should be used when working with a jupyter notebook with python code cells. Do not use this tool if not already working with a notebook, or for a language other than python. If the tool configure_notebooks exists, then ensure to call configure_notebooks before using this tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"filePath\": {\n                    \"description\": \"The absolute path of the notebook with the active kernel.\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"filePath\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"configure_python_environment\",\n        \"description\": \"This tool configures a Python environment in the given workspace. ALWAYS Use this tool to set up the user's chosen environment and ALWAYS call this tool before using any other Python related tools or running any Python command in the terminal.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resourcePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The path to the Python file or workspace for which a Python Environment needs to be configured.\"\n                }\n            },\n            \"required\": []\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_python_environment_details\",\n        \"description\": \"This tool will retrieve the details of the Python Environment for the specified file or workspace. The details returned include the 1. Type of Python Environment (conda, venv, etec), 2. Version of Python, 3. List of all installed Python packages with their versions. ALWAYS call configure_python_environment before using this tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resourcePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The path to the Python file or workspace to get the environment information for.\"\n                }\n            },\n            \"required\": []\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"get_python_executable_details\",\n        \"description\": \"This tool will retrieve the details of the Python Environment for the specified file or workspace. ALWAYS use this tool before executing any Python command in the terminal. This tool returns the details of how to construct the fully qualified path and or command including details such as arguments required to run Python in a terminal. Note: Instead of executing `python --version` or `python -c 'import sys; print(sys.executable)'`, use this tool to get the Python executable path to replace the `python` command. E.g. instead of using `python -c 'import sys; print(sys.executable)'`, use this tool to build the command `conda run -n <env_name> -c 'import sys; print(sys.executable)'`. ALWAYS call configure_python_environment before using this tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resourcePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The path to the Python file or workspace to get the executable information for. If not provided, the current workspace will be used. Where possible pass the path to the file or workspace.\"\n                }\n            },\n            \"required\": []\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"install_python_packages\",\n        \"description\": \"Installs Python packages in the given workspace. Use this tool to install Python packages in the user's chosen Python environment. ALWAYS call configure_python_environment before using this tool.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"packageList\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    },\n                    \"description\": \"The list of Python packages to install.\"\n                },\n                \"resourcePath\": {\n                    \"type\": \"string\",\n                    \"description\": \"The path to the Python file or workspace into which the packages are installed. If not provided, the current workspace will be used. Where possible pass the path to the file or workspace.\"\n                }\n            },\n            \"required\": [\n                \"packageList\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_container_management_tools\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThis group of tools is focused on managing the lifecycle of containers within a containerization platform. The tools allow users to start, stop, restart, or remove containers using their names or IDs, providing essential control over running applications. Additionally, users can run new containers, enabling the deployment of new instances of applications or services as needed. Together, these tools facilitate the dynamic management of containerized environments, allowing for efficient resource utilization and application scalability.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_image_management_tools\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThe tools in this group are designed for managing container images, which are essential for creating and deploying containers. Users can pull new images from repositories or remove existing ones, ensuring that the local environment is up-to-date with the necessary application versions. The ability to inspect images allows users to understand their configurations and dependencies, while tagging images with new identifiers helps in organizing and versioning them effectively. These functionalities are crucial for maintaining a clean and efficient image repository, supporting continuous integration and deployment workflows.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_container_inspection_and_logging_tools\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThis group provides tools for inspecting and monitoring the performance of containers. Users can inspect containers to retrieve detailed information about their configurations, statuses, and resource usage. Additionally, the ability to view logs for specific containers allows for troubleshooting and performance analysis, helping users identify issues and optimize their applications. By combining inspection and logging capabilities, these tools enable developers and system administrators to maintain the health and efficiency of their containerized applications.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_container_inventory_tools\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThe tools in this group focus on inventory management for containers, images, and volumes. Users can list all containers, including those that are stopped, which aids in monitoring resource usage and managing application states. Similarly, listing container images provides visibility into available images, including untagged and orphaned ones, which can help in cleaning up unused resources. Additionally, listing container volumes allows users to manage persistent data storage associated with containers. Together, these tools provide a comprehensive overview of the container ecosystem, facilitating better resource management and operational efficiency.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_copilot_conta_list_networks\",\n        \"description\": \"List container networks\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {}\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_copilot_conta_prune\",\n        \"description\": \"Prune unused container resources\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"pruneTarget\": {\n                    \"type\": \"string\",\n                    \"enum\": [\n                        \"containers\",\n                        \"images\",\n                        \"volumes\",\n                        \"networks\",\n                        \"all\"\n                    ],\n                    \"description\": \"The type of resource to prune\"\n                }\n            },\n            \"required\": [\n                \"pruneTarget\"\n            ],\n            \"additionalProperties\": false,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_add_or_commit\",\n        \"description\": \"Add file contents to the index (git add <pathspec>) OR record changes to the repository (git commit -m <message> [files...]). Use the 'action' parameter to specify which action to perform.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"action\": {\n                    \"description\": \"The action to perform: 'add' or 'commit'\",\n                    \"enum\": [\n                        \"add\",\n                        \"commit\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"directory\": {\n                    \"description\": \"The directory to run git add or commit in\",\n                    \"type\": \"string\"\n                },\n                \"files\": {\n                    \"description\": \"Optional array of files to add or commit. If omitted, all files are added or all staged changes are committed.\",\n                    \"items\": {\n                        \"type\": \"string\"\n                    },\n                    \"type\": \"array\"\n                },\n                \"message\": {\n                    \"description\": \"The commit message (required if action is 'commit')\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\",\n                \"action\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_blame\",\n        \"description\": \"Show what revision and author last modified each line of a file (git blame <file>).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"directory\": {\n                    \"description\": \"The directory to run git blame in\",\n                    \"type\": \"string\"\n                },\n                \"file\": {\n                    \"description\": \"The file to blame\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\",\n                \"file\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_branch\",\n        \"description\": \"List or create branches (git branch).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"action\": {\n                    \"description\": \"Git branch action to be executed\",\n                    \"enum\": [\n                        \"create\",\n                        \"list\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"branch_name\": {\n                    \"description\": \"(Optional) Name of the branch to create or delete\",\n                    \"type\": \"string\"\n                },\n                \"directory\": {\n                    \"description\": \"The directory to run git branch in\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\",\n                \"action\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_checkout\",\n        \"description\": \"Switch branches or restore working tree files (git checkout <branch>).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"branch\": {\n                    \"description\": \"The branch to checkout. This must be a valid branch name without spaces\",\n                    \"type\": \"string\"\n                },\n                \"directory\": {\n                    \"description\": \"The directory to run git checkout in\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\",\n                \"branch\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_log_or_diff\",\n        \"description\": \"Show commit logs or changes between commits (git log --oneline or git diff).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"action\": {\n                    \"description\": \"The action to perform: 'log' for commit logs or 'diff' for changes\",\n                    \"enum\": [\n                        \"log\",\n                        \"diff\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"commit\": {\n                    \"description\": \"Optional commit to compare against HEAD for 'diff', defaults to HEAD\",\n                    \"type\": \"string\"\n                },\n                \"directory\": {\n                    \"description\": \"The directory to run the command in\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\",\n                \"action\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_push\",\n        \"description\": \"Update remote refs along with associated objects (git push).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"directory\": {\n                    \"description\": \"The directory to run git push in\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_stash\",\n        \"description\": \"Stash the changes in a dirty working directory (git stash).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"directory\": {\n                    \"description\": \"The directory to run git stash in\",\n                    \"type\": \"string\"\n                },\n                \"name\": {\n                    \"description\": \"Optional name for the stash (used as the stash message)\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_status\",\n        \"description\": \"Show the working tree status (git status).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"directory\": {\n                    \"description\": \"The directory to run git status in\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_git_worktree\",\n        \"description\": \"List or add git worktrees (git worktree <action>).\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"action\": {\n                    \"description\": \"Git worktree action to be executed\",\n                    \"enum\": [\n                        \"list\",\n                        \"add\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"branch\": {\n                    \"description\": \"(Optional) Existing branch for the new worktree (used for add)\",\n                    \"type\": \"string\"\n                },\n                \"directory\": {\n                    \"description\": \"The directory to run git worktree in\",\n                    \"type\": \"string\"\n                },\n                \"path\": {\n                    \"description\": \"(Optional) Path for the worktree (required for add)\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"directory\",\n                \"action\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_gitkraken_workspace_list\",\n        \"description\": \" Lists all Gitkraken workspaces\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {}\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_issues_add_comment\",\n        \"description\": \"Add a comment to an issue\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_organization\": {\n                    \"description\": \"Optionally set the Azure DevOps organization name. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"comment\": {\n                    \"description\": \"The text content of the comment\",\n                    \"type\": \"string\"\n                },\n                \"issue_id\": {\n                    \"description\": \"The ID of the issue to comment on\",\n                    \"type\": \"string\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the issue provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"jira\",\n                        \"azure\",\n                        \"linear\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Repository name. This is required for GitHub and GitLab\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Organization name. This is required for GitHub and GitLab\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"provider\",\n                \"issue_id\",\n                \"comment\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_issues_assigned_to_me\",\n        \"description\": \"Fetch issues assigned to the user\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_organization\": {\n                    \"description\": \"Optionally set the Azure DevOps organization name. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"page\": {\n                    \"description\": \"Optional parameter to specify the page number, defaults to 1\",\n                    \"type\": \"number\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the issue provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"jira\",\n                        \"azure\",\n                        \"linear\"\n                    ],\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_issues_get_detail\",\n        \"description\": \"Retrieve detailed information about a specific issue by its unique ID\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_organization\": {\n                    \"description\": \"Optionally set the Azure DevOps organization name. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"issue_id\": {\n                    \"description\": \"The ID of the issue to retrieve\",\n                    \"type\": \"string\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the issue provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"jira\",\n                        \"azure\",\n                        \"linear\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Repository name. This is required for GitHub and GitLab\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Organization name. This is required for GitHub and GitLab\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"provider\",\n                \"issue_id\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_pull_request_assigned_to_me\",\n        \"description\": \"Search pull requests where you are the assignee, author, or reviewer\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name of the pull request. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"is_closed\": {\n                    \"description\": \"Set to true if you want to search for closed pull requests\",\n                    \"type\": \"boolean\"\n                },\n                \"page\": {\n                    \"description\": \"Optional parameter to specify the page number, defaults to 1\",\n                    \"type\": \"number\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the git provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"bitbucket\",\n                        \"azure\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Set the repository name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Set the organization name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_pull_request_create\",\n        \"description\": \"Create a new pull request\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name of the pull request. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"body\": {\n                    \"description\": \"The body/description of the pull request\",\n                    \"type\": \"string\"\n                },\n                \"is_draft\": {\n                    \"description\": \"Create as draft pull request\",\n                    \"type\": \"boolean\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the git provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"bitbucket\",\n                        \"azure\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Set the repository name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Set the organization name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                },\n                \"source_branch\": {\n                    \"description\": \"Source branch from which the pull request will be created\",\n                    \"type\": \"string\"\n                },\n                \"target_branch\": {\n                    \"description\": \"Target branch where the pull request will be merged\",\n                    \"type\": \"string\"\n                },\n                \"title\": {\n                    \"description\": \"The title of the pull request\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"repository_name\",\n                \"repository_organization\",\n                \"title\",\n                \"source_branch\",\n                \"target_branch\",\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_pull_request_create_review\",\n        \"description\": \"Create a review for a pull request\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"approve\": {\n                    \"description\": \"Set to true if you want to approve the pull request\",\n                    \"type\": \"boolean\"\n                },\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name of the pull request. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the git provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"bitbucket\",\n                        \"azure\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"pull_request_id\": {\n                    \"description\": \"ID of the pull request to create the review for\",\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Set the repository name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Set the organization name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                },\n                \"review\": {\n                    \"description\": \"Comment to add to the pull request review\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"repository_name\",\n                \"repository_organization\",\n                \"pull_request_id\",\n                \"review\",\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_pull_request_get_comments\",\n        \"description\": \"Get all the comments in a pull requests\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name of the pull request. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the git provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"bitbucket\",\n                        \"azure\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"pull_request_id\": {\n                    \"description\": \"ID of the pull request to add the comment to\",\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Set the repository name of the pull request\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Set the organization name of the pull request\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"repository_name\",\n                \"repository_organization\",\n                \"pull_request_id\",\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_pull_request_get_detail\",\n        \"description\": \"Get an specific pull request\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name of the pull request. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the git provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"bitbucket\",\n                        \"azure\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"pull_request_files\": {\n                    \"description\": \"Set to true if you want to retrieve the files changed in the pull request. Not supported by Azure DevOps.\",\n                    \"type\": \"boolean\"\n                },\n                \"pull_request_id\": {\n                    \"description\": \"ID of the pull request to retrieve\",\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Set the repository name of the pull request\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Set the organization name of the pull request\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"pull_request_id\",\n                \"repository_name\",\n                \"repository_organization\",\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_gitkraken_repository_get_file_content\",\n        \"description\": \"Get file content from a repository\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"azure_project\": {\n                    \"description\": \"Optionally set the Azure DevOps project name of the pull request. Required for Azure DevOps\",\n                    \"type\": \"string\"\n                },\n                \"file_path\": {\n                    \"description\": \"File path to retrieve from the repository\",\n                    \"type\": \"string\"\n                },\n                \"provider\": {\n                    \"description\": \"Specify the git provider\",\n                    \"enum\": [\n                        \"github\",\n                        \"gitlab\",\n                        \"bitbucket\",\n                        \"azure\"\n                    ],\n                    \"type\": \"string\"\n                },\n                \"ref\": {\n                    \"description\": \"Set the branch, tag, or commit SHA to retrieve the file from\",\n                    \"type\": \"string\"\n                },\n                \"repository_name\": {\n                    \"description\": \"Set the repository name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                },\n                \"repository_organization\": {\n                    \"description\": \"Set the organization name of the pull request. Required for Azure DevOps and Bitbucket\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"repository_name\",\n                \"repository_organization\",\n                \"ref\",\n                \"file_path\",\n                \"provider\"\n            ]\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_python_code_validation_and_execution\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThis group of tools focuses on validating and executing Python code snippets within a workspace environment. The 'Check Python file for syntax errors' tool allows users to identify syntax issues in Python files, providing detailed error messages that include line numbers and error types. This is particularly useful for debugging and validating code before execution. The 'Execute Python code snippets directly in the workspace environment' tool enables users to run Python code snippets seamlessly, avoiding common issues associated with terminal execution, such as shell escaping. It provides clean output and is ideal for quick testing and validation of code. Additionally, the 'Validate Python code snippets for syntax errors without saving to file' tool allows for quick checks of code snippets, making it easier to validate generated or user-provided code before running it. Together, these tools streamline the process of writing, testing, and debugging Python code in a cohesive workspace setting.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_python_import_analysis_tools\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThis group is dedicated to analyzing and managing Python imports within a workspace. The 'Analyze imports across workspace user files' tool helps users identify all top-level modules that are imported in their project, including both resolved and unresolved imports. This is essential for understanding project dependencies and identifying any missing packages. The 'Get available top-level modules from installed Python packages in environment' tool complements this by providing a list of all modules that can be imported from the installed packages, allowing users to verify the availability of necessary libraries. Together, these tools facilitate a comprehensive understanding of import patterns and dependencies, enabling users to manage their Python projects more effectively.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_python_environment_management\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThis group of tools is focused on managing Python environments within a workspace. The 'Get Python environment information for workspace' tool provides users with insights into the current active Python environment and all available environments, which is crucial for troubleshooting environment-related issues. The 'Get current Python analysis settings and configuration for a workspace' tool allows users to review their Python analysis settings, helping to diagnose any configuration problems that may arise. Additionally, the 'Switch active Python environment for workspace' tool enables users to easily change their active Python environment, whether switching between different Python installations or virtual environments. Together, these tools empower users to effectively manage their Python environments, ensuring that they can work with the correct settings and dependencies for their projects.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"activate_workspace_structure_and_file_management\",\n        \"description\": \"Call this tool when you need access to a new category of tools. The category of tools is described as follows:\\n\\nThis group provides tools for understanding and managing the structure of a Python workspace. The 'Get workspace root directories' tool allows users to retrieve the root directories of their workspace, which is essential for navigating and organizing project files. The 'Get list of all user Python files in workspace' tool complements this by providing a comprehensive list of all user-created Python files, excluding library and dependency files. This tool respects user-defined settings for file inclusion and exclusion, making it easier to analyze and operate on relevant code. Together, these tools enhance users' ability to navigate their workspace, manage their files effectively, and gain insights into their project structure, ultimately leading to a more organized and efficient development process.\\n\\nBe sure to call this tool if you need a capability related to the above.\",\n        \"parameters\": {},\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_pylance_mcp_s_pylanceDocuments\",\n        \"description\": \"Search Pylance documentation for Python language server help, configuration guidance, feature explanations, and troubleshooting. Returns comprehensive answers about Pylance settings, capabilities, and usage. Use when users ask: How to configure Pylance? What features are available? How to fix Pylance issues?\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"search\": {\n                    \"type\": \"string\",\n                    \"description\": \"Detailed question in natural language. Think of it as a prompt for an LLM. Do not use keyword search terms.\"\n                }\n            },\n            \"required\": [\n                \"search\"\n            ],\n            \"additionalProperties\": false,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_pylance_mcp_s_pylanceInvokeRefactoring\",\n        \"description\": \"Apply automated code refactoring to Python files. Returns refactored content (does not modify original file) unless mode is \\\"update\\\". Use for: extracting functions, organizing imports, improving code structure, applying refactoring patterns.  Optional \\\"mode\\\" parameter: \\\"update\\\" updates the file, \\\"edits\\\" returns a WorkspaceEdit, \\\"string\\\" returns updated content as string. If mode is not specified, \\\"update\\\" will be used as the default. The \\\"edits\\\" mode is helpful for determining if a file needs changes (for example, to remove unused imports or fix import formatting) without making any modifications; if no changes are needed, the result will be either an empty WorkspaceEdit or a message indicating that no text edits were found. Available refactorings: source.unusedImports: - Removes all unused import statements from a Python file. Use when imports are imported but never referenced in the code. Requires fileUri parameter pointing to a Python file with unused imports.\\nsource.convertImportFormat: - Converts import statements between absolute and relative formats according to python.analysis.importFormat setting. Use when import format consistency is needed. Requires fileUri parameter pointing to a Python file with imports to convert.\\nsource.convertImportStar: - Converts all wildcard imports (from module import *) to explicit imports listing all imported symbols. Use when explicit imports are preferred for better code clarity and IDE support. Requires fileUri parameter pointing to a Python file with wildcard imports.\\nsource.addTypeAnnotation: - Adds type annotations to all variables and functions in a Python file that can be inferred from their usage. Use when type hints are needed for better type checking and code clarity. Requires fileUri parameter pointing to a Python file with unannotated variables or functions.\\nsource.fixAll.pylance: - Applies all available automatic code fixes from python.analysis.fixAll setting. Use when multiple code issues need to be addressed simultaneously. Requires fileUri parameter pointing to a Python file with fixable issues.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"fileUri\": {\n                    \"type\": \"string\",\n                    \"description\": \"The uri of the file to invoke the refactoring.\"\n                },\n                \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the refactoring to invoke. This must be one of these [source.unusedImports, source.convertImportFormat, source.convertImportStar, source.addTypeAnnotation, source.fixAll.pylance]\"\n                },\n                \"mode\": {\n                    \"type\": \"string\",\n                    \"enum\": [\n                        \"update\",\n                        \"edits\",\n                        \"string\"\n                    ],\n                    \"description\": \"Determines the output mode: \\\"update\\\" updates the file directly, \\\"edits\\\" returns a WorkspaceEdit, \\\"string\\\" returns the updated content as a string. If omitted, \\\"update\\\" will be used as the default. The \\\"edits\\\" mode is especially useful for checking if any changes are needed (such as unused imports or import formatting issues) without modifying the file, as it will return a WorkspaceEdit only if edits are required.\"\n                }\n            },\n            \"required\": [\n                \"fileUri\",\n                \"name\"\n            ],\n            \"additionalProperties\": false,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_copilot_conta_list_containers\",\n        \"description\": \"List containers, including stopped ones\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {}\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_pylance_mcp_s_pylanceImports\",\n        \"description\": \"Analyze imports across workspace user files. Returns all top-level module names imported, including resolved and unresolved imports. Use for: finding missing dependencies, understanding project dependencies, analyzing import patterns.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"workspaceRoot\": {\n                    \"type\": \"string\",\n                    \"description\": \"The root directory uri of the workspace.\"\n                }\n            },\n            \"required\": [\n                \"workspaceRoot\"\n            ],\n            \"additionalProperties\": false,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_pylance_mcp_s_pylanceFileSyntaxErrors\",\n        \"description\": \"Check Python file for syntax errors. Returns detailed error list with line numbers, messages, and error types. Use when: users report syntax problems, validating files before processing, debugging parse errors.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"workspaceRoot\": {\n                    \"type\": \"string\",\n                    \"description\": \"The root directory uri of the workspace.\"\n                },\n                \"fileUri\": {\n                    \"type\": \"string\",\n                    \"description\": \"The uri of the file to check for syntax errors. Must be a user file in the workspace.\"\n                }\n            },\n            \"required\": [\n                \"workspaceRoot\",\n                \"fileUri\"\n            ],\n            \"additionalProperties\": false,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_copilot_conta_list_images\",\n        \"description\": \"List container images, including untagged and orphaned ones\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {}\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_pylance_mcp_s_pylanceWorkspaceRoots\",\n        \"description\": \"Get workspace root directories. Returns workspace root for specific file or all workspace roots if no file provided. Use for: understanding workspace structure, getting paths for other operations.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"fileUri\": {\n                    \"type\": \"string\",\n                    \"description\": \"The uri of the file to check its workspace\"\n                }\n            },\n            \"additionalProperties\": false,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\"\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    },\n    {\n        \"name\": \"mcp_copilot_conta_list_volumes\",\n        \"description\": \"List container volumes\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {}\n        },\n        \"type\": \"function\",\n        \"strict\": false\n    }\n]\nRequest Messages\nSystem\nYou are an expert AI programming assistant, working with a user in the VS Code editor.\nYour name is GitHub Copilot. When asked about the model you are using, state that you are using Raptor mini (Preview).\nFollow Microsoft content policies.\nAvoid content that violates copyrights.\nIf you are asked to generate content that is harmful, hateful, racist, sexist, lewd, or violent, only respond with \"Sorry, I can't assist with that.\"\n<coding_agent_instructions>\nYou are a coding agent running in VS Code. You are expected to be precise, safe, and helpful.\nYour capabilities:\n- Receive user prompts and other context provided by the workspace, such as files in the environment.\n- Communicate with the user by streaming thinking & responses, and by making & updating plans.\n- Execute a wide range of development tasks including file operations, code analysis, testing, workspace management, and external integrations.\n\n</coding_agent_instructions>\n<personality>\nYour default personality and tone is concise, direct, and friendly. You communicate efficiently, always keeping the user clearly informed about ongoing actions without unnecessary detail. You always prioritize actionable guidance, clearly stating assumptions, environment prerequisites, and next steps. Unless explicitly asked, you avoid excessively verbose explanations about your work.\n\n</personality>\n<tool_preambles>\nBefore making tool calls, send a brief preamble to the user explaining what you're about to do. When sending preamble messages, follow these principles:\n- Logically group related actions: if you're about to run several related commands, describe them together in one preamble rather than sending a separate note for each.\n- Keep it concise: be no more than 1-2 sentences (8-12 words for quick updates).\n- Build on prior context: if this is not your first tool call, use the preamble message to connect the dots with what's been done so far and create a sense of momentum and clarity for the user to understand your next actions.\n- Keep your tone light, friendly and curious: add small touches of personality in preambles to feel collaborative and engaging.\nExamples of good preambles:\n- \"I've explored the repo; now checking the API route definitions.\"\n- \"Next, I'll patch the config and update the related tests.\"\n- \"I'm about to scaffold the CLI commands and helper functions.\"\n- \"Config's looking tidy. Next up is patching helpers to keep things in sync.\"\n\nAvoiding preambles when:\n- Avoiding a preamble for every trivial read (e.g., `cat` a single file) unless it's part of a larger grouped action.\n- Jumping straight into tool calls without explaining what's about to happen.\n- Writing overly long or speculative preambles â€” focus on immediate, tangible next steps.\n\n</tool_preambles>\n<planning>\nYou have access to an `manage_todo_list` tool which tracks steps and progress and renders them to the user. Using the tool helps demonstrate that you've understood the task and convey how you're approaching it. Plans can help to make complex, ambiguous, or multi-phase work clearer and more collaborative for the user. A good plan should break the task into meaningful, logically ordered steps that are easy to verify as you go. Note that plans are not for padding out simple work with filler steps or stating the obvious. \nUse a plan when:\n- The task is non-trivial and will require multiple actions over a long time horizon.\n- There are logical phases or dependencies where sequencing matters.\n- The work has ambiguity that benefits from outlining high-level goals.\n- You want intermediate checkpoints for feedback and validation.\n- When the user asked you to do more than one thing in a single prompt\n- The user has asked you to use the plan tool (aka \"TODOs\")\n- You generate additional steps while working, and plan to do them before yielding to the user\n\nSkip a plan when:\n- The task is simple and direct.\n- Breaking it down would only produce literal or trivial steps.\n\nPlanning steps are called \"steps\" in the tool, but really they're more like tasks or TODOs. As such they should be very concise descriptions of non-obvious work that an engineer might do like \"Write the API spec\", then \"Update the backend\", then \"Implement the frontend\". On the other hand, it's obvious that you'll usually have to \"Explore the codebase\" or \"Implement the changes\", so those are not worth tracking in your plan.\n\nIt may be the case that you complete all steps in your plan after a single pass of implementation. If this is the case, you can simply mark all the planned steps as completed. The content of your plan should not involve doing anything that you aren't capable of doing (i.e. don't try to test things that you can't test). Do not use plans for simple or single-step queries that you can just do or answer immediately.\n\n### Examples\n\n**High-quality plans**\n\nExample 1:\n\n1. Add CLI entry with file args\n2. Parse Markdown via CommonMark library\n3. Apply semantic HTML template\n4. Handle code blocks, images, links\n5. Add error handling for invalid files\n\nExample 2:\n\n1. Define CSS variables for colors\n2. Add toggle with localStorage state\n3. Refactor components to use variables\n4. Verify all views for readability\n5. Add smooth theme-change transition\n\nExample 3:\n\n1. Set up Node.js + WebSocket server\n2. Add join/leave broadcast events\n3. Implement messaging with timestamps\n4. Add usernames + mention highlighting\n5. Persist messages in lightweight DB\n6. Add typing indicators + unread count\n\n**Low-quality plans**\n\nExample 1:\n\n1. Create CLI tool\n2. Add Markdown parser\n3. Convert to HTML\n\nExample 2:\n\n1. Add dark mode toggle\n2. Save preference\n3. Make styles look good\n\nExample 3:\n1. Create single-file HTML game\n2. Run quick sanity check\n3. Summarize usage instructions\n\nIf you need to write a plan, only write high quality plans, not low quality ones.\n\n</planning>\n<task_execution>\nYou are a coding agent. Please keep going until the query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. Autonomously resolve the query to the best of your ability, using the tools available to you, before coming back to the user. Do NOT guess or make up an answer.\n\nYou MUST adhere to the following criteria when solving queries:\n- Working on the repo(s) in the current environment is allowed, even if they are proprietary.\n- Analyzing code for vulnerabilities is allowed.\n- Showing user code and tool call details is allowed.\n- Use the apply_patch tool to edit files (NEVER try `applypatch` or `apply-patch`, only `apply_patch`): {\"command\":[\"apply_patch\",\"*** Begin Patch\\n*** Update File: path/to/file.py\\n@@ def example():\\n-  pass\\n+  return 123\\n*** End Patch\"]}.\n\nIf completing the user's task requires writing or modifying files, your code and final answer should follow these coding guidelines, though user instructions (i.e. copilot-instructions.md) may override these guidelines\n- Fix the problem at the root cause rather than applying surface-level patches, when possible.\n- Avoid unneeded complexity in your solution.\n- Do not attempt to fix unrelated bugs or broken tests. It is not your responsibility to fix them.\n- Update documentation as necessary.\n- Keep changes consistent with the style of the existing codebase. Changes should be minimal and focused on the task.\n- NEVER add copyright or license headers unless specifically requested.\n- Do not add inline comments within code unless explicitly requested.\n- Do not use one-letter variable names unless explicitly requested.\n\n</task_execution>\n<testing>\nIf the codebase has tests or the ability to build or run, you should use them to verify that your work is complete. Generally, your testing philosophy should be to start as specific as possible to the code you changed so that you can catch issues efficiently, then make your way to broader tests as you build confidence.\nOnce you're confident in correctness, use formatting commands to ensure that your code is well formatted. These commands can take time so you should run them on as precise a target as possible.\nFor all of testing, running, building, and formatting, do not attempt to fix unrelated bugs. It is not your responsibility to fix them.\n\n</testing>\n<ambition_vs_precision>\nFor tasks that have no prior context (i.e. the user is starting something brand new), you should feel free to be ambitious and demonstrate creativity with your implementation.\nIf you're operating in an existing codebase, you should make sure you do exactly what the user asks with surgical precision. Treat the surrounding codebase with respect, and don't overstep (i.e. changing filenames or variables unnecessarily). You should balance being sufficiently ambitious and proactive when completing tasks of this nature.\n\n</ambition_vs_precision>\n<progress_updates>\nFor especially longer tasks that you work on (i.e. requiring many tool calls, or a plan with multiple steps), you should provide progress updates back to the user at reasonable intervals. These updates should be structured as a concise sentence or two (no more than 8-10 words long) recapping progress so far in plain language: this update demonstrates your understanding of what needs to be done, progress so far (i.e. files explores, subtasks complete), and where you're going next.\nBefore doing large chunks of work that may incur latency as experienced by the user (i.e. writing a new file), you should send a concise message to the user with an update indicating what you're about to do to ensure they know what you're spending time on. Don't start editing or writing large files before informing the user what you are doing and why.\nThe messages you send before tool calls should describe what is immediately about to be done next in very concise language. If there was previous work done, this preamble message should also include a note about the work done so far to bring the user along.\n\n</progress_updates>\n<applyPatchInstructions>\nTo edit files in the workspace, use the apply_patch tool. If you have issues with it, you should first try to fix your patch and continue using apply_patch. \nPrefer the smallest set of changes needed to satisfy the task. Avoid reformatting unrelated code; preserve existing style and public APIs unless the task requires changes. When practical, complete all edits for a file within a single message.\nThe input for this tool is a string representing the patch to apply, following a special format. For each snippet of code that needs to be changed, repeat the following:\n*** Update File: [file_path]\n[context_before] -> See below for further instructions on context.\n-[old_code] -> Precede each line in the old code with a minus sign.\n+[new_code] -> Precede each line in the new, replacement code with a plus sign.\n[context_after] -> See below for further instructions on context.\n\nFor instructions on [context_before] and [context_after]:\n- By default, show 3 lines of code immediately above and 3 lines immediately below each change. If a change is within 3 lines of a previous change, do NOT duplicate the first change's [context_after] lines in the second change's [context_before] lines.\n- If 3 lines of context is insufficient to uniquely identify the snippet of code within the file, use the @@ operator to indicate the class or function to which the snippet belongs.\n- If a code block is repeated so many times in a class or function such that even a single @@ statement and 3 lines of context cannot uniquely identify the snippet of code, you can use multiple `@@` statements to jump to the right context.\nYou must use the same indentation style as the original code. If the original code uses tabs, you must use tabs. If the original code uses spaces, you must use spaces. Be sure to use a proper UNESCAPED tab character.\n\nSee below for an example of the patch format. If you propose changes to multiple regions in the same file, you should repeat the *** Update File header for each snippet of code to change:\n\n*** Begin Patch\n*** Update File: /Users/someone/pygorithm/searching/binary_search.py\n@@ class BaseClass\n@@   def method():\n[3 lines of pre-context]\n-[old_code]\n+[new_code]\n+[new_code]\n[3 lines of post-context]\n*** End Patch\n\nNEVER print this out to the user, instead call the tool and the edits will be applied and shown to the user.\nFollow best practices when editing files. If a popular external library exists to solve a problem, use it and properly install the package e.g. with \"npm install\" or creating a \"requirements.txt\".\nIf you're building a webapp from scratch, give it a beautiful and modern UI.\nAfter editing a file, any new errors in the file will be in the tool result. Fix the errors if they are relevant to your change or the prompt, and if you can figure out how to fix them, and remember to validate that they were actually fixed. Do not loop more than 3 times attempting to fix errors in the same file. If the third try fails, you should stop and ask the user what to do next.\n\n</applyPatchInstructions>\n<final_answer_formatting>\n## Presenting your work and final message\n\nYour final message should read naturally, like an update from a concise teammate. For casual conversation, brainstorming tasks, or quick questions from the user, respond in a friendly, conversational tone. You should ask questions, suggest ideas, and adapt to the user's style. If you've finished a large amount of work, when describing what you've done to the user, you should follow the final answer formatting guidelines to communicate substantive changes. You don't need to add structured formatting for one-word answers, greetings, or purely conversational exchanges.\nYou can skip heavy formatting for single, simple actions or confirmations. In these cases, respond in plain sentences with any relevant next step or quick option. Reserve multi-section structured responses for results that need grouping or explanation.\nThe user is working on the same computer as you, and has access to your work. As such there's no need to show the full contents of large files you have already written unless the user explicitly asks for them. Similarly, if you've created or modified files using `apply_patch`, there's no need to tell users to \"save the file\" or \"copy the code into a file\"â€”just reference the file path.\nIf there's something that you think you could help with as a logical next step, concisely ask the user if they want you to do so. Good examples of this are running tests, committing changes, or building out the next logical component. If there's something that you couldn't do (even with approval) but that the user might want to do (such as verifying changes by running the app), include those instructions succinctly.\nBrevity is very important as a default. You should be very concise (i.e. no more than 10 lines), but can relax this requirement for tasks where additional detail and comprehensiveness is important for the user's understanding.\n\nFinal answer structure and style guidelines:\nYou are producing plain text that will later be styled by the CLI. Follow these rules exactly. Formatting should make results easy to scan, but not feel mechanical. Use judgment to decide how much structure adds value.\nSection Headers:\n- Use only when they improve clarity â€” they are not mandatory for every answer.\n- Choose descriptive names that fit the content\n- Keep headers short (1-3 words) and in `**Title Case**`. Always start headers with `**` and end with `**`\n- Leave no blank line before the first bullet under a header.\n- Section headers should only be used where they genuinely improve scanability; avoid fragmenting the answer.\n\nBullets:\n- Use `-` followed by a space for every bullet.\n- Bold the keyword, then colon + concise description.\n- Merge related points when possible; avoid a bullet for every trivial detail.\n- Keep bullets to one line unless breaking for clarity is unavoidable.\n- Group into short lists (4-6 bullets) ordered by importance.\n- Use consistent keyword phrasing and formatting across sections.\n\nMonospace:\n- Wrap all commands, env vars, and code identifiers in backticks (`` `...` ``).\n- Apply to inline examples and to bullet keywords if the keyword itself is a literal file/command.\n- Never mix monospace and bold markers; choose one based on whether it's a keyword (`**`).\n- File path and line number formatting rules are defined in the fileLinkification section below.\n\nStructure:\n- Place related bullets together; don't mix unrelated concepts in the same section.\n- Order sections from general â†’ specific â†’ supporting info.\n- For subsections (e.g., \"Binaries\" under \"Rust Workspace\"), introduce with a bolded keyword bullet, then list items under it.\n- Match structure to complexity:\n- Multi-part or detailed results â†’ use clear headers and grouped bullets.\n- Simple results â†’ minimal headers, possibly just a short list or paragraph.\n\nTone:\n- Keep the voice collaborative and natural, like a coding partner handing off work.\n- Be concise and factual â€” no filler or conversational commentary and avoid unnecessary repetition\n- Use present tense and active voice (e.g., \"Runs tests\" not \"This will run tests\").\n- Keep descriptions self-contained; don't refer to \"above\" or \"below\".\n- Use parallel structure in lists for consistency.\n\nDon't:\n- Don't use literal words \"bold\" or \"monospace\" in the content.\n- Don't nest bullets or create deep hierarchies.\n- Don't output ANSI escape codes directly â€” the CLI renderer applies them.\n- Don't cram unrelated keywords into a single bullet; split for clarity.\n- Don't let keyword lists run long â€” wrap or reformat for scanability.\n\nGenerally, ensure your final answers adapt their shape and depth to the request. For example, answers to code explanations should have a precise, structured explanation with code references that answer the question directly. For tasks with a simple implementation, lead with the outcome and supplement only with what's needed for clarity. Larger changes can be presented as a logical walkthrough of your approach, grouping related steps, explaining rationale where it adds value, and highlighting next actions to accelerate the user. Your answers should provide the right level of detail while being easily scannable.\n\nFor casual greetings, acknowledgements, or other one-off conversational messages that are not delivering substantive information or structured results, respond naturally without section headers or bullet formatting.\n\n- Wrap symbol names (classes, methods, variables) in backticks: `MyClass`, `handleClick()`\n- When mentioning files or line numbers, always follow the rules in fileLinkification section below:<fileLinkification>\nWhen mentioning files or line numbers, always convert them to markdown links using workspace-relative paths and 1-based line numbers.\nNO BACKTICKS ANYWHERE:\n- Never wrap file names, paths, or links in backticks.\n- Never use inline-code formatting for any file reference.\n\nREQUIRED FORMATS:\n- File: [path/file.ts](path/file.ts)\n- Line: [file.ts](file.ts#L10)\n- Range: [file.ts](file.ts#L10-L12)\n\nPATH RULES:\n- Without line numbers: Display text must match the target path.\n- With line numbers: Display text can be either the path or descriptive text.\n- Use '/' only; strip drive letters and external folders.\n- Do not use these URI schemes: file://, vscode://\n- Encode spaces only in the target (My File.md â†’ My%20File.md).\n- Non-contiguous lines require separate links. NEVER use comma-separated line references like #L10-L12, L20.\n- Valid formats: [file.ts](file.ts#L10) or [file.ts#L10] only. Invalid: ([file.ts#L10]) or [file.ts](file.ts)#L10\n\nUSAGE EXAMPLES:\n- With path as display: The handler is in [src/handler.ts](src/handler.ts#L10).\n- With descriptive text: The [widget initialization](src/widget.ts#L321) runs on startup.\n- Bullet list: [Init widget](src/widget.ts#L321)\n- File only: See [src/config.ts](src/config.ts) for settings.\n\nFORBIDDEN (NEVER OUTPUT):\n- Inline code: `file.ts`, `src/file.ts`, `L86`.\n- Plain text file names: file.ts, chatService.ts.\n- References without links when mentioning specific file locations.\n- Specific line citations without links (\"Line 86\", \"at line 86\", \"on line 25\").\n- Combining multiple line references in one link: [file.ts#L10-L12, L20](file.ts#L10-L12, L20)\n\n\n</fileLinkification>\nUse KaTeX for math equations in your answers.\nWrap inline math equations in $.\nWrap more complex blocks of math equations in $$.\n\n</final_answer_formatting>\nRespond in the following locale: ko\nUser\n<environment_info>\nThe user's current OS is: Windows\n</environment_info>\n<workspace_info>\nThe following tasks can be executed using the run_task tool if they are not already running:\n<workspaceFolder path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\">\n<task id=\"shell: run make install\">\n{\n\t\"label\": \"run make install\",\n\t\"type\": \"shell\",\n\t\"command\": \"/usr/bin/make -j 8 install\",\n\t\"options\": {\n\t\t\"cwd\": \"/OpenROAD-flow-scripts/tools/OpenROAD/build\"\n\t}\n}\n</task>\n\n</workspaceFolder>\nI am working in a workspace with the following folders:\n- c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI \nI am working in a workspace that has the following structure:\n```\nalembic.ini\nCODEOWNERS\ncomfyui_version.py\nCONTRIBUTING.md\ncuda_malloc.py\nexecution.py\nextra_model_paths.yaml.example\nfolder_paths.py\nhook_breaker_ac10a0.py\nlatent_preview.py\nLICENSE\nmain.py\nnew_updater.py\nnode_helpers.py\nnodes.py\nprotocol.py\npyproject.toml\npytest.ini\nQUANTIZATION.md\nREADME.md\nrequirements.txt\nserver.py\n__pycache__/\nalembic_db/\n\tenv.py\n\tREADME.md\n\tscript.py.mako\napi_server/\n\t__init__.py\n\troutes/\n\tservices/\n\tutils/\napp/\n\t__init__.py\n\tapp_settings.py\n\tcustom_node_manager.py\n\tfrontend_management.py\n\tlogger.py\n\tmodel_manager.py\n\tsubgraph_manager.py\n\tuser_manager.py\n\t__pycache__/\n\tdatabase/\ncomfy/\n\tcheckpoint_pickle.py\n\tcli_args.py\n\tclip_config_bigg.json\n\tclip_model.py\n\tclip_vision_config_g.json\n\tclip_vision_config_h.json\n\tclip_vision_config_vitl_336_llava.json\n\tclip_vision_config_vitl_336.json\n\tclip_vision_config_vitl.json\n\tclip_vision_siglip_384.json\n\tclip_vision_siglip_512.json\n\tclip_vision.py\n\tconds.py\n\tcontext_windows.py\n\tcontrolnet.py\n\tdiffusers_convert.py\n\tdiffusers_load.py\n\tfloat.py\n\tgligen.py\n\thooks.py\n\tlatent_formats.py\n\tlora_convert.py\n\tlora.py\n\tmodel_base.py\n\tmodel_detection.py\n\tmodel_management.py\n\tmodel_patcher.py\n\tmodel_sampling.py\n\tnested_tensor.py\n\tops.py\n\toptions.py\n\tpatcher_extension.py\n\tpixel_space_convert.py\n\tquant_ops.py\n\trmsnorm.py\n\tsample.py\n\tsampler_helpers.py\n\tsamplers.py\n\tsd.py\n\tsd1_clip_config.json\n\tsd1_clip.py\n\tsdxl_clip.py\n\tsupported_models_base.py\n\tsupported_models.py\n\tutils.py\n\t__pycache__/\n\taudio_encoders/\n\tcldm/\n\tcomfy_types/\n\textra_samplers/\n\timage_encoders/\n\tk_diffusion/\n\tldm/\n\tsd1_tokenizer/\n\tt2i_adapter/\n\ttaesd/\n\ttext_encoders/\n\tweight_adapter/\ncomfy_api/\n\tfeature_flags.py\n\tgenerate_api_stubs.py\n\tutil.py\n\tversion_list.py\n\t__pycache__/\n\tinput/\n\tinput_impl/\n\tinternal/\n\tlatest/\n\ttorch_helpers/\n\tutil/\n\tv0_0_1/\n\tv0_0_2/\ncomfy_api_nodes/\n\t__init__.py\n\tcanary.py\n\tmapper_utils.py\n\t...\ncomfy_config/\n\t...\ncomfy_execution/\ncomfy_extras/\ncustom_nodes/\ninput/\nmiddleware/\nmodels/\noutput/\nscript_examples/\ntests/\ntests-unit/\nutils/\n```\nThis is the state of the context at this point in the conversation. The view of the workspace structure may be truncated. You can use tools to collect more context if needed.\n</workspace_info>\n\n\n[copilot_cache_control: { type: 'ephemeral' }]\nUser\n<conversation-summary>\n<analysis>\n[Chronological Review: Initial Request (Optimize startup/Disable nodes) â†’ Implementation (Commented out imports in nodes.py) â†’ Profiling (Added timing logs) â†’ Feature Request (Add `--fast-load` arg to toggle optimization) â†’ Implementation (Added arg, used Mock objects in nodes.py) â†’ Debugging (Fixed Mock inheritance error) â†’ Rejection (User felt Mocking was over-engineering) â†’ Revert (Removed Mock logic from nodes.py)]\n[Intent Mapping: User initially wanted max speed. Then wanted to measure bottlenecks. Then wanted a toggle switch. Finally, user decided the complex Mocking solution for the toggle was unnecessary.]\n[Technical Inventory: ComfyUI, Python `importlib`, `unittest.mock` (attempted), `argparse`, PyTorch hardware checks (IPEX, XPU, etc.), `time.time()` profiling]\n[Code Archaeology: \n- `comfy/cli_args.py`: Added `--fast-load` argument.\n- `comfy/model_management.py`: Modified to skip hardware checks if `--fast-load` is active.\n- `nodes.py`: Was modified to use Mock objects, but just reverted to standard imports with timing logs.]\n[Progress Assessment: Profiling logs are in place. The `--fast-load` feature is currently in a fractured state (exists in args and model_management, but removed from nodes.py).]\n[Context Validation: The system is currently in a state where `nodes.py` loads normally (with logs), but `model_management.py` still respects the `--fast-load` flag. The user wants to simplify.]\n[Recent Commands Analysis: `replace_string_in_file` on `nodes.py` to remove the `if not args.fast_load:` block and the Mock class definition, restoring standard `import torch` etc., with timing logs.]\n</analysis>\n\n<summary>\n1. Conversation Overview:\n- Primary Objectives: \"ComfyUIì˜ ê¸°ë³¸ ë…¸ë“œë“¤ì„ ë¡œë“œí•˜ì§€ ì•Šë„ë¡ ë°”ê¾¸ê³  ì‹¶ì–´... ìµœëŒ€í•œ ë¡œë”© ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•˜ê³  ì‹¶ì–´\" (Disable default nodes and maximize startup speed). Later evolved to \"argumentë¡œ ì˜µì…˜ì„ ì¶”ê°€í•´ì„œ... ìŠ¤í‚µí•  ìˆ˜ ìžˆëŠ”ê±° ìŠ¤í‚µí•˜ê³ \" (Add an argument to toggle optimizations).\n- Session Context: The user wanted to strip down ComfyUI for speed. We aggressively removed imports, then added profiling to measure gains. We attempted to implement a `--fast-load` flag using Mock objects to bypass imports dynamically.\n- User Intent Evolution: The user encountered complexity with Mock objects (inheritance errors) and decided \"ìŒ êµ³ì´ ì´ì •ë„ê¹Œì§€ í•´ì•¼í•˜ë‚˜ ì‹¶ì€ë°\" (I doubt we need to go this far), prompting a revert of the complex Mocking logic.\n\n2. Technical Foundation:\n- ComfyUI: Custom node loading and initialization logic.\n- PyTorch: Heavy dependency being profiled/skipped.\n- Mocking: Attempted to use dummy classes to bypass `import torch` dependencies, but it caused `TypeError: __mro_entries__` with `torch.nn` inheritance.\n- Profiling: `time.time()` logs added around heavy imports and hardware checks.\n\n3. Codebase Status:\n- `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\nodes.py`:\n- Purpose: Main node registration file.\n- Current State: **Reverted.** The complex Mocking logic and `--fast-load` check were removed. It now performs standard imports (`torch`, `safetensors`, `comfy.*`) but includes `logging.info` to measure import times.\n- `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\comfy\\model_management.py`:\n- Purpose: Hardware detection and memory management.\n- Current State: **Modified.** Contains logic to check `if not args.fast_load:` before running heavy hardware checks (IPEX, XPU, etc.).\n- `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\comfy\\cli_args.py`:\n- Purpose: Command line argument parsing.\n- Current State: **Modified.** Contains the `--fast-load` argument definition.\n\n4. Problem Resolution:\n- Issues Encountered: Implementing `--fast-load` in `nodes.py` required Mocking `torch` to avoid `NameError`. This caused issues when ComfyUI code tried to inherit from `torch.nn.Module` (Mock objects need `__mro_entries__`).\n- Solutions Implemented: We fixed the Mock class, but the user decided the complexity was unwarranted.\n- Current State: `nodes.py` is back to normal loading (with logs). The `--fast-load` flag currently only affects `model_management.py`.\n\n5. Progress Tracking:\n- Completed Tasks: Added profiling logs to `nodes.py` and `model_management.py`. Added `--fast-load` arg.\n- Partially Complete Work: The `--fast-load` feature is inconsistent; it is active in `model_management.py` but removed from `nodes.py`.\n- Validated Outcomes: Startup profiling is working and visible in logs.\n\n6. Active Work State:\n- Current Focus: Simplifying the codebase after an over-engineered attempt at dynamic import skipping.\n- Recent Context: The user rejected the Mocking approach in `nodes.py`. I executed a revert on `nodes.py` to restore standard imports.\n- Working Code: `nodes.py` now imports `torch` and other modules directly, logging the time taken.\n- Immediate Context: The system is in a mixed state. `nodes.py` ignores `--fast-load`, while `model_management.py` and `cli_args.py` still support it.\n\n7. Recent Operations:\n- Last Agent Commands: `replace_string_in_file` on `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\nodes.py`.\n- Tool Results Summary: Successfully replaced the Mocking logic block with standard imports wrapped in timing logs.\n- Pre-Summary State: The agent had just finished reverting `nodes.py` to a cleaner state.\n- Operation Context: To align with the user's request \"I doubt we need to go this far,\" removing the complex workaround.\n\n8. Continuation Plan:\n- [Pending Task 1]: Clean up `comfy/model_management.py` if the user wants to fully abandon `--fast-load` or keep it only for hardware checks.\n- [Pending Task 2]: Decide whether to keep or remove the `--fast-load` argument in `cli_args.py`.\n- [Priority Information]: The codebase is currently inconsistent regarding the `--fast-load` flag.\n- [Next Action]: Ask the user if they want to keep `--fast-load` just for `model_management.py` (hardware checks) or remove it entirely.\n\n</summary>\n</conversation-summary>\n\nAssistant\n\nðŸ› ï¸ read_file (call_MHxPU1RvVjEwSVZyNkI3aTFrazk) {\n  \"endLine\": 2150,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\",\n  \"startLine\": 2100\n}\nTool\nðŸ› ï¸ call_MHxPU1RvVjEwSVZyNkI3aTFrazk\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\nodes.py`. Lines 2100 to 2150 (2448 lines total): \n```python\n\nif args.fast_load:\n    NODE_CLASS_MAPPINGS = {}\n    NODE_DISPLAY_NAME_MAPPINGS = {}\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\ndef get_module_name(module_path: str) -> str:\n    \"\"\"\n    Returns the module name based on the given module path.\n    Examples:\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.disabled\") -> \"custom_nodes\n    Args:\n        module_path (str): The path of the module.\n    Returns:\n        str: The module name.\n    \"\"\"\n    base_path = os.path.basename(module_path)\n    if os.path.isfile(module_path):\n        base_path = os.path.splitext(base_path)[0]\n    return base_path\n\n\nasync def load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    module_name = get_module_name(module_path)\n    if os.path.isfile(module_path):\n        sp = os.path.splitext(module_path)\n        module_name = sp[0]\n        sys_module_name = module_name\n    elif os.path.isdir(module_path):\n        sys_module_name = module_path.replace(\".\", \"_x_\")\n\n    try:\n        logging.debug(\"Trying to load custom node {}\".format(module_path))\n        if os.path.isfile(module_path):\n            module_spec = importlib.util.spec_from_file_location(sys_module_name, module_path)\n            module_dir = os.path.split(module_path)[0]\n        else:\n            module_spec = importlib.util.spec_from_file_location(sys_module_name, os.path.join(module_path, \"__init__.py\"))\n            module_dir = module_path\n\n```\nAssistant\n\nðŸ› ï¸ read_file (call_MHxrcE1FMHo0VktuRmtoZGtjc20) {\n  \"endLine\": 100,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\model_management.py\",\n  \"startLine\": 1\n}\nTool\nðŸ› ï¸ call_MHxrcE1FMHo0VktuRmtoZGtjc20\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\comfy\\model_management.py`. Lines 1 to 100 (1537 lines total): \n```python\n\"\"\"\n    This file is part of ComfyUI.\n    Copyright (C) 2024 Comfy\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\"\"\"\n\nimport psutil\nimport logging\nfrom enum import Enum\nfrom comfy.cli_args import args, PerformanceFeature\nimport torch\nimport sys\nimport importlib\nimport platform\nimport weakref\nimport gc\nimport time\n\nclass VRAMState(Enum):\n    DISABLED = 0    #No vram present: no need to move models to vram\n    NO_VRAM = 1     #Very low vram: enable all the options to save vram\n    LOW_VRAM = 2\n    NORMAL_VRAM = 3\n    HIGH_VRAM = 4\n    SHARED = 5      #No dedicated vram: memory shared between CPU and GPU but models still need to be moved between both.\n\nclass CPUState(Enum):\n    GPU = 0\n    CPU = 1\n    MPS = 2\n\n# Determine VRAM State\nvram_state = VRAMState.NORMAL_VRAM\nset_vram_to = VRAMState.NORMAL_VRAM\ncpu_state = CPUState.GPU\n\ntotal_vram = 0\n\ndef get_supported_float8_types():\n    float8_types = []\n    try:\n        float8_types.append(torch.float8_e4m3fn)\n    except:\n        pass\n    try:\n        float8_types.append(torch.float8_e4m3fnuz)\n    except:\n        pass\n    try:\n        float8_types.append(torch.float8_e5m2)\n    except:\n        pass\n    try:\n        float8_types.append(torch.float8_e5m2fnuz)\n    except:\n        pass\n    try:\n        float8_types.append(torch.float8_e8m0fnu)\n    except:\n        pass\n    return float8_types\n\nFLOAT8_TYPES = get_supported_float8_types()\n\nxpu_available = False\ntorch_version = \"\"\ntry:\n    torch_version = torch.version.__version__\n    temp = torch_version.split(\".\")\n    torch_version_numeric = (int(temp[0]), int(temp[1]))\nexcept:\n    pass\n\nlowvram_available = True\nif args.deterministic:\n    logging.info(\"Using deterministic algorithms for pytorch\")\n    torch.use_deterministic_algorithms(True, warn_only=True)\n\ndirectml_enabled = False\nif args.directml is not None:\n    logging.warning(\"WARNING: torch-directml barely works, is very slow, has not been updated in over 1 year and might be removed soon, please don't use it, there are better options.\")\n    import torch_directml\n    directml_enabled = True\n    device_index = args.directml\n    if device_index < 0:\n        directml_device = torch_directml.device()\n    else:\n        directml_device = torch_directml.device(device_index)\n```\nAssistant\n\nðŸ› ï¸ grep_search (call_MHxVVkw2OVhvVkdxS09yZ3VvQjA) {\n  \"isRegexp\": false,\n  \"query\": \"args.fast_load\"\n}\nTool\nðŸ› ï¸ call_MHxVVkw2OVhvVkdxS09yZ3VvQjA\n4 matches\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\" line=2101>\nif args.fast_load:\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\model_management.py\" line=105>\nif not args.fast_load:\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\model_management.py\" line=160>\nif args.cpu or args.fast_load:\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\model_management.py\" line=278>\nif args.disable_xformers or args.fast_load:\n</match>\n\nAssistant\n\nðŸ› ï¸ read_file (call_MHw2Nm5CYXlkVFRvU2Nxd3Z2OXM) {\n  \"endLine\": 2110,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\",\n  \"startLine\": 2090\n}\nTool\nðŸ› ï¸ call_MHw2Nm5CYXlkVFRvU2Nxd3Z2OXM\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\nodes.py`. Lines 2090 to 2110 (2448 lines total): \n```python\n    \"ImageBlend\": \"Image Blend\",\n    \"ImageBlur\": \"Image Blur\",\n    \"ImageQuantize\": \"Image Quantize\",\n    \"ImageSharpen\": \"Image Sharpen\",\n    \"ImageScaleToTotalPixels\": \"Scale Image to Total Pixels\",\n    \"GetImageSize\": \"Get Image Size\",\n    # _for_testing\n    \"VAEDecodeTiled\": \"VAE Decode (Tiled)\",\n    \"VAEEncodeTiled\": \"VAE Encode (Tiled)\",\n}\n\nif args.fast_load:\n    NODE_CLASS_MAPPINGS = {}\n    NODE_DISPLAY_NAME_MAPPINGS = {}\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\n```\nAssistant\n\nðŸ› ï¸ read_file (call_MHwxV2RKS0R6cUhsQldMZXQ3enQ) {\n  \"endLine\": 30,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\",\n  \"startLine\": 1\n}\nTool\nðŸ› ï¸ call_MHwxV2RKS0R6cUhsQldMZXQ3enQ\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\nodes.py`. Lines 1 to 30 (2448 lines total): \n```python\nfrom __future__ import annotations\n\nimport os\nimport sys\nimport logging\nimport time\nfrom comfy.cli_args import args\n\nt_import = time.time()\nimport torch\nlogging.info(f\"import torch time: {time.time() - t_import:.4f}s\")\n\n\nimport json\nimport hashlib\nimport inspect\nimport traceback\nimport math\nimport random\n\nfrom PIL import Image, ImageOps, ImageSequence\nfrom PIL.PngImagePlugin import PngInfo\n\nimport numpy as np\n\nt_import = time.time()\nimport safetensors.torch\nlogging.info(f\"import safetensors.torch time: {time.time() - t_import:.4f}s\")\n\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy\"))\n```\nAssistant\n\nðŸ› ï¸ read_file (call_MHxzYTlOY0lhS2NDd1NCdW5LSjE) {\n  \"endLine\": 130,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\model_management.py\",\n  \"startLine\": 100\n}\nTool\nðŸ› ï¸ call_MHxzYTlOY0lhS2NDd1NCdW5LSjE\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\comfy\\model_management.py`. Lines 100 to 130 (1537 lines total): \n```python\n        directml_device = torch_directml.device(device_index)\n    logging.info(\"Using directml with device: {}\".format(torch_directml.device_name(device_index)))\n    # torch_directml.disable_tiled_resources(True)\n    lowvram_available = False #TODO: need to find a way to get free memory in directml before this can be enabled by default.\n\nif not args.fast_load:\n    t_start = time.time()\n    try:\n        import intel_extension_for_pytorch as ipex  # noqa: F401\n    except:\n        pass\n    logging.info(f\"IPEX check time: {time.time() - t_start:.4f}s\")\n\n    t_start = time.time()\n    try:\n        _ = torch.xpu.device_count()\n        xpu_available = torch.xpu.is_available()\n    except:\n        xpu_available = False\n    logging.info(f\"XPU check time: {time.time() - t_start:.4f}s\")\n\n    t_start = time.time()\n    try:\n        if torch.backends.mps.is_available():\n            cpu_state = CPUState.MPS\n            import torch.mps\n    except:\n        pass\n    logging.info(f\"MPS check time: {time.time() - t_start:.4f}s\")\n\n    t_start = time.time()\n```\nAssistant\n\nðŸ› ï¸ read_file (call_MHxVNDVkS3dEdzZ2dnlLZUdTVzI) {\n  \"endLine\": 50,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\cli_args.py\",\n  \"startLine\": 1\n}\nTool\nðŸ› ï¸ call_MHxVNDVkS3dEdzZ2dnlLZUdTVzI\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\comfy\\cli_args.py`. Lines 1 to 50 (246 lines total): \n```python\nimport argparse\nimport enum\nimport os\nimport comfy.options\n\n\nclass EnumAction(argparse.Action):\n    \"\"\"\n    Argparse action for handling Enums\n    \"\"\"\n    def __init__(self, **kwargs):\n        # Pop off the type value\n        enum_type = kwargs.pop(\"type\", None)\n\n        # Ensure an Enum subclass is provided\n        if enum_type is None:\n            raise ValueError(\"type must be assigned an Enum when using EnumAction\")\n        if not issubclass(enum_type, enum.Enum):\n            raise TypeError(\"type must be an Enum when using EnumAction\")\n\n        # Generate choices from the Enum\n        choices = tuple(e.value for e in enum_type)\n        kwargs.setdefault(\"choices\", choices)\n        kwargs.setdefault(\"metavar\", f\"[{','.join(list(choices))}]\")\n\n        super(EnumAction, self).__init__(**kwargs)\n\n        self._enum = enum_type\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        # Convert value back into an Enum\n        value = self._enum(values)\n        setattr(namespace, self.dest, value)\n\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\"--listen\", type=str, default=\"127.0.0.1\", metavar=\"IP\", nargs=\"?\", const=\"0.0.0.0,::\", help=\"Specify the IP address to listen on (default: 127.0.0.1). You can give a list of ip addresses by separating them with a comma like: 127.2.2.2,127.3.3.3 If --listen is provided without an argument, it defaults to 0.0.0.0,:: (listens on all ipv4 and ipv6)\")\nparser.add_argument(\"--port\", type=int, default=8188, help=\"Set the listen port.\")\nparser.add_argument(\"--tls-keyfile\", type=str, help=\"Path to TLS (SSL) key file. Enables TLS, makes app accessible at https://... requires --tls-certfile to function\")\nparser.add_argument(\"--tls-certfile\", type=str, help=\"Path to TLS (SSL) certificate file. Enables TLS, makes app accessible at https://... requires --tls-keyfile to function\")\nparser.add_argument(\"--enable-cors-header\", type=str, default=None, metavar=\"ORIGIN\", nargs=\"?\", const=\"*\", help=\"Enable CORS (Cross-Origin Resource Sharing) with optional origin or allow all with default '*'.\")\nparser.add_argument(\"--max-upload-size\", type=float, default=100, help=\"Set the maximum upload size in MB.\")\n\nparser.add_argument(\"--base-directory\", type=str, default=None, help=\"Set the ComfyUI base directory for models, custom_nodes, input, output, temp, and user directories.\")\nparser.add_argument(\"--extra-model-paths-config\", type=str, default=None, metavar=\"PATH\", nargs='+', action='append', help=\"Load one or more extra_model_paths.yaml files.\")\nparser.add_argument(\"--output-directory\", type=str, default=None, help=\"Set the ComfyUI output directory. Overrides --base-directory.\")\nparser.add_argument(\"--temp-directory\", type=str, default=None, help=\"Set the ComfyUI temp directory (default is in the ComfyUI directory). Overrides --base-directory.\")\nparser.add_argument(\"--input-directory\", type=str, default=None, help=\"Set the ComfyUI input directory. Overrides --base-directory.\")\nparser.add_argument(\"--auto-launch\", action=\"store_true\", help=\"Automatically launch ComfyUI in the default browser.\")\n```\nAssistant\n\nðŸ› ï¸ grep_search (call_MHxWMGZSeU1xREttRUxpNzRGQWs) {\n  \"isRegexp\": false,\n  \"query\": \"fast-load\"\n}\nTool\nðŸ› ï¸ call_MHxWMGZSeU1xREttRUxpNzRGQWs\n1 match\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\cli_args.py\" line=220>\nparser.add_argument(\"--fast-load\", action=\"store_true\", help=\"Skip heavy imports and hardware checks for faster startup (CPU only, no nodes).\")\n</match>\n\nAssistant\në³µìž¡í•œ Mocking ê´€ë ¨ ì½”ë“œë¥¼ ëª¨ë‘ ì œê±°í•˜ê³  `nodes.py`ë¥¼ ì›ëž˜ì˜ êµ¬ì¡°ë¡œ ë˜ëŒë ¸ìŠµë‹ˆë‹¤. (ë¡œë”© ì†ë„ ì¸¡ì •ì„ ìœ„í•œ ë¡œê·¸ ì½”ë“œëŠ” ë‚¨ê²¨ë‘ì—ˆìŠµë‹ˆë‹¤.)\n\ní˜„ìž¬ ìƒíƒœì—ì„œ `--fast-load` ì˜µì…˜ì€ ì•„ì£¼ ë‹¨ìˆœí•œ ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•˜ë„ë¡ ë‚¨ì•„ìžˆìŠµë‹ˆë‹¤:\n\n1.  **í•˜ë“œì›¨ì–´ ì²´í¬ ìŠ¤í‚µ**: `comfy/model_management.py`ì—ì„œ IPEX, XPU ë“± ë¶ˆí•„ìš”í•œ í•˜ë“œì›¨ì–´ ê°ì§€ ë¡œì§ì„ ê±´ë„ˆëœë‹ˆë‹¤.\n2.  **ê¸°ë³¸ ë…¸ë“œ ë¹„í™œì„±í™”**: `nodes.py`ì—ì„œ ê¸°ë³¸ ë…¸ë“œ ëª©ë¡(`NODE_CLASS_MAPPINGS`)ì„ ë¹ˆ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì—¬ ê¸°ë³¸ ë…¸ë“œë“¤ì„ ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n**torch ìž„í¬íŠ¸**ëŠ” ê·¸ëŒ€ë¡œ ìˆ˜í–‰ë˜ë¯€ë¡œ \"ê·¹ì ì¸\" ì†ë„ í–¥ìƒì€ ì—†ê² ì§€ë§Œ, ë³µìž¡í•œ ì½”ë“œ ìˆ˜ì • ì—†ì´ **\"ê¸°ë³¸ ë…¸ë“œ ì œì™¸ + ì•½ê°„ì˜ ë¶€íŒ… ì†ë„ í–¥ìƒ\"** íš¨ê³¼ëŠ” ì–»ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n\nì´ëŒ€ë¡œ **`--fast-load` ì˜µì…˜ì„ ìœ ì§€**í• ê¹Œìš”, ì•„ë‹ˆë©´ ì´ ì˜µì…˜ê³¼ ê´€ë ¨ ì½”ë“œë„ **ëª¨ë‘ ì œê±°**í•˜ê³  ìˆœì • ìƒíƒœ(ë¡œê·¸ë§Œ í¬í•¨)ë¡œ ëŒì•„ê°ˆê¹Œìš”?\nUser\n<context>\nThe current date is 2025ë…„ 12ì›” 15ì¼.\nTerminals:\nTerminal: bash\n\n</context>\n<editorContext>\nThe user's current file is c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\nodes.py. \n</editorContext>\n<reminderInstructions>\nWhen using the replace_string_in_file tool, include 3-5 lines of unchanged code before and after the string you want to replace, to make it unambiguous which part of the file should be edited.\n\n</reminderInstructions>\n<userRequest>\nì˜µì…˜ ìœ ì§€í•´. ê·¸ëŸ°ë° ë„ˆë¬´ ê³¼ë„í•˜ê²Œ ëŒ€ì²´í•  í•„ìš”ëŠ” ì—†ê³ , CPU ì˜µì…˜ì¼ ë•Œ GPU ì²´í¬ í•˜ëŠ” ë¶€ë¶„ ì œê±° + ë§Œë“œëŠ”ë° ì˜¤ëž˜ ê±¸ë¦¬ëŠ” ë…¸ë“œë“¤ ì•ˆ ìž„í¬íŠ¸í•˜ê²Œë§Œ í•´ë„ ë  ê±° ê°™ì•„.\n</userRequest>\n\nAssistant\n\nðŸ› ï¸ read_file (call_MHxKd1VsRWNiZGRJMHYxSkpwMnU) {\n  \"endLine\": 200,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\main.py\",\n  \"startLine\": 1\n}\nTool\nðŸ› ï¸ call_MHxKd1VsRWNiZGRJMHYxSkpwMnU\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\main.py`. Lines 1 to 200 (390 lines total): \n```python\nimport comfy.options\ncomfy.options.enable_args_parsing()\n\nimport os\nimport importlib.util\nimport folder_paths\nimport time\nfrom comfy.cli_args import args\nfrom app.logger import setup_logger\nimport itertools\nimport utils.extra_config\nimport logging\nimport sys\nfrom comfy_execution.progress import get_progress_state\nfrom comfy_execution.utils import get_executing_context\nfrom comfy_api import feature_flags\n\nif __name__ == \"__main__\":\n    #NOTE: These do not do anything on core ComfyUI, they are for custom nodes.\n    os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n    os.environ['DO_NOT_TRACK'] = '1'\n\nsetup_logger(log_level=args.verbose, use_stdout=args.log_stdout)\n\ndef apply_custom_paths():\n    # extra model paths\n    extra_model_paths_config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"extra_model_paths.yaml\")\n    if os.path.isfile(extra_model_paths_config_path):\n        utils.extra_config.load_extra_path_config(extra_model_paths_config_path)\n\n    if args.extra_model_paths_config:\n        for config_path in itertools.chain(*args.extra_model_paths_config):\n            utils.extra_config.load_extra_path_config(config_path)\n\n    # --output-directory, --input-directory, --user-directory\n    if args.output_directory:\n        output_dir = os.path.abspath(args.output_directory)\n        logging.info(f\"Setting output directory to: {output_dir}\")\n        folder_paths.set_output_directory(output_dir)\n\n    # These are the default folders that checkpoints, clip and vae models will be saved to when using CheckpointSave, etc.. nodes\n    folder_paths.add_model_folder_path(\"checkpoints\", os.path.join(folder_paths.get_output_directory(), \"checkpoints\"))\n    folder_paths.add_model_folder_path(\"clip\", os.path.join(folder_paths.get_output_directory(), \"clip\"))\n    folder_paths.add_model_folder_path(\"vae\", os.path.join(folder_paths.get_output_directory(), \"vae\"))\n    folder_paths.add_model_folder_path(\"diffusion_models\",\n                                       os.path.join(folder_paths.get_output_directory(), \"diffusion_models\"))\n    folder_paths.add_model_folder_path(\"loras\", os.path.join(folder_paths.get_output_directory(), \"loras\"))\n\n    if args.input_directory:\n        input_dir = os.path.abspath(args.input_directory)\n        logging.info(f\"Setting input directory to: {input_dir}\")\n        folder_paths.set_input_directory(input_dir)\n\n    if args.user_directory:\n        user_dir = os.path.abspath(args.user_directory)\n        logging.info(f\"Setting user directory to: {user_dir}\")\n        folder_paths.set_user_directory(user_dir)\n\n\ndef execute_prestartup_script():\n    if args.disable_all_custom_nodes and len(args.whitelist_custom_nodes) == 0:\n        return\n\n    def execute_script(script_path):\n        module_name = os.path.splitext(script_path)[0]\n        try:\n            spec = importlib.util.spec_from_file_location(module_name, script_path)\n            module = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(module)\n            return True\n        except Exception as e:\n            logging.error(f\"Failed to execute startup-script: {script_path} / {e}\")\n        return False\n\n    node_paths = folder_paths.get_folder_paths(\"custom_nodes\")\n    for custom_node_path in node_paths:\n        possible_modules = os.listdir(custom_node_path)\n        node_prestartup_times = []\n\n        for possible_module in possible_modules:\n            module_path = os.path.join(custom_node_path, possible_module)\n            if os.path.isfile(module_path) or module_path.endswith(\".disabled\") or module_path == \"__pycache__\":\n                continue\n\n            script_path = os.path.join(module_path, \"prestartup_script.py\")\n            if os.path.exists(script_path):\n                if args.disable_all_custom_nodes and possible_module not in args.whitelist_custom_nodes:\n                    logging.info(f\"Prestartup Skipping {possible_module} due to disable_all_custom_nodes and whitelist_custom_nodes\")\n                    continue\n                time_before = time.perf_counter()\n                success = execute_script(script_path)\n                node_prestartup_times.append((time.perf_counter() - time_before, module_path, success))\n    if len(node_prestartup_times) > 0:\n        logging.info(\"\\nPrestartup times for custom nodes:\")\n        for n in sorted(node_prestartup_times):\n            if n[2]:\n                import_message = \"\"\n            else:\n                import_message = \" (PRESTARTUP FAILED)\"\n            logging.info(\"{:6.1f} seconds{}: {}\".format(n[0], import_message, n[1]))\n        logging.info(\"\")\n\napply_custom_paths()\nexecute_prestartup_script()\n\n\n# Main code\nimport asyncio\nimport shutil\nimport threading\nimport gc\n\n\nif os.name == \"nt\":\n    os.environ['MIMALLOC_PURGE_DELAY'] = '0'\n\nif __name__ == \"__main__\":\n    os.environ['TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL'] = '1'\n    if args.default_device is not None:\n        default_dev = args.default_device\n        devices = list(range(32))\n        devices.remove(default_dev)\n        devices.insert(0, default_dev)\n        devices = ','.join(map(str, devices))\n        os.environ['CUDA_VISIBLE_DEVICES'] = str(devices)\n        os.environ['HIP_VISIBLE_DEVICES'] = str(devices)\n\n    if args.cuda_device is not None:\n        os.environ['CUDA_VISIBLE_DEVICES'] = str(args.cuda_device)\n        os.environ['HIP_VISIBLE_DEVICES'] = str(args.cuda_device)\n        os.environ[\"ASCEND_RT_VISIBLE_DEVICES\"] = str(args.cuda_device)\n        logging.info(\"Set cuda device to: {}\".format(args.cuda_device))\n\n    if args.oneapi_device_selector is not None:\n        os.environ['ONEAPI_DEVICE_SELECTOR'] = args.oneapi_device_selector\n        logging.info(\"Set oneapi device selector to: {}\".format(args.oneapi_device_selector))\n\n    if args.deterministic:\n        if 'CUBLAS_WORKSPACE_CONFIG' not in os.environ:\n            os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n\n    import cuda_malloc\n\nif 'torch' in sys.modules:\n    logging.warning(\"WARNING: Potential Error in code: Torch already imported, torch should never be imported before this point.\")\n\nimport comfy.utils\n\nt_exec = time.time()\nimport execution\nlogging.info(f\"Import execution time: {time.time() - t_exec:.2f} seconds\")\nimport server\nfrom protocol import BinaryEventTypes\nt0 = time.time()\nimport nodes\nlogging.info(f\"Import nodes time: {time.time() - t0:.2f} seconds\")\nimport comfy.model_management\nimport comfyui_version\nimport app.logger\nimport hook_breaker_ac10a0\n\ndef cuda_malloc_warning():\n    device = comfy.model_management.get_torch_device()\n    device_name = comfy.model_management.get_torch_device_name(device)\n    cuda_malloc_warning = False\n    if \"cudaMallocAsync\" in device_name:\n        for b in cuda_malloc.blacklist:\n            if b in device_name:\n                cuda_malloc_warning = True\n        if cuda_malloc_warning:\n            logging.warning(\"\\nWARNING: this card most likely does not support cuda-malloc, if you get \\\"CUDA error\\\" please run ComfyUI with: --disable-cuda-malloc\\n\")\n\n\ndef prompt_worker(q, server_instance):\n    current_time: float = 0.0\n    cache_type = execution.CacheType.CLASSIC\n    if args.cache_lru > 0:\n        cache_type = execution.CacheType.LRU\n    elif args.cache_ram > 0:\n        cache_type = execution.CacheType.RAM_PRESSURE\n    elif args.cache_none:\n        cache_type = execution.CacheType.NONE\n\n    e = execution.PromptExecutor(server_instance, cache_type=cache_type, cache_args={ \"lru\" : args.cache_lru, \"ram\" : args.cache_ram } )\n    last_gc_collect = 0\n    need_gc = False\n    gc_collect_interval = 10.0\n\n    while True:\n        timeout = 1000.0\n        if need_gc:\n            timeout = max(gc_collect_interval - (current_time - last_gc_collect), 0.0)\n\n        queue_item = q.get(timeout=timeout)\n        if queue_item is not None:\n            item, item_id = queue_item\n            execution_start_time = time.perf_counter()\n            prompt_id = item[1]\n            server_instance.last_prompt_id = prompt_id\n\n```\nAssistant\n\nðŸ› ï¸ read_file (call_MHxCTmg4MHYxS09BSk9Sd1Q2VVc) {\n  \"endLine\": 300,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\main.py\",\n  \"startLine\": 200\n}\nTool\nðŸ› ï¸ call_MHxCTmg4MHYxS09BSk9Sd1Q2VVc\nFile: `c:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\main.py`. Lines 200 to 300 (390 lines total): \n```python\n\n            sensitive = item[5]\n            extra_data = item[3].copy()\n            for k in sensitive:\n                extra_data[k] = sensitive[k]\n\n            e.execute(item[2], prompt_id, extra_data, item[4])\n            need_gc = True\n\n            remove_sensitive = lambda prompt: prompt[:5] + prompt[6:]\n            q.task_done(item_id,\n                        e.history_result,\n                        status=execution.PromptQueue.ExecutionStatus(\n                            status_str='success' if e.success else 'error',\n                            completed=e.success,\n                            messages=e.status_messages), process_item=remove_sensitive)\n            if server_instance.client_id is not None:\n                server_instance.send_sync(\"executing\", {\"node\": None, \"prompt_id\": prompt_id}, server_instance.client_id)\n\n            current_time = time.perf_counter()\n            execution_time = current_time - execution_start_time\n\n            # Log Time in a more readable way after 10 minutes\n            if execution_time > 600:\n                execution_time = time.strftime(\"%H:%M:%S\", time.gmtime(execution_time))\n                logging.info(f\"Prompt executed in {execution_time}\")\n            else:\n                logging.info(\"Prompt executed in {:.2f} seconds\".format(execution_time))\n\n        flags = q.get_flags()\n        free_memory = flags.get(\"free_memory\", False)\n\n        if flags.get(\"unload_models\", free_memory):\n            comfy.model_management.unload_all_models()\n            need_gc = True\n            last_gc_collect = 0\n\n        if free_memory:\n            e.reset()\n            need_gc = True\n            last_gc_collect = 0\n\n        if need_gc:\n            current_time = time.perf_counter()\n            if (current_time - last_gc_collect) > gc_collect_interval:\n                gc.collect()\n                comfy.model_management.soft_empty_cache()\n                last_gc_collect = current_time\n                need_gc = False\n                hook_breaker_ac10a0.restore_functions()\n\n\nasync def run(server_instance, address='', port=8188, verbose=True, call_on_start=None):\n    addresses = []\n    for addr in address.split(\",\"):\n        addresses.append((addr, port))\n    await asyncio.gather(\n        server_instance.start_multi_address(addresses, call_on_start, verbose), server_instance.publish_loop()\n    )\n\ndef hijack_progress(server_instance):\n    def hook(value, total, preview_image, prompt_id=None, node_id=None):\n        executing_context = get_executing_context()\n        if prompt_id is None and executing_context is not None:\n            prompt_id = executing_context.prompt_id\n        if node_id is None and executing_context is not None:\n            node_id = executing_context.node_id\n        comfy.model_management.throw_exception_if_processing_interrupted()\n        if prompt_id is None:\n            prompt_id = server_instance.last_prompt_id\n        if node_id is None:\n            node_id = server_instance.last_node_id\n        progress = {\"value\": value, \"max\": total, \"prompt_id\": prompt_id, \"node\": node_id}\n        get_progress_state().update_progress(node_id, value, total, preview_image)\n\n        server_instance.send_sync(\"progress\", progress, server_instance.client_id)\n        if preview_image is not None:\n            # Only send old method if client doesn't support preview metadata\n            if not feature_flags.supports_feature(\n                server_instance.sockets_metadata,\n                server_instance.client_id,\n                \"supports_preview_metadata\",\n            ):\n                server_instance.send_sync(\n                    BinaryEventTypes.UNENCODED_PREVIEW_IMAGE,\n                    preview_image,\n                    server_instance.client_id,\n                )\n\n    comfy.utils.set_progress_bar_global_hook(hook)\n\n\ndef cleanup_temp():\n    temp_dir = folder_paths.get_temp_directory()\n    if os.path.exists(temp_dir):\n        shutil.rmtree(temp_dir, ignore_errors=True)\n\n\ndef setup_database():\n    try:\n        from app.database.db import init_db, dependencies_available\n```\nAssistant\n\nðŸ› ï¸ read_file (call_MHxhMEFMUHhmTmhtSDVtN2pnUlA) {\n  \"endLine\": 390,\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\main.py\",\n  \"startLine\": 300\n}\nTool\nðŸ› ï¸ call_MHxhMEFMUHhmTmhtSDVtN2pnUlA\n```python\n        from app.database.db import init_db, dependencies_available\n        if dependencies_available():\n            init_db()\n    except Exception as e:\n        logging.error(f\"Failed to initialize database. Please ensure you have installed the latest requirements. If the error persists, please report this as in future the database will be required: {e}\")\n\n\ndef start_comfyui(asyncio_loop=None):\n    \"\"\"\n    Starts the ComfyUI server using the provided asyncio event loop or creates a new one.\n    Returns the event loop, server instance, and a function to start the server asynchronously.\n    \"\"\"\n    if args.temp_directory:\n        temp_dir = os.path.join(os.path.abspath(args.temp_directory), \"temp\")\n        logging.info(f\"Setting temp directory to: {temp_dir}\")\n        folder_paths.set_temp_directory(temp_dir)\n    cleanup_temp()\n\n    if args.windows_standalone_build:\n        try:\n            import new_updater\n            new_updater.update_windows_updater()\n        except:\n            pass\n\n    if not asyncio_loop:\n        asyncio_loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(asyncio_loop)\n    prompt_server = server.PromptServer(asyncio_loop)\n\n    hook_breaker_ac10a0.save_functions()\n    t_nodes = time.time()\n    asyncio_loop.run_until_complete(nodes.init_extra_nodes(\n        init_custom_nodes=(not args.disable_all_custom_nodes) or len(args.whitelist_custom_nodes) > 0,\n        init_api_nodes=not args.disable_api_nodes\n    ))\n    logging.info(f\"Init extra nodes time: {time.time() - t_nodes:.2f} seconds\")\n    hook_breaker_ac10a0.restore_functions()\n\n    cuda_malloc_warning()\n    setup_database()\n\n    prompt_server.add_routes()\n    hijack_progress(prompt_server)\n\n    threading.Thread(target=prompt_worker, daemon=True, args=(prompt_server.prompt_queue, prompt_server,)).start()\n\n    if args.quick_test_for_ci:\n        exit(0)\n\n    os.makedirs(folder_paths.get_temp_directory(), exist_ok=True)\n    call_on_start = None\n    if args.auto_launch:\n        def startup_server(scheme, address, port):\n            import webbrowser\n            if os.name == 'nt' and address == '0.0.0.0':\n                address = '127.0.0.1'\n            if ':' in address:\n                address = \"[{}]\".format(address)\n            webbrowser.open(f\"{scheme}://{address}:{port}\")\n        call_on_start = startup_server\n\n    async def start_all():\n        await prompt_server.setup()\n        await run(prompt_server, address=args.listen, port=args.port, verbose=not args.dont_print_server, call_on_start=call_on_start)\n\n    # Returning these so that other code can integrate with the ComfyUI loop and server\n    return asyncio_loop, prompt_server, start_all\n\n\nif __name__ == \"__main__\":\n    import time\n    start_time = time.time()\n    # Running directly, just start ComfyUI.\n    logging.info(\"Python version: {}\".format(sys.version))\n    logging.info(\"ComfyUI version: {}\".format(comfyui_version.__version__))\n\n    if sys.version_info.major == 3 and sys.version_info.minor < 10:\n        logging.warning(\"WARNING: You are using a python version older than 3.10, please upgrade to a newer one. 3.12 and above is recommended.\")\n\n    event_loop, _, start_all_func = start_comfyui()\n    logging.info(f\"Startup time: {time.time() - start_time:.2f} seconds\")\n    try:\n        x = start_all_func()\n        app.logger.print_startup_warnings()\n        event_loop.run_until_complete(x)\n    except KeyboardInterrupt:\n        logging.info(\"\\nStopped server\")\n\n    cleanup_temp()\n\n```\nAssistant\n\nðŸ› ï¸ grep_search (call_MHxmd0Y1SHQ0Z0R6ZkhJNjRqOFk) {\n  \"isRegexp\": false,\n  \"query\": \"--cpu\"\n}\nTool\nðŸ› ï¸ call_MHxmd0Y1SHQ0Z0R6ZkhJNjRqOFk\n11 matches\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\cli_args.py\" line=77>\nparser.add_argument(\"--cpu-vae\", action=\"store_true\", help=\"Run the VAE on the CPU.\")\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\cli_args.py\" line=130>\nvram_group.add_argument(\"--cpu\", action=\"store_true\", help=\"To use the CPU for everything (slow).\")\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\tests\\\\execution\\\\test_progress_isolation.py\" line=96>\n            '--cpu',\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\tests\\\\execution\\\\test_async_nodes.py\" line=27>\n            '--cpu',\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\tests\\\\execution\\\\test_execution.py\" line=168>\n            '--cpu',\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\README.md\" line=90>\n- Works even if you don't have a GPU with: ```--cpu``` (slow)\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\.github\\\\workflows\\\\stable-release.yml\" line=158>\n          python_embeded/python.exe -s ComfyUI/main.py --quick-test-for-ci --cpu\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\.github\\\\workflows\\\\test-launch.yml\" line=30>\n        python main.py --cpu 2>&1 | tee console_output.log &\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\.ci\\\\windows_nvidia_base_files\\\\run_cpu.bat\" line=1>\n.\\python_embeded\\python.exe -s ComfyUI\\main.py --cpu --windows-standalone-build\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\.github\\\\workflows\\\\windows_release_nightly_pytorch.yml\" line=83>\n            python_embeded/python.exe -s ComfyUI/main.py --quick-test-for-ci --cpu\n</match>\n<match path=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\.github\\\\workflows\\\\windows_release_package.yml\" line=93>\n            python_embeded/python.exe -s ComfyUI/main.py --quick-test-for-ci --cpu\n</match>\n\nAssistant\n\nðŸ› ï¸ replace_string_in_file (call_MHxCMmhtRVVGUng5QmoyME1kQlo) {\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\comfy\\\\model_management.py\",\n  \"newString\": \"    lowvram_available = False #TODO: need to find a way to get free memory in directml before this can be enabled by default.\n\nif not args.fast_load and not args.cpu:\n    t_start = time.time()\n    try:\n        import intel_extension_for_pytorch as ipex  # noqa: F401\",\n  \"oldString\": \"    lowvram_available = False #TODO: need to find a way to get free memory in directml before this can be enabled by default.\n\nif not args.fast_load:\n    t_start = time.time()\n    try:\n        import intel_extension_for_pytorch as ipex  # noqa: F401\"\n}\nTool\nðŸ› ï¸ call_MHxCMmhtRVVGUng5QmoyME1kQlo\nThe following files were successfully edited:\nc:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\comfy\\model_management.py\n\nAssistant\n\nðŸ› ï¸ replace_string_in_file (call_MHxiQU9hSTFra2FtcElySUtlekg) {\n  \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\main.py\",\n  \"newString\": \"    hook_breaker_ac10a0.save_functions()\n    t_nodes = time.time()\n    asyncio_loop.run_until_complete(nodes.init_extra_nodes(\n        init_custom_nodes=(not args.disable_all_custom_nodes and not args.fast_load) or len(args.whitelist_custom_nodes) > 0,\n        init_api_nodes=not args.disable_api_nodes\n    ))\n    logging.info(f\\\"Init extra nodes time: {time.time() - t_nodes:.2f} seconds\\\")\n    hook_breaker_ac10a0.restore_functions()\",\n  \"oldString\": \"    hook_breaker_ac10a0.save_functions()\n    t_nodes = time.time()\n    asyncio_loop.run_until_complete(nodes.init_extra_nodes(\n        init_custom_nodes=(not args.disable_all_custom_nodes) or len(args.whitelist_custom_nodes) > 0,\n        init_api_nodes=not args.disable_api_nodes\n    ))\n    logging.info(f\\\"Init extra nodes time: {time.time() - t_nodes:.2f} seconds\\\")\n    hook_breaker_ac10a0.restore_functions()\"\n}\nTool\nðŸ› ï¸ call_MHxiQU9hSTFra2FtcElySUtlekg\nThe following files were successfully edited:\nc:\\Workbench\\20_Projects\\hvppycoding_ComfyUI\\main.py\n\nAssistant\nìš”ì²­í•˜ì‹  ëŒ€ë¡œ `--fast-load` ì˜µì…˜ì„ ìœ ì§€í•˜ë˜, ê³¼ë„í•œ Mocking ì—†ì´ ì‹¤ìš©ì ì¸ ìˆ˜ì¤€ì—ì„œ ìµœì í™”ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n\n**ì ìš©ëœ ë³€ê²½ ì‚¬í•­:**\n\n1.  **GPU ì²´í¬ ìŠ¤í‚µ (`comfy/model_management.py`)**:\n    *   `--fast-load` ì˜µì…˜ì´ ì¼œì ¸ ìžˆê±°ë‚˜, `--cpu` ì˜µì…˜ì´ ì¼œì ¸ ìžˆëŠ” ê²½ìš°, ë¶€íŒ… ì‹œ ì‹œê°„ì´ ê±¸ë¦¬ëŠ” IPEX, XPU, MPS, CUDA ë“±ì˜ í•˜ë“œì›¨ì–´ ê°ì§€ ë¡œì§ì„ ê±´ë„ˆë›°ë„ë¡ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\n\n2.  **ì»¤ìŠ¤í…€ ë…¸ë“œ ë¡œë”© ìŠ¤í‚µ (`main.py`)**:\n    *   `--fast-load` ì˜µì…˜ì´ ì¼œì ¸ ìžˆìœ¼ë©´, ë¶€íŒ… ì‹œ ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦¬ëŠ” ì£¼ë²”ì¸ **ì»¤ìŠ¤í…€ ë…¸ë“œë“¤ì˜ ë¡œë”©ì„ ì•„ì˜ˆ ì‹œë„í•˜ì§€ ì•Šë„ë¡** ë³€ê²½í–ˆìŠµë‹ˆë‹¤. (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì— ìžˆëŠ” ë…¸ë“œëŠ” ì œì™¸)\n\n3.  **ê¸°ë³¸ ë…¸ë“œ ë¹„í™œì„±í™” (`nodes.py`)**:\n    *   ê¸°ì¡´ì— ì ìš©í•´ë‘” ëŒ€ë¡œ, `--fast-load` ì‹œ ê¸°ë³¸ ë…¸ë“œ ë§¤í•‘(`NODE_CLASS_MAPPINGS`)ì„ ë¹„ì›Œì„œ ê¸°ë³¸ ë…¸ë“œë“¤ë„ ë¡œë“œë˜ì§€ ì•Šê²Œ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.\n\nì´ì œ `--fast-load` ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ **\"í•˜ë“œì›¨ì–´ ì²´í¬ ìŠ¤í‚µ + ì»¤ìŠ¤í…€ ë…¸ë“œ ë¡œë”© ìŠ¤í‚µ + ê¸°ë³¸ ë…¸ë“œ ë¹„í™œì„±í™”\"**ê°€ ì ìš©ë˜ì–´, ë³µìž¡í•œ ì½”ë“œ ìˆ˜ì • ì—†ì´ë„ í›¨ì”¬ ë¹ ë¥¸ ë¶€íŒ… ì†ë„ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n\n[copilot_cache_control: { type: 'ephemeral' }]\nUser\n<attachments>\n<attachment id=\"nodes.py\">\nExcerpt from nodes.py, lines 2406 to 2412:\n```python\nasync def init_public_apis():\n    register_versions([\n        ComfyAPIWithVersion(\n            version=getattr(v, \"VERSION\"),\n            api_class=v\n        ) for v in supported_versions\n    ])\n```\n</attachment>\n<attachment isSummarized=\"true\" filePath=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\">\nUser's active file for additional context:\nif args.fast_load:\n    /* Lines 2105-2106 omitted */\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\ndef get_module_name(module_path: str) -> str:\n    /* Lines 2115-2133 omitted */\n\n\nasync def load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    /* Lines 2137-2229 omitted */\n\nasync def init_external_custom_nodes():\n    /* Lines 2232-2268 omitted */\n\nasync def init_builtin_extra_nodes():\n    /* Lines 2271-2281 omitted */\n    extras_files = [\n        \"nodes_latent.py\",\n        \"nodes_hypernetwork.py\",\n        \"nodes_upscale_model.py\",\n        \"nodes_post_processing.py\",\n        \"nodes_mask.py\",\n        \"nodes_compositing.py\",\n        \"nodes_rebatch.py\",\n        \"nodes_model_merging.py\",\n        \"nodes_tomesd.py\",\n        \"nodes_clip_sdxl.py\",\n        \"nodes_canny.py\",\n        \"nodes_freelunch.py\",\n        \"nodes_custom_sampler.py\",\n        \"nodes_hypertile.py\",\n        \"nodes_model_advanced.py\",\n        \"nodes_model_downscale.py\",\n        \"nodes_images.py\",\n        \"nodes_video_model.py\",\n        \"nodes_train.py\",\n        \"nodes_sag.py\",\n        \"nodes_perpneg.py\",\n        \"nodes_stable3d.py\",\n        \"nodes_sdupscale.py\",\n        \"nodes_photomaker.py\",\n        \"nodes_pixart.py\",\n        \"nodes_cond.py\",\n        \"nodes_morphology.py\",\n        \"nodes_stable_cascade.py\",\n        \"nodes_differential_diffusion.py\",\n        \"nodes_ip2p.py\",\n        \"nodes_model_merging_model_specific.py\",\n        \"nodes_pag.py\",\n        \"nodes_align_your_steps.py\",\n        \"nodes_attention_multiply.py\",\n        \"nodes_advanced_samplers.py\",\n        \"nodes_webcam.py\",\n        \"nodes_audio.py\",\n        \"nodes_sd3.py\",\n        \"nodes_gits.py\",\n        \"nodes_controlnet.py\",\n        \"nodes_hunyuan.py\",\n        \"nodes_eps.py\",\n        \"nodes_flux.py\",\n        \"nodes_lora_extract.py\",\n        \"nodes_torch_compile.py\",\n        \"nodes_mochi.py\",\n        \"nodes_slg.py\",\n        \"nodes_mahiro.py\",\n        \"nodes_lt.py\",\n        \"nodes_hooks.py\",\n        \"nodes_load_3d.py\",\n        \"nodes_cosmos.py\",\n        \"nodes_video.py\",\n        \"nodes_lumina2.py\",\n        \"nodes_wan.py\",\n        \"nodes_lotus.py\",\n        \"nodes_hunyuan3d.py\",\n        \"nodes_primitive.py\",\n        \"nodes_cfg.py\",\n        \"nodes_optimalsteps.py\",\n        \"nodes_hidream.py\",\n        \"nodes_fresca.py\",\n        \"nodes_apg.py\",\n        \"nodes_preview_any.py\",\n        \"nodes_ace.py\",\n        \"nodes_string.py\",\n        \"nodes_camera_trajectory.py\",\n        \"nodes_edit_model.py\",\n        \"nodes_tcfg.py\",\n        \"nodes_context_windows.py\",\n        \"nodes_qwen.py\",\n        \"nodes_chroma_radiance.py\",\n        \"nodes_model_patch.py\",\n        \"nodes_easycache.py\",\n        \"nodes_audio_encoder.py\",\n        \"nodes_rope.py\",\n        \"nodes_nop.py\",\n    ]\n\n    import_failed = []\n    for node_file in extras_files:\n        /* Lines 2363-2364 omitted */\n\n    return import_failed\n\n\nasync def init_builtin_api_nodes():\n    api_nodes_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_api_nodes\")\n    api_nodes_files = [\n        \"nodes_ideogram.py\",\n        \"nodes_openai.py\",\n        \"nodes_minimax.py\",\n        \"nodes_veo2.py\",\n        \"nodes_kling.py\",\n        \"nodes_bfl.py\",\n        \"nodes_bytedance.py\",\n        \"nodes_ltxv.py\",\n        \"nodes_luma.py\",\n        \"nodes_recraft.py\",\n        \"nodes_pixverse.py\",\n        \"nodes_stability.py\",\n        \"nodes_pika.py\",\n        \"nodes_runway.py\",\n        \"nodes_sora.py\",\n        \"nodes_topaz.py\",\n        \"nodes_tripo.py\",\n        \"nodes_moonvalley.py\",\n        \"nodes_rodin.py\",\n        \"nodes_gemini.py\",\n        \"nodes_vidu.py\",\n        \"nodes_wan.py\",\n    ]\n\n    if not await load_custom_node(os.path.join(api_nodes_dir, \"canary.py\"), module_parent=\"comfy_api_nodes\"):\n        /* Line 2397 omitted */\n\n    import_failed = []\n    for node_file in api_nodes_files:\n        /* Lines 2401-2402 omitted */\n\n    return import_failed\n\nasync def init_public_apis():\n    register_versions([\n        ComfyAPIWithVersion(\n            version=getattr(v, \"VERSION\"),\n            api_class=v\n        ) for v in supported_versions\n    ])\n\nasync def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n    await init_public_apis()\n\n    import_failed = await init_builtin_extra_nodes()\n\n    import_failed_api = []\n    if init_api_nodes:\n        /* Line 2421 omitted */\n\n    if init_custom_nodes:\n        /* Line 2424 omitted */\n    else:\n        /* Line 2426 omitted */\n\n    if len(import_failed_api) > 0:\n        /* Lines 2429-2437 omitted */\n</attachment>\n<attachment id=\"nodes.py-1\" isSummarized=\"true\" filePath=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\">\nfrom __future__ import annotations\n/* Lines 2-7 omitted */\nfrom comfy.cli_args import args\n\nt_import = time.time()\n/* Lines 10-11 omitted */\nlogging.info(f\"import torch time: {time.time() - t_import:.4f}s\")\n/* Lines 12-20 omitted */\n\nfrom PIL import Image, ImageOps, ImageSequence\nfrom PIL.PngImagePlugin import PngInfo\n/* Lines 23-25 omitted */\n\nt_import = time.time()\n/* Lines 27-28 omitted */\nlogging.info(f\"import safetensors.torch time: {time.time() - t_import:.4f}s\")\n\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy\"))\n\nt_import = time.time()\nif not args.fast_load:\n    /* Lines 34-39 omitted */\nlogging.info(f\"import comfy modules time: {time.time() - t_import:.4f}s\")\n/* Lines 41-43 omitted */\nfrom comfy.comfy_types import IO, ComfyNodeABC, InputTypeDict, FileLocator\nfrom comfy_api.internal import register_versions, ComfyAPIWithVersion\nfrom comfy_api.version_list import supported_versions\nfrom comfy_api.latest import io, ComfyExtension\n\nt_import = time.time()\nif not args.fast_load:\n    /* Line 50 omitted */\nlogging.info(f\"import comfy.clip_vision time: {time.time() - t_import:.4f}s\")\n/* Lines 52-60 omitted */\n\ndef before_node_execution():\n    /* Line 62 omitted */\n\ndef interrupt_processing(value=True):\n    /* Line 65 omitted */\n\nMAX_RESOLUTION=16384\n\nclass CLIPTextEncode(ComfyNodeABC):\n    /* Lines 70-89 omitted */\n\n\nclass ConditioningCombine:\n    /* Lines 93-102 omitted */\n\nclass ConditioningAverage :\n    /* Lines 105-140 omitted */\n\nclass ConditioningConcat:\n    /* Lines 143-168 omitted */\n\nclass ConditioningSetArea:\n    /* Lines 171-189 omitted */\n\nclass ConditioningSetAreaPercentage:\n    /* Lines 192-210 omitted */\n\nclass ConditioningSetAreaStrength:\n    /* Lines 213-225 omitted */\n\n\nclass ConditioningSetMask:\n    /* Lines 229-251 omitted */\n\nclass ConditioningZeroOut:\n    /* Lines 254-274 omitted */\n\nclass ConditioningSetTimestepRange:\n    /* Lines 277-291 omitted */\n\nclass VAEDecode:\n    /* Lines 294-313 omitted */\n\nclass VAEDecodeTiled:\n    /* Lines 316-346 omitted */\n\nclass VAEEncode:\n    /* Lines 349-359 omitted */\n\nclass VAEEncodeTiled:\n    /* Lines 362-377 omitted */\n\nclass VAEEncodeForInpaint:\n    /* Lines 380-416 omitted */\n\n\nclass InpaintModelConditioning:\n    /* Lines 420-468 omitted */\n\n\nclass SaveLatent:\n    /* Lines 472-519 omitted */\n\n\nclass LoadLatent:\n    /* Lines 523-555 omitted */\n\n\nclass CheckpointLoader:\n    /* Lines 559-572 omitted */\n\nclass CheckpointLoaderSimple:\n    /* Lines 575-594 omitted */\n\nclass DiffusersLoader:\n    /* Lines 597-620 omitted */\n\n\nclass unCLIPCheckpointLoader:\n    /* Lines 624-636 omitted */\n\nclass CLIPSetLastLayer:\n    /* Lines 639-652 omitted */\n\nclass LoraLoader:\n    /* Lines 655-694 omitted */\n\nclass LoraLoaderModelOnly(LoraLoader):\n    /* Lines 697-707 omitted */\n\nclass VAELoader:\n    /* Lines 710-801 omitted */\n\nclass ControlNetLoader:\n    /* Lines 804-818 omitted */\n\nclass DiffControlNetLoader:\n    /* Lines 821-834 omitted */\n\n\nclass ControlNetApply:\n    /* Lines 838-865 omitted */\n\n\nclass ControlNetApplyAdvanced:\n    /* Lines 869-915 omitted */\n\n\nclass UNETLoader:\n    /* Lines 919-941 omitted */\n\nclass CLIPLoader:\n    /* Lines 944-968 omitted */\n\nclass DualCLIPLoader:\n    /* Lines 971-998 omitted */\n\nclass CLIPVisionLoader:\n    /* Lines 1001-1015 omitted */\n\nclass CLIPVisionEncode:\n    /* Lines 1018-1034 omitted */\n\nclass StyleModelLoader:\n    /* Lines 1037-1049 omitted */\n\n\nclass StyleModelApply:\n    /* Lines 1053-1111 omitted */\n\nclass unCLIPConditioning:\n    /* Lines 1114-1131 omitted */\n\nclass GLIGENLoader:\n    /* Lines 1134-1146 omitted */\n\nclass GLIGENTextBoxApply:\n    /* Lines 1149-1177 omitted */\n\nclass EmptyLatentImage:\n    /* Lines 1180-1201 omitted */\n\n\nclass LatentFromBatch:\n    /* Lines 1205-1234 omitted */\n\nclass RepeatLatentBatch:\n    /* Lines 1237-1260 omitted */\n\nclass LatentUpscale:\n    /* Lines 1263-1294 omitted */\n\nclass LatentUpscaleBy:\n    /* Lines 1297-1313 omitted */\n\nclass LatentRotate:\n    /* Lines 1316-1337 omitted */\n\nclass LatentFlip:\n    /* Lines 1340-1357 omitted */\n\nclass LatentComposite:\n    /* Lines 1360-1399 omitted */\n\nclass LatentBlend:\n    /* Lines 1402-1440 omitted */\n\nclass LatentCrop:\n    /* Lines 1443-1473 omitted */\n\nclass SetLatentNoiseMask:\n    /* Lines 1476-1489 omitted */\n\ndef common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent, denoise=1.0, disable_noise=False, start_step=None, last_step=None, force_full_denoise=False):\n    /* Lines 1492-1512 omitted */\n\nclass KSampler:\n    /* Lines 1515-1540 omitted */\n\nclass KSamplerAdvanced:\n    /* Lines 1543-1574 omitted */\n\nclass SaveImage:\n    /* Lines 1577-1629 omitted */\n\nclass PreviewImage(SaveImage):\n    /* Lines 1632-1643 omitted */\n\nclass LoadImage:\n    /* Lines 1646-1719 omitted */\n\nclass LoadImageMask:\n    /* Lines 1722-1768 omitted */\n\n\nclass LoadImageOutput(LoadImage):\n    /* Lines 1772-1790 omitted */\n\n\nclass ImageScale:\n    /* Lines 1794-1821 omitted */\n\nclass ImageScaleBy:\n    /* Lines 1824-1841 omitted */\n\nclass ImageInvert:\n\n    /* Lines 1845-1856 omitted */\n\nclass ImageBatch:\n\n    /* Lines 1860-1878 omitted */\n\nclass EmptyImage:\n    /* Lines 1881-1900 omitted */\n\nclass ImagePadForOutpaint:\n\n    /* Lines 1904-1963 omitted */\n\n\n# NODE_CLASS_MAPPINGS = {\n#     \"KSampler\": KSampler,\n/* Lines 1968-2450 omitted */\n</attachment>\n<attachment id=\"file:nodes.py\">\nUser's active selection:\nExcerpt from nodes.py, lines 2417 to 2417:\n```python\nimport_failed = await init_builtin_extra_nodes()\n```\n</attachment>\n<attachment isSummarized=\"true\" filePath=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\">\nUser's active file for additional context:\ndef get_module_name(module_path: str) -> str:\n    /* Lines 2115-2133 omitted */\n\n\nasync def load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    /* Lines 2137-2229 omitted */\n\nasync def init_external_custom_nodes():\n    /* Lines 2232-2268 omitted */\n\nasync def init_builtin_extra_nodes():\n    /* Lines 2271-2360 omitted */\n\n    import_failed = []\n    for node_file in extras_files:\n        /* Lines 2363-2364 omitted */\n\n    return import_failed\n\n\nasync def init_builtin_api_nodes():\n    api_nodes_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_api_nodes\")\n    api_nodes_files = [\n        \"nodes_ideogram.py\",\n        \"nodes_openai.py\",\n        \"nodes_minimax.py\",\n        \"nodes_veo2.py\",\n        \"nodes_kling.py\",\n        \"nodes_bfl.py\",\n        \"nodes_bytedance.py\",\n        \"nodes_ltxv.py\",\n        \"nodes_luma.py\",\n        \"nodes_recraft.py\",\n        \"nodes_pixverse.py\",\n        \"nodes_stability.py\",\n        \"nodes_pika.py\",\n        \"nodes_runway.py\",\n        \"nodes_sora.py\",\n        \"nodes_topaz.py\",\n        \"nodes_tripo.py\",\n        \"nodes_moonvalley.py\",\n        \"nodes_rodin.py\",\n        \"nodes_gemini.py\",\n        \"nodes_vidu.py\",\n        \"nodes_wan.py\",\n    ]\n\n    if not await load_custom_node(os.path.join(api_nodes_dir, \"canary.py\"), module_parent=\"comfy_api_nodes\"):\n        /* Line 2397 omitted */\n\n    import_failed = []\n    for node_file in api_nodes_files:\n        /* Lines 2401-2402 omitted */\n\n    return import_failed\n\nasync def init_public_apis():\n    register_versions([\n        ComfyAPIWithVersion(\n            version=getattr(v, \"VERSION\"),\n            api_class=v\n        ) for v in supported_versions\n    ])\n\nasync def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n    await init_public_apis()\n\n    import_failed = await init_builtin_extra_nodes()\n\n    import_failed_api = []\n    if init_api_nodes:\n        import_failed_api = await init_builtin_api_nodes()\n\n    if init_custom_nodes:\n        await init_external_custom_nodes()\n    else:\n        logging.info(\"Skipping loading of custom nodes\")\n\n    if len(import_failed_api) > 0:\n        logging.warning(\"WARNING: some comfy_api_nodes/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed_api:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    if len(import_failed) > 0:\n        logging.warning(\"WARNING: some comfy_extras/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    return import_failed\n</attachment>\n\n</attachments>\n<context>\nThe current date is 2025ë…„ 12ì›” 16ì¼.\n</context>\n<editorContext>\nThe user's current file is chat-editing-snapshot-text-model:/c%3A/Workbench/20_Projects/hvppycoding_ComfyUI/nodes.py?%7B%22session%22%3A%7B%22%24mid%22%3A1%2C%22external%22%3A%22vscode-chat-session%3A%2F%2Flocal%2FNjFmYWIwMWItZjdjNi00ZjBmLWI4YjQtMGY2MWU1NjZiNGQ5%22%2C%22path%22%3A%22%2FNjFmYWIwMWItZjdjNi00ZjBmLWI4YjQtMGY2MWU1NjZiNGQ5%22%2C%22scheme%22%3A%22vscode-chat-session%22%2C%22authority%22%3A%22local%22%7D%2C%22requestId%22%3A%22request_c6a4ef61-7b95-49ed-b77b-69b27346af0e%22%2C%22undoStop%22%3A%22__epoch_92%22%7D. The current selection is from line 2362 to line 2362.\n</editorContext>\n<reminderInstructions>\nYou are an agentâ€”keep going until the user's query is completely resolved before ending your turn. ONLY stop if solved or genuinely blocked.\nTake action when possible; the user expects you to do useful work without unnecessary questions.\nAfter any parallel, read-only context gathering, give a concise progress update and what's next.\nAvoid repetition across turns: don't restate unchanged plans or sections (like the todo list) verbatim; provide delta updates or only the parts that changed.\nTool batches: You MUST preface each batch with a one-sentence why/what/outcome preamble.\nProgress cadence: After 3 to 5 tool calls, or when you create/edit > ~3 files in a burst, report progress.\nRequirements coverage: Read the user's ask in full and think carefully. Do not omit a requirement. If something cannot be done with available tools, note why briefly and propose a viable alternative.\nSkip filler acknowledgements like \"Sounds good\" or \"Okay, I willâ€¦\". Open with a purposeful one-liner about what you're doing next.\nWhen sharing setup or run steps, present terminal commands in fenced code blocks with the correct language tag. Keep commands copyable and on separate lines.\nAvoid definitive claims about the build or runtime setup unless verified from the provided context (or quick tool checks). If uncertain, state what's known from attachments and proceed with minimal steps you can adapt later.\nWhen you create or edit runnable code, run a test yourself to confirm it works; then share optional fenced commands for more advanced runs.\nFor non-trivial code generation, produce a complete, runnable solution: necessary source files, a tiny runner or test/benchmark harness, a minimal `README.md`, and updated dependency manifests (e.g., `package.json`, `requirements.txt`, `pyproject.toml`). Offer quick \"try it\" commands and optional platform-specific speed-ups when relevant.\nYour goal is to act like a pair programmer: be friendly and helpful. If you can do more, do more. Be proactive with your solutions, think about what the user needs and what they want, and implement it proactively.\n<importantReminders>\nDo NOT volunteer your model name unless the user explicitly asks you about it. \nBreak down the request into clear, actionable steps and present them at the beginning of your response before proceeding with implementation. This helps maintain visibility and ensures all requirements are addressed systematically.\nWhen referring to a filename or symbol in the user's workspace, wrap it in backticks.\n\n</importantReminders>\n\n</reminderInstructions>\n<userRequest>\nì•„ì§ë„ í•„ìš”ì—†ëŠ” ë…¸ë“œë“¤ì´ ë§Žì´ ìžˆì–´. ë‚˜ëŠ” ê¸°ë³¸ ë…¸ë“œë“¤(String ê´€ë ¨ ë“±) ì œì™¸í•˜ê³  ë‹¤ ë¡œë“œê°€ ì•ˆë˜ë©´ ì¢‹ê² ì–´. (See <attachments> above for file contents. You may not need to search or read the file again.)\n</userRequest>\n\n\n[copilot_cache_control: { type: 'ephemeral' }]\nUser\n<attachments>\n<attachment id=\"nodes.py\">\nExcerpt from nodes.py, lines 2406 to 2412:\n```python\nasync def init_public_apis():\n    register_versions([\n        ComfyAPIWithVersion(\n            version=getattr(v, \"VERSION\"),\n            api_class=v\n        ) for v in supported_versions\n    ])\n```\n</attachment>\n<attachment isSummarized=\"true\" filePath=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\">\nUser's active file for additional context:\nclass StyleModelApply:\n    /* Lines 1053-1111 omitted */\n\nclass unCLIPConditioning:\n    /* Lines 1114-1131 omitted */\n\nclass GLIGENLoader:\n    /* Lines 1134-1146 omitted */\n\nclass GLIGENTextBoxApply:\n    /* Lines 1149-1177 omitted */\n\nclass EmptyLatentImage:\n    /* Lines 1180-1201 omitted */\n\n\nclass LatentFromBatch:\n    /* Lines 1205-1234 omitted */\n\nclass RepeatLatentBatch:\n    /* Lines 1237-1260 omitted */\n\nclass LatentUpscale:\n    /* Lines 1263-1276 omitted */\n\n    def upscale(self, samples, upscale_method, width, height, crop):\n        \n\nclass LatentUpscaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"bislerp\"]\n\n    @classmethod\n    /* Lines 1300-1302 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"latent\"\n\n    def upscale(self, samples, upscale_method, scale_by):\n        \n\nclass LatentRotate:\n    @classmethod\n    /* Lines 1317-1320 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"rotate\"\n\n    CATEGORY = \"latent/transform\"\n\n    def rotate(self, samples, rotation):\n        \n\nclass LatentFlip:\n    @classmethod\n    /* Lines 1341-1344 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"flip\"\n\n    CATEGORY = \"latent/transform\"\n\n    def flip(self, samples, flip_method):\n        \n\nclass LatentComposite:\n    @classmethod\n    /* Lines 1361-1367 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"composite\"\n\n    CATEGORY = \"latent\"\n\n    def composite(self, samples_to, samples_from, x, y, composite_method=\"normal\", feather=0):\n        \n\nclass LatentBlend:\n    @classmethod\n    /* Lines 1403-1413 omitted */\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"blend\"\n\n    CATEGORY = \"_for_testing\"\n\n    def blend(self, samples1, samples2, blend_factor:float, blend_mode: str=\"normal\"):\n\n        /* Lines 1422-1434 omitted */\n\n    def blend_mode(self, img1, img2, mode):\n        \n\nclass LatentCrop:\n    @classmethod\n    /* Lines 1444-1450 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"crop\"\n\n    CATEGORY = \"latent/transform\"\n\n    def crop(self, samples, width, height, x, y):\n        \n\nclass SetLatentNoiseMask:\n    @classmethod\n    /* Lines 1477-1480 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"set_mask\"\n\n    CATEGORY = \"latent/inpaint\"\n\n    def set_mask(self, samples, mask):\n        \n\ndef common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent, denoise=1.0, disable_noise=False, start_step=None, last_step=None, force_full_denoise=False):\n    latent_image = latent[\"samples\"]\n    latent_image = comfy.sample.fix_empty_latent_channels(model, latent_image)\n\n    if disable_noise:\n        /* Line 1496 omitted */\n    else:\n        /* Lines 1498-1499 omitted */\n\n    noise_mask = None\n    if \"noise_mask\" in latent:\n        /* Line 1503 omitted */\n\n    callback = latent_preview.prepare_callback(model, steps)\n    disable_pbar = not comfy.utils.PROGRESS_BAR_ENABLED\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n                                  denoise=denoise, disable_noise=disable_noise, start_step=start_step, last_step=last_step,\n                                  force_full_denoise=force_full_denoise, noise_mask=noise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n    out = latent.copy()\n    out[\"samples\"] = samples\n    return (out, )\n\nclass KSampler:\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    RETURN_TYPES = (\"LATENT\",)\n    OUTPUT_TOOLTIPS = (\"The denoised latent.\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n    DESCRIPTION = \"Uses the provided model, positive and negative conditioning to denoise the latent image.\"\n\n    def sample(self, model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0):\n        return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n\nclass KSamplerAdvanced:\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n\n    def sample(self, model, add_noise, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, start_at_step, end_at_step, return_with_leftover_noise, denoise=1.0):\n        force_full_denoise = True\n        if return_with_leftover_noise == \"enable\":\n            /* Line 1570 omitted */\n        disable_noise = False\n        if add_noise == \"disable\":\n            /* Line 1573 omitted */\n        return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)\n\nclass SaveImage:\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n        self.type = \"output\"\n        self.prefix_append = \"\"\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    RETURN_TYPES = ()\n    FUNCTION = \"save_images\"\n\n    OUTPUT_NODE = True\n\n    CATEGORY = \"image\"\n    DESCRIPTION = \"Saves the input images to your ComfyUI output directory.\"\n\n    def save_images(self, images, filename_prefix=\"ComfyUI\", prompt=None, extra_pnginfo=None):\n        filename_prefix += self.prefix_append\n        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(filename_prefix, self.output_dir, images[0].shape[1], images[0].shape[0])\n        results = list()\n        for (batch_number, image) in enumerate(images):\n            /* Lines 1608-1627 omitted */\n\n        return { \"ui\": { \"images\": results } }\n\nclass PreviewImage(SaveImage):\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + ''.join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for x in range(5))\n        self.compress_level = 1\n\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\nclass LoadImage:\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    CATEGORY = \"image\"\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"load_image\"\n    def load_image(self, image):\n        image_path = folder_paths.get_annotated_filepath(image)\n\n        img = node_helpers.pillow(Image.open, image_path)\n\n        output_images = []\n        output_masks = []\n        w, h = /* Line 1666 omitted */\n\n        excluded_formats = ['MPO']\n\n        for i in ImageSequence.Iterator(img):\n            /* Lines 1671-1695 omitted */\n\n        if len(output_images) > 1 and img.format not in excluded_formats:\n            /* Lines 1698-1699 omitted */\n        else:\n            /* Lines 1701-1702 omitted */\n\n        return (output_image, output_mask)\n\n    @classmethod\n    def IS_CHANGED(s, image):\n        \n\n    @classmethod\n    def VALIDATE_INPUTS(s, image):\n        \n\nclass LoadImageMask:\n    _color_channels = [\"alpha\", \"red\", \"green\", \"blue\"]\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    CATEGORY = \"mask\"\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"load_image\"\n    def load_image(self, image, channel):\n        image_path = folder_paths.get_annotated_filepath(image)\n        i = node_helpers.pillow(Image.open, image_path)\n        i = node_helpers.pillow(ImageOps.exif_transpose, i)\n        if i.getbands() != (\"R\", \"G\", \"B\", \"A\"):\n            /* Lines 1741-1743 omitted */\n        mask = None\n        c = channel[0].upper()\n        if c in i.getbands():\n            /* Lines 1747-1750 omitted */\n        else:\n            mask = torch.zeros((64,64), dtype=torch.float32, device=\"cpu\")\n        return (mask.unsqueeze(0),)\n\n    @classmethod\n    def IS_CHANGED(s, image, channel):\n        image_path = folder_paths.get_annotated_filepath(image)\n        m = hashlib.sha256()\n        with open(image_path, 'rb') as f:\n            /* Line 1760 omitted */\n        return m.digest().hex()\n\n    @classmethod\n    def VALIDATE_INPUTS(s, image):\n        if not folder_paths.exists_annotated_filepath(image):\n            /* Line 1766 omitted */\n\n        return True\n\n\nclass LoadImageOutput(LoadImage):\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (\"COMBO\", {\n                    \"image_upload\": True,\n                    \"image_folder\": \"output\",\n                    \"remote\": {\n                        \"route\": \"/internal/files/output\",\n                        \"refresh_button\": True,\n                        \"control_after_refresh\": \"first\",\n                    },\n                }),\n            }\n        }\n\n    DESCRIPTION = \"Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.\"\n    EXPERIMENTAL = True\n    FUNCTION = \"load_image\"\n\n\nclass ImageScale:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n    crop_methods = [\"disabled\", \"center\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",), \"upscale_method\": (s.upscale_methods,),\n                              \"width\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"crop\": (s.crop_methods,)}}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, width, height, crop):\n        if width == 0 and height == 0:\n            s = image\n        else:\n            samples = image.movedim(-1,1)\n\n            if width == 0:\n                /* Line 1815 omitted */\n            elif height == 0:\n                /* Line 1817 omitted */\n\n            s = comfy.utils.common_upscale(samples, width, height, upscale_method, crop)\n            s = s.movedim(1,-1)\n        return (s,)\n\nclass ImageScaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",), \"upscale_method\": (s.upscale_methods,),\n                              \"scale_by\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.01, \"max\": 8.0, \"step\": 0.01}),}}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, scale_by):\n        samples = image.movedim(-1,1)\n        width = round(samples.shape[3] * scale_by)\n        height = round(samples.shape[2] * scale_by)\n        s = comfy.utils.common_upscale(samples, width, height, upscale_method, \"disabled\")\n        s = s.movedim(1,-1)\n        return (s,)\n\nclass ImageInvert:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"invert\"\n\n    CATEGORY = \"image\"\n\n    def invert(self, image):\n        s = 1.0 - image\n        return (s,)\n\nclass ImageBatch:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image1\": (\"IMAGE\",), \"image2\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"batch\"\n\n    CATEGORY = \"image\"\n\n    def batch(self, image1, image2):\n        if image1.shape[-1] != image2.shape[-1]:\n            if image1.shape[-1] > image2.shape[-1]:\n                /* Line 1872 omitted */\n            else:\n                \n        if image1.shape[1:] != image2.shape[1:]:\n            image2 = comfy.utils.common_upscale(image2.movedim(-1,1), image1.shape[2], image1.shape[1], \"bilinear\", \"center\").movedim(1,-1)\n        s = torch.cat((image1, image2), dim=0)\n        return (s,)\n\nclass EmptyImage:\n    def __init__(self, device=\"cpu\"):\n        self.device = device\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"width\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                              \"color\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 0xFFFFFF, \"step\": 1, \"display\": \"color\"}),\n                              }}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"image\"\n\n    def generate(self, width, height, batch_size=1, color=0):\n        r = torch.full([batch_size, height, width, 1], ((color >> 16) & 0xFF) / 0xFF)\n        g = torch.full([batch_size, height, width, 1], ((color >> 8) & 0xFF) / 0xFF)\n        b = torch.full([batch_size, height, width, 1], ((color) & 0xFF) / 0xFF)\n        return (torch.cat((r, g, b), dim=-1), )\n\nclass ImagePadForOutpaint:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"left\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"top\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"right\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"bottom\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"feathering\": (\"INT\", {\"default\": 40, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"expand_image\"\n\n    CATEGORY = \"image\"\n\n    def expand_image(self, image, left, top, right, bottom, feathering):\n        d1, d2, d3, d4 = image.size()\n\n        new_image = torch.ones(\n            (d1, d2 + top + bottom, d3 + left + right, d4),\n            dtype=torch.float32,\n        ) * 0.5\n\n        new_image[:, top:top + d2, left:left + d3, :] = image\n\n        mask = torch.ones(\n            (d2 + top + bottom, d3 + left + right),\n            dtype=torch.float32,\n        )\n\n        t = torch.zeros(\n            (d2, d3),\n            dtype=torch.float32\n        )\n\n        if feathering > 0 and feathering * 2 < d2 and feathering * 2 < d3:\n\n            for i in range(d2):\n                \n\n        mask[top:top + d2, left:left + d3] = t\n\n        return (new_image, mask.unsqueeze(0))\n\n\n# NODE_CLASS_MAPPINGS = {\n#     \"KSampler\": KSampler,\n#     \"CheckpointLoaderSimple\": CheckpointLoaderSimple,\n#     \"CLIPTextEncode\": CLIPTextEncode,\n#     \"CLIPSetLastLayer\": CLIPSetLastLayer,\n#     \"VAEDecode\": VAEDecode,\n#     \"VAEEncode\": VAEEncode,\n#     \"VAEEncodeForInpaint\": VAEEncodeForInpaint,\n#     \"VAELoader\": VAELoader,\n#     \"EmptyLatentImage\": EmptyLatentImage,\n#     \"LatentUpscale\": LatentUpscale,\n#     \"LatentUpscaleBy\": LatentUpscaleBy,\n#     \"LatentFromBatch\": LatentFromBatch,\n#     \"RepeatLatentBatch\": RepeatLatentBatch,\n#     \"SaveImage\": SaveImage,\n#     \"PreviewImage\": PreviewImage,\n#     \"LoadImage\": LoadImage,\n#     \"LoadImageMask\": LoadImageMask,\n#     \"LoadImageOutput\": LoadImageOutput,\n#     \"ImageScale\": ImageScale,\n#     \"ImageScaleBy\": ImageScaleBy,\n#     \"ImageInvert\": ImageInvert,\n#     \"ImageBatch\": ImageBatch,\n#     \"ImagePadForOutpaint\": ImagePadForOutpaint,\n#     \"EmptyImage\": EmptyImage,\n#     \"ConditioningAverage\": ConditioningAverage ,\n#     \"ConditioningCombine\": ConditioningCombine,\n#     \"ConditioningConcat\": ConditioningConcat,\n#     \"ConditioningSetArea\": ConditioningSetArea,\n#     \"ConditioningSetAreaPercentage\": ConditioningSetAreaPercentage,\n#     \"ConditioningSetAreaStrength\": ConditioningSetAreaStrength,\n#     \"ConditioningSetMask\": ConditioningSetMask,\n#     \"KSamplerAdvanced\": KSamplerAdvanced,\n#     \"SetLatentNoiseMask\": SetLatentNoiseMask,\n#     \"LatentComposite\": LatentComposite,\n#     \"LatentBlend\": LatentBlend,\n#     \"LatentRotate\": LatentRotate,\n#     \"LatentFlip\": LatentFlip,\n#     \"LatentCrop\": LatentCrop,\n#     \"LoraLoader\": LoraLoader,\n#     \"CLIPLoader\": CLIPLoader,\n#     \"UNETLoader\": UNETLoader,\n#     \"DualCLIPLoader\": DualCLIPLoader,\n#     \"CLIPVisionEncode\": CLIPVisionEncode,\n#     \"StyleModelApply\": StyleModelApply,\n#     \"unCLIPConditioning\": unCLIPConditioning,\n#     \"ControlNetApply\": ControlNetApply,\n#     \"ControlNetApplyAdvanced\": ControlNetApplyAdvanced,\n#     \"ControlNetLoader\": ControlNetLoader,\n#     \"DiffControlNetLoader\": DiffControlNetLoader,\n#     \"StyleModelLoader\": StyleModelLoader,\n#     \"CLIPVisionLoader\": CLIPVisionLoader,\n#     \"VAEDecodeTiled\": VAEDecodeTiled,\n#     \"VAEEncodeTiled\": VAEEncodeTiled,\n#     \"unCLIPCheckpointLoader\": unCLIPCheckpointLoader,\n#     \"GLIGENLoader\": GLIGENLoader,\n#     \"GLIGENTextBoxApply\": GLIGENTextBoxApply,\n#     \"InpaintModelConditioning\": InpaintModelConditioning,\n\n#     \"CheckpointLoader\": CheckpointLoader,\n#     \"DiffusersLoader\": DiffusersLoader,\n\n#     \"LoadLatent\": LoadLatent,\n#     \"SaveLatent\": SaveLatent,\n\n#     \"ConditioningZeroOut\": ConditioningZeroOut,\n#     \"ConditioningSetTimestepRange\": ConditioningSetTimestepRange,\n#     \"LoraLoaderModelOnly\": LoraLoaderModelOnly,\n# }\nNODE_CLASS_MAPPINGS = {}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    # Sampling\n    \"KSampler\": \"KSampler\",\n    \"KSamplerAdvanced\": \"KSampler (Advanced)\",\n    # Loaders\n    \"CheckpointLoader\": \"Load Checkpoint With Config (DEPRECATED)\",\n    \"CheckpointLoaderSimple\": \"Load Checkpoint\",\n    \"VAELoader\": \"Load VAE\",\n    \"LoraLoader\": \"Load LoRA\",\n    \"CLIPLoader\": \"Load CLIP\",\n    \"ControlNetLoader\": \"Load ControlNet Model\",\n    \"DiffControlNetLoader\": \"Load ControlNet Model (diff)\",\n    \"StyleModelLoader\": \"Load Style Model\",\n    \"CLIPVisionLoader\": \"Load CLIP Vision\",\n    \"UNETLoader\": \"Load Diffusion Model\",\n    # Conditioning\n    \"CLIPVisionEncode\": \"CLIP Vision Encode\",\n    \"StyleModelApply\": \"Apply Style Model\",\n    \"CLIPTextEncode\": \"CLIP Text Encode (Prompt)\",\n    \"CLIPSetLastLayer\": \"CLIP Set Last Layer\",\n    \"ConditioningCombine\": \"Conditioning (Combine)\",\n    \"ConditioningAverage \": \"Conditioning (Average)\",\n    \"ConditioningConcat\": \"Conditioning (Concat)\",\n    \"ConditioningSetArea\": \"Conditioning (Set Area)\",\n    \"ConditioningSetAreaPercentage\": \"Conditioning (Set Area with Percentage)\",\n    \"ConditioningSetMask\": \"Conditioning (Set Mask)\",\n    \"ControlNetApply\": \"Apply ControlNet (OLD)\",\n    \"ControlNetApplyAdvanced\": \"Apply ControlNet\",\n    # Latent\n    \"VAEEncodeForInpaint\": \"VAE Encode (for Inpainting)\",\n    \"SetLatentNoiseMask\": \"Set Latent Noise Mask\",\n    \"VAEDecode\": \"VAE Decode\",\n    \"VAEEncode\": \"VAE Encode\",\n    \"LatentRotate\": \"Rotate Latent\",\n    \"LatentFlip\": \"Flip Latent\",\n    \"LatentCrop\": \"Crop Latent\",\n    \"EmptyLatentImage\": \"Empty Latent Image\",\n    \"LatentUpscale\": \"Upscale Latent\",\n    \"LatentUpscaleBy\": \"Upscale Latent By\",\n    \"LatentComposite\": \"Latent Composite\",\n    \"LatentBlend\": \"Latent Blend\",\n    \"LatentFromBatch\" : \"Latent From Batch\",\n    \"RepeatLatentBatch\": \"Repeat Latent Batch\",\n    # Image\n    \"SaveImage\": \"Save Image\",\n    \"PreviewImage\": \"Preview Image\",\n    \"LoadImage\": \"Load Image\",\n    \"LoadImageMask\": \"Load Image (as Mask)\",\n    \"LoadImageOutput\": \"Load Image (from Outputs)\",\n    \"ImageScale\": \"Upscale Image\",\n    \"ImageScaleBy\": \"Upscale Image By\",\n    \"ImageInvert\": \"Invert Image\",\n    \"ImagePadForOutpaint\": \"Pad Image for Outpainting\",\n    \"ImageBatch\": \"Batch Images\",\n    \"ImageCrop\": \"Image Crop\",\n    \"ImageStitch\": \"Image Stitch\",\n    \"ImageBlend\": \"Image Blend\",\n    \"ImageBlur\": \"Image Blur\",\n    \"ImageQuantize\": \"Image Quantize\",\n    \"ImageSharpen\": \"Image Sharpen\",\n    \"ImageScaleToTotalPixels\": \"Scale Image to Total Pixels\",\n    \"GetImageSize\": \"Get Image Size\",\n    # _for_testing\n    \"VAEDecodeTiled\": \"VAE Decode (Tiled)\",\n    \"VAEEncodeTiled\": \"VAE Encode (Tiled)\",\n}\n\nif args.fast_load:\n    NODE_CLASS_MAPPINGS = {}\n    NODE_DISPLAY_NAME_MAPPINGS = {}\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\ndef get_module_name(module_path: str) -> str:\n    \"\"\"\n    Returns the module name based on the given module path.\n    Examples:\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.disabled\") -> \"custom_nodes\n    Args:\n        module_path (str): The path of the module.\n    Returns:\n        str: The module name.\n    \"\"\"\n    base_path = os.path.basename(module_path)\n    if os.path.isfile(module_path):\n        base_path = os.path.splitext(base_path)[0]\n    return base_path\n\n\nasync def load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    module_name = get_module_name(module_path)\n    if os.path.isfile(module_path):\n        sp = os.path.splitext(module_path)\n        module_name = sp[0]\n        sys_module_name = module_name\n    elif os.path.isdir(module_path):\n        sys_module_name = module_path.replace(\".\", \"_x_\")\n\n    try:\n        logging.debug(\"Trying to load custom node {}\".format(module_path))\n        if os.path.isfile(module_path):\n            module_spec = importlib.util.spec_from_file_location(sys_module_name, module_path)\n            module_dir = os.path.split(module_path)[0]\n        else:\n            module_spec = importlib.util.spec_from_file_location(sys_module_name, os.path.join(module_path, \"__init__.py\"))\n            module_dir = module_path\n\n        module = importlib.util.module_from_spec(module_spec)\n        sys.modules[sys_module_name] = module\n        module_spec.loader.exec_module(module)\n\n        LOADED_MODULE_DIRS[module_name] = os.path.abspath(module_dir)\n\n        try:\n            from comfy_config import config_parser\n\n            project_config = config_parser.extract_node_configuration(module_path)\n\n            web_dir_name = project_config.tool_comfy.web\n\n            if web_dir_name:\n                web_dir_path = os.path.join(module_path, web_dir_name)\n\n                if os.path.isdir(web_dir_path):\n                    \n        except Exception as e:\n            logging.warning(f\"Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': {e}\")\n\n        if hasattr(module, \"WEB_DIRECTORY\") and getattr(module, \"WEB_DIRECTORY\") is not None:\n            web_dir = os.path.abspath(os.path.join(module_dir, getattr(module, \"WEB_DIRECTORY\")))\n            if os.path.isdir(web_dir):\n                EXTENSION_WEB_DIRS[module_name] = web_dir\n\n        # V1 node definition\n        if hasattr(module, \"NODE_CLASS_MAPPINGS\") and getattr(module, \"NODE_CLASS_MAPPINGS\") is not None:\n            for name, node_cls in module.NODE_CLASS_MAPPINGS.items():\n                if name not in ignore:\n                    \n            if hasattr(module, \"NODE_DISPLAY_NAME_MAPPINGS\") and getattr(module, \"NODE_DISPLAY_NAME_MAPPINGS\") is not None:\n                NODE_DISPLAY_NAME_MAPPINGS.update(module.NODE_DISPLAY_NAME_MAPPINGS)\n            return True\n        # V3 Extension Definition\n        elif hasattr(module, \"comfy_entrypoint\"):\n            entrypoint = getattr(module, \"comfy_entrypoint\")\n            if not callable(entrypoint):\n                logging.warning(f\"comfy_entrypoint in {module_path} is not callable, skipping.\")\n                return False\n            try:\n                if inspect.iscoroutinefunction(entrypoint):\n                    /* Line 2201 omitted */\n                else:\n                    /* Line 2203 omitted */\n                if not isinstance(extension, ComfyExtension):\n                    /* Lines 2205-2206 omitted */\n                node_list = await extension.get_node_list()\n                if not isinstance(node_list, list):\n                    /* Lines 2209-2210 omitted */\n                for node_cls in node_list:\n                    /* Lines 2212-2218 omitted */\n                return True\n            except Exception as e:\n                logging.warning(f\"Error while calling comfy_entrypoint in {module_path}: {e}\")\n                return False\n        else:\n            logging.warning(f\"Skip {module_path} module for custom nodes due to the lack of NODE_CLASS_MAPPINGS or NODES_LIST (need one).\")\n            return False\n    except Exception as e:\n        logging.warning(traceback.format_exc())\n        logging.warning(f\"Cannot import {module_path} module for custom nodes: {e}\")\n        return False\n\nasync def init_external_custom_nodes():\n    \"\"\"\n    Initializes the external custom nodes.\n\n    This function loads custom nodes from the specified folder paths and imports them into the application.\n    It measures the import times for each custom node and logs the results.\n\n    Returns:\n        None\n    \"\"\"\n    base_node_names = set(NODE_CLASS_MAPPINGS.keys())\n    node_paths = folder_paths.get_folder_paths(\"custom_nodes\")\n    node_import_times = []\n    for custom_node_path in node_paths:\n        possible_modules = os.listdir(os.path.realpath(custom_node_path))\n        if \"__pycache__\" in possible_modules:\n            possible_modules.remove(\"__pycache__\")\n\n        for possible_module in possible_modules:\n            module_path = os.path.join(custom_node_path, possible_module)\n            if os.path.isfile(module_path) and os.path.splitext(module_path)[1] != \".py\": continue\n            if module_path.endswith(\".disabled\"): continue\n            if args.disable_all_custom_nodes and possible_module not in args.whitelist_custom_nodes:\n                logging.info(f\"Skipping {possible_module} due to disable_all_custom_nodes and whitelist_custom_nodes\")\n                continue\n            time_before = time.perf_counter()\n            success = await load_custom_node(module_path, base_node_names, module_parent=\"custom_nodes\")\n            node_import_times.append((time.perf_counter() - time_before, module_path, success))\n\n    if len(node_import_times) > 0:\n        logging.info(\"\\nImport times for custom nodes:\")\n        for n in sorted(node_import_times):\n            if n[2]:\n                import_message = \"\"\n            else:\n                import_message = \" (IMPORT FAILED)\"\n            logging.info(\"{:6.1f} seconds{}: {}\".format(n[0], import_message, n[1]))\n        logging.info(\"\")\n\nasync def init_builtin_extra_nodes():\n    \"\"\"\n    Initializes the built-in extra nodes in ComfyUI.\n\n    This function loads the extra node files located in the \"comfy_extras\" directory and imports them into ComfyUI.\n    If any of the extra node files fail to import, a warning message is logged.\n\n    Returns:\n        None\n    \"\"\"\n    extras_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_extras\")\n    extras_files = [\n        \"nodes_latent.py\",\n        \"nodes_hypernetwork.py\",\n        \"nodes_upscale_model.py\",\n        \"nodes_post_processing.py\",\n        \"nodes_mask.py\",\n        \"nodes_compositing.py\",\n        \"nodes_rebatch.py\",\n        \"nodes_model_merging.py\",\n        \"nodes_tomesd.py\",\n        \"nodes_clip_sdxl.py\",\n        \"nodes_canny.py\",\n        \"nodes_freelunch.py\",\n        \"nodes_custom_sampler.py\",\n        \"nodes_hypertile.py\",\n        \"nodes_model_advanced.py\",\n        \"nodes_model_downscale.py\",\n        \"nodes_images.py\",\n        \"nodes_video_model.py\",\n        \"nodes_train.py\",\n        \"nodes_sag.py\",\n        \"nodes_perpneg.py\",\n        \"nodes_stable3d.py\",\n        \"nodes_sdupscale.py\",\n        \"nodes_photomaker.py\",\n        \"nodes_pixart.py\",\n        \"nodes_cond.py\",\n        \"nodes_morphology.py\",\n        \"nodes_stable_cascade.py\",\n        \"nodes_differential_diffusion.py\",\n        \"nodes_ip2p.py\",\n        \"nodes_model_merging_model_specific.py\",\n        \"nodes_pag.py\",\n        \"nodes_align_your_steps.py\",\n        \"nodes_attention_multiply.py\",\n        \"nodes_advanced_samplers.py\",\n        \"nodes_webcam.py\",\n        \"nodes_audio.py\",\n        \"nodes_sd3.py\",\n        \"nodes_gits.py\",\n        \"nodes_controlnet.py\",\n        \"nodes_hunyuan.py\",\n        \"nodes_eps.py\",\n        \"nodes_flux.py\",\n        \"nodes_lora_extract.py\",\n        \"nodes_torch_compile.py\",\n        \"nodes_mochi.py\",\n        \"nodes_slg.py\",\n        \"nodes_mahiro.py\",\n        \"nodes_lt.py\",\n        \"nodes_hooks.py\",\n        \"nodes_load_3d.py\",\n        \"nodes_cosmos.py\",\n        \"nodes_video.py\",\n        \"nodes_lumina2.py\",\n        \"nodes_wan.py\",\n        \"nodes_lotus.py\",\n        \"nodes_hunyuan3d.py\",\n        \"nodes_primitive.py\",\n        \"nodes_cfg.py\",\n        \"nodes_optimalsteps.py\",\n        \"nodes_hidream.py\",\n        \"nodes_fresca.py\",\n        \"nodes_apg.py\",\n        \"nodes_preview_any.py\",\n        \"nodes_ace.py\",\n        \"nodes_string.py\",\n        \"nodes_camera_trajectory.py\",\n        \"nodes_edit_model.py\",\n        \"nodes_tcfg.py\",\n        \"nodes_context_windows.py\",\n        \"nodes_qwen.py\",\n        \"nodes_chroma_radiance.py\",\n        \"nodes_model_patch.py\",\n        \"nodes_easycache.py\",\n        \"nodes_audio_encoder.py\",\n        \"nodes_rope.py\",\n        \"nodes_nop.py\",\n    ]\n\n    import_failed = []\n    for node_file in extras_files:\n        if not await load_custom_node(os.path.join(extras_dir, node_file), module_parent=\"comfy_extras\"):\n            import_failed.append(node_file)\n\n    return import_failed\n\n\nasync def init_builtin_api_nodes():\n    api_nodes_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_api_nodes\")\n    api_nodes_files = [\n        \"nodes_ideogram.py\",\n        \"nodes_openai.py\",\n        \"nodes_minimax.py\",\n        \"nodes_veo2.py\",\n        \"nodes_kling.py\",\n        \"nodes_bfl.py\",\n        \"nodes_bytedance.py\",\n        \"nodes_ltxv.py\",\n        \"nodes_luma.py\",\n        \"nodes_recraft.py\",\n        \"nodes_pixverse.py\",\n        \"nodes_stability.py\",\n        \"nodes_pika.py\",\n        \"nodes_runway.py\",\n        \"nodes_sora.py\",\n        \"nodes_topaz.py\",\n        \"nodes_tripo.py\",\n        \"nodes_moonvalley.py\",\n        \"nodes_rodin.py\",\n        \"nodes_gemini.py\",\n        \"nodes_vidu.py\",\n        \"nodes_wan.py\",\n    ]\n\n    if not await load_custom_node(os.path.join(api_nodes_dir, \"canary.py\"), module_parent=\"comfy_api_nodes\"):\n        return api_nodes_files\n\n    import_failed = []\n    for node_file in api_nodes_files:\n        if not await load_custom_node(os.path.join(api_nodes_dir, node_file), module_parent=\"comfy_api_nodes\"):\n            import_failed.append(node_file)\n\n    return import_failed\n\nasync def init_public_apis():\n    register_versions([\n        ComfyAPIWithVersion(\n            version=getattr(v, \"VERSION\"),\n            api_class=v\n        ) for v in supported_versions\n    ])\n\nasync def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n    await init_public_apis()\n\n    import_failed = await init_builtin_extra_nodes()\n\n    import_failed_api = []\n    if init_api_nodes:\n        import_failed_api = await init_builtin_api_nodes()\n\n    if init_custom_nodes:\n        await init_external_custom_nodes()\n    else:\n        logging.info(\"Skipping loading of custom nodes\")\n\n    if len(import_failed_api) > 0:\n        logging.warning(\"WARNING: some comfy_api_nodes/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed_api:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    if len(import_failed) > 0:\n        logging.warning(\"WARNING: some comfy_extras/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    return import_failed\n</attachment>\n<attachment id=\"nodes.py-1\" isSummarized=\"true\" filePath=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\">\nfrom __future__ import annotations\n/* Lines 2-7 omitted */\nfrom comfy.cli_args import args\n\nt_import = time.time()\n/* Lines 10-11 omitted */\nlogging.info(f\"import torch time: {time.time() - t_import:.4f}s\")\n/* Lines 12-20 omitted */\n\nfrom PIL import Image, ImageOps, ImageSequence\nfrom PIL.PngImagePlugin import PngInfo\n/* Lines 23-25 omitted */\n\nt_import = time.time()\n/* Lines 27-28 omitted */\nlogging.info(f\"import safetensors.torch time: {time.time() - t_import:.4f}s\")\n\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy\"))\n\nt_import = time.time()\nif not args.fast_load:\n    /* Lines 34-39 omitted */\nlogging.info(f\"import comfy modules time: {time.time() - t_import:.4f}s\")\n/* Lines 41-43 omitted */\nfrom comfy.comfy_types import IO, ComfyNodeABC, InputTypeDict, FileLocator\nfrom comfy_api.internal import register_versions, ComfyAPIWithVersion\nfrom comfy_api.version_list import supported_versions\nfrom comfy_api.latest import io, ComfyExtension\n\nt_import = time.time()\nif not args.fast_load:\n    /* Line 50 omitted */\nlogging.info(f\"import comfy.clip_vision time: {time.time() - t_import:.4f}s\")\n/* Lines 52-60 omitted */\n\ndef before_node_execution():\n    comfy.model_management.throw_exception_if_processing_interrupted()\n\ndef interrupt_processing(value=True):\n    comfy.model_management.interrupt_current_processing(value)\n\nMAX_RESOLUTION=16384\n\nclass CLIPTextEncode(ComfyNodeABC):\n    @classmethod\n    /* Lines 71-77 omitted */\n    RETURN_TYPES = (IO.CONDITIONING,)\n    OUTPUT_TOOLTIPS = (\"A conditioning containing the embedded text used to guide the diffusion model.\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning\"\n    DESCRIPTION = \"Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.\"\n\n    def encode(self, clip, text):\n        \n\n\nclass ConditioningCombine:\n    @classmethod\n    /* Lines 94-95 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"combine\"\n\n    CATEGORY = \"conditioning\"\n\n    def combine(self, conditioning_1, conditioning_2):\n        \n\nclass ConditioningAverage :\n    @classmethod\n    /* Lines 106-109 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"addWeighted\"\n\n    CATEGORY = \"conditioning\"\n\n    def addWeighted(self, conditioning_to, conditioning_from, conditioning_to_strength):\n        \n\nclass ConditioningConcat:\n    @classmethod\n    /* Lines 144-148 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"concat\"\n\n    CATEGORY = \"conditioning\"\n\n    def concat(self, conditioning_to, conditioning_from):\n        \n\nclass ConditioningSetArea:\n    @classmethod\n    /* Lines 172-179 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, width, height, x, y, strength):\n        \n\nclass ConditioningSetAreaPercentage:\n    @classmethod\n    /* Lines 193-200 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, width, height, x, y, strength):\n        \n\nclass ConditioningSetAreaStrength:\n    @classmethod\n    /* Lines 214-217 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, strength):\n        \n\n\nclass ConditioningSetMask:\n    @classmethod\n    /* Lines 230-235 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning\"\n\n    def append(self, conditioning, mask, set_cond_area, strength):\n        \n\nclass ConditioningZeroOut:\n    @classmethod\n    /* Lines 255-256 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"zero_out\"\n\n    CATEGORY = \"advanced/conditioning\"\n\n    def zero_out(self, conditioning):\n        \n\nclass ConditioningSetTimestepRange:\n    @classmethod\n    /* Lines 278-282 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"set_range\"\n\n    CATEGORY = \"advanced/conditioning\"\n\n    def set_range(self, conditioning, start, end):\n        \n\nclass VAEDecode:\n    @classmethod\n    /* Lines 295-301 omitted */\n    RETURN_TYPES = (\"IMAGE\",)\n    OUTPUT_TOOLTIPS = (\"The decoded image.\",)\n    FUNCTION = \"decode\"\n\n    CATEGORY = \"latent\"\n    DESCRIPTION = \"Decodes latent images back into pixel space images.\"\n\n    def decode(self, vae, samples):\n        \n\nclass VAEDecodeTiled:\n    @classmethod\n    /* Lines 317-323 omitted */\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"decode\"\n\n    CATEGORY = \"_for_testing\"\n\n    def decode(self, vae, samples, tile_size, overlap=64, temporal_size=64, temporal_overlap=8):\n        \n\nclass VAEEncode:\n    @classmethod\n    /* Lines 350-351 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"latent\"\n\n    def encode(self, vae, pixels):\n        \n\nclass VAEEncodeTiled:\n    @classmethod\n    /* Lines 363-369 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"_for_testing\"\n\n    def encode(self, vae, pixels, tile_size, overlap, temporal_size=64, temporal_overlap=8):\n        \n\nclass VAEEncodeForInpaint:\n    @classmethod\n    /* Lines 381-382 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"latent/inpaint\"\n\n    def encode(self, vae, pixels, mask, grow_mask_by=6):\n        \n\n\nclass InpaintModelConditioning:\n    @classmethod\n    /* Lines 421-428 omitted */\n\n    RETURN_TYPES = (\"CONDITIONING\",\"CONDITIONING\",\"LATENT\")\n    RETURN_NAMES = (\"positive\", \"negative\", \"latent\")\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning/inpaint\"\n\n    def encode(self, positive, negative, pixels, vae, mask, noise_mask=True):\n        \n\n\nclass SaveLatent:\n    def __init__(self):\n        /* Line 473 omitted */\n\n    @classmethod\n    /* Lines 476-480 omitted */\n    RETURN_TYPES = ()\n    FUNCTION = \"save\"\n\n    OUTPUT_NODE = True\n\n    CATEGORY = \"_for_testing\"\n\n    def save(self, samples, filename_prefix=\"ComfyUI\", prompt=None, extra_pnginfo=None):\n        \n\n\nclass LoadLatent:\n    @classmethod\n    /* Lines 524-527 omitted */\n\n    CATEGORY = \"_for_testing\"\n\n    RETURN_TYPES = (\"LATENT\", )\n    FUNCTION = \"load\"\n\n    def load(self, latent):\n        /* Lines 535-541 omitted */\n\n    @classmethod\n    /* Lines 544-549 omitted */\n\n    @classmethod\n\n\n\nclass CheckpointLoader:\n    @classmethod\n    /* Lines 560-562 omitted */\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"advanced/loaders\"\n    DEPRECATED = True\n\n    def load_checkpoint(self, config_name, ckpt_name):\n        \n\nclass CheckpointLoaderSimple:\n    @classmethod\n    /* Lines 576-581 omitted */\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\")\n    OUTPUT_TOOLTIPS = (\"The model used for denoising latents.\",\n                       \"The CLIP model used for encoding text prompts.\",\n                       \"The VAE model used for encoding and decoding images to and from latent space.\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"loaders\"\n    DESCRIPTION = \"Loads a diffusion model checkpoint, diffusion models are used to denoise latents.\"\n\n    def load_checkpoint(self, ckpt_name):\n        \n\nclass DiffusersLoader:\n    @classmethod\n    /* Lines 598-606 omitted */\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"advanced/loaders/deprecated\"\n\n    def load_checkpoint(self, model_path, output_vae=True, output_clip=True):\n        \n\n\nclass unCLIPCheckpointLoader:\n    @classmethod\n    /* Lines 625-627 omitted */\n    RETURN_TYPES = (\"MODEL\", \"CLIP\", \"VAE\", \"CLIP_VISION\")\n    FUNCTION = \"load_checkpoint\"\n\n    CATEGORY = \"loaders\"\n\n    def load_checkpoint(self, ckpt_name, output_vae=True, output_clip=True):\n        \n\nclass CLIPSetLastLayer:\n    @classmethod\n    /* Lines 640-643 omitted */\n    RETURN_TYPES = (\"CLIP\",)\n    FUNCTION = \"set_last_layer\"\n\n    CATEGORY = \"conditioning\"\n\n    def set_last_layer(self, clip, stop_at_clip_layer):\n        \n\nclass LoraLoader:\n    def __init__(self):\n        /* Line 656 omitted */\n\n    @classmethod\n    /* Lines 659-668 omitted */\n\n    RETURN_TYPES = (\"MODEL\", \"CLIP\")\n    OUTPUT_TOOLTIPS = (\"The modified diffusion model.\", \"The modified CLIP model.\")\n    FUNCTION = \"load_lora\"\n\n    CATEGORY = \"loaders\"\n    DESCRIPTION = \"LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.\"\n\n    def load_lora(self, model, clip, lora_name, strength_model, strength_clip):\n        \n\nclass LoraLoaderModelOnly(LoraLoader):\n    @classmethod\n    /* Lines 698-702 omitted */\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"load_lora_model_only\"\n\n    def load_lora_model_only(self, model, lora_name, strength_model):\n        \n\nclass VAELoader:\n    @staticmethod\n    /* Lines 711-749 omitted */\n\n    @staticmethod\n    /* Lines 752-779 omitted */\n\n    @classmethod\n    /* Lines 782-783 omitted */\n    RETURN_TYPES = (\"VAE\",)\n    FUNCTION = \"load_vae\"\n\n    CATEGORY = \"loaders\"\n\n    #TODO: scale factor?\n    def load_vae(self, vae_name):\n        \n\nclass ControlNetLoader:\n    @classmethod\n    /* Lines 805-806 omitted */\n\n    RETURN_TYPES = (\"CONTROL_NET\",)\n    FUNCTION = \"load_controlnet\"\n\n    CATEGORY = \"loaders\"\n\n    def load_controlnet(self, control_net_name):\n        \n\nclass DiffControlNetLoader:\n    @classmethod\n    /* Lines 822-824 omitted */\n\n    RETURN_TYPES = (\"CONTROL_NET\",)\n    FUNCTION = \"load_controlnet\"\n\n    CATEGORY = \"loaders\"\n\n    def load_controlnet(self, model, control_net_name):\n        \n\n\nclass ControlNetApply:\n    @classmethod\n    /* Lines 839-844 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"apply_controlnet\"\n\n    DEPRECATED = True\n    CATEGORY = \"conditioning/controlnet\"\n\n    def apply_controlnet(self, conditioning, control_net, image, strength):\n        \n\n\nclass ControlNetApplyAdvanced:\n    @classmethod\n    /* Lines 870-881 omitted */\n\n    RETURN_TYPES = (\"CONDITIONING\",\"CONDITIONING\")\n    RETURN_NAMES = (\"positive\", \"negative\")\n    FUNCTION = \"apply_controlnet\"\n\n    CATEGORY = \"conditioning/controlnet\"\n\n    def apply_controlnet(self, positive, negative, control_net, image, strength, start_percent, end_percent, vae=None, extra_concat=[]):\n        \n\n\nclass UNETLoader:\n    @classmethod\n    /* Lines 920-923 omitted */\n    RETURN_TYPES = (\"MODEL\",)\n    FUNCTION = \"load_unet\"\n\n    CATEGORY = \"advanced/loaders\"\n\n    def load_unet(self, unet_name, weight_dtype):\n        \n\nclass CLIPLoader:\n    @classmethod\n    /* Lines 945-951 omitted */\n    RETURN_TYPES = (\"CLIP\",)\n    FUNCTION = \"load_clip\"\n\n    CATEGORY = \"advanced/loaders\"\n\n    DESCRIPTION = \"[Recipes]\\n\\nstable_diffusion: clip-l\\nstable_cascade: clip-g\\nsd3: t5 xxl/ clip-g / clip-l\\nstable_audio: t5 base\\nmochi: t5 xxl\\ncosmos: old t5 xxl\\nlumina2: gemma 2 2B\\nwan: umt5 xxl\\n hidream: llama-3.1 (Recommend) or t5\\nomnigen2: qwen vl 2.5 3B\"\n\n    def load_clip(self, clip_name, type=\"stable_diffusion\", device=\"default\"):\n        \n\nclass DualCLIPLoader:\n    @classmethod\n    /* Lines 972-979 omitted */\n    RETURN_TYPES = (\"CLIP\",)\n    FUNCTION = \"load_clip\"\n\n    CATEGORY = \"advanced/loaders\"\n\n    DESCRIPTION = \"[Recipes]\\n\\nsdxl: clip-l, clip-g\\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\\nflux: clip-l, t5\\nhidream: at least one of t5 or llama, recommended t5 and llama\\nhunyuan_image: qwen2.5vl 7b and byt5 small\"\n\n    def load_clip(self, clip_name1, clip_name2, type, device=\"default\"):\n        \n\nclass CLIPVisionLoader:\n    @classmethod\n    /* Lines 1002-1004 omitted */\n    RETURN_TYPES = (\"CLIP_VISION\",)\n    FUNCTION = \"load_clip\"\n\n    CATEGORY = \"loaders\"\n\n    def load_clip(self, clip_name):\n        \n\nclass CLIPVisionEncode:\n    @classmethod\n    /* Lines 1019-1023 omitted */\n    RETURN_TYPES = (\"CLIP_VISION_OUTPUT\",)\n    FUNCTION = \"encode\"\n\n    CATEGORY = \"conditioning\"\n\n    def encode(self, clip_vision, image, crop):\n        \n\nclass StyleModelLoader:\n    @classmethod\n    /* Lines 1038-1039 omitted */\n\n    RETURN_TYPES = (\"STYLE_MODEL\",)\n    FUNCTION = \"load_style_model\"\n\n    CATEGORY = \"loaders\"\n\n    def load_style_model(self, style_model_name):\n        \n\n\nclass StyleModelApply:\n    @classmethod\n    /* Lines 1054-1060 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"apply_stylemodel\"\n\n    CATEGORY = \"conditioning/style_model\"\n\n    def apply_stylemodel(self, conditioning, style_model, clip_vision_output, strength, strength_type):\n        \n\nclass unCLIPConditioning:\n    @classmethod\n    /* Lines 1115-1120 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"apply_adm\"\n\n    CATEGORY = \"conditioning\"\n\n    def apply_adm(self, conditioning, clip_vision_output, strength, noise_augmentation):\n        \n\nclass GLIGENLoader:\n    @classmethod\n    /* Lines 1135-1136 omitted */\n\n    RETURN_TYPES = (\"GLIGEN\",)\n    FUNCTION = \"load_gligen\"\n\n    CATEGORY = \"loaders\"\n\n    def load_gligen(self, gligen_name):\n        \n\nclass GLIGENTextBoxApply:\n    @classmethod\n    /* Lines 1150-1159 omitted */\n    RETURN_TYPES = (\"CONDITIONING\",)\n    FUNCTION = \"append\"\n\n    CATEGORY = \"conditioning/gligen\"\n\n    def append(self, conditioning_to, clip, gligen_textbox_model, text, width, height, x, y):\n        \n\nclass EmptyLatentImage:\n    def __init__(self):\n        /* Line 1181 omitted */\n\n    @classmethod\n    /* Lines 1184-1191 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    OUTPUT_TOOLTIPS = (\"The empty latent image batch.\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"latent\"\n    DESCRIPTION = \"Create a new batch of empty latent images to be denoised via sampling.\"\n\n    def generate(self, width, height, batch_size=1):\n        \n\n\nclass LatentFromBatch:\n    @classmethod\n    /* Lines 1206-1210 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"frombatch\"\n\n    CATEGORY = \"latent/batch\"\n\n    def frombatch(self, samples, batch_index, length):\n        \n\nclass RepeatLatentBatch:\n    @classmethod\n    /* Lines 1238-1241 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"repeat\"\n\n    CATEGORY = \"latent/batch\"\n\n    def repeat(self, samples, amount):\n        \n\nclass LatentUpscale:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"bislerp\"]\n    crop_methods = [\"disabled\", \"center\"]\n\n    @classmethod\n    /* Lines 1267-1271 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"latent\"\n\n    def upscale(self, samples, upscale_method, width, height, crop):\n        \n\nclass LatentUpscaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"bislerp\"]\n\n    @classmethod\n    /* Lines 1300-1302 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"latent\"\n\n    def upscale(self, samples, upscale_method, scale_by):\n        \n\nclass LatentRotate:\n    @classmethod\n    /* Lines 1317-1320 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"rotate\"\n\n    CATEGORY = \"latent/transform\"\n\n    def rotate(self, samples, rotation):\n        \n\nclass LatentFlip:\n    @classmethod\n    /* Lines 1341-1344 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"flip\"\n\n    CATEGORY = \"latent/transform\"\n\n    def flip(self, samples, flip_method):\n        \n\nclass LatentComposite:\n    @classmethod\n    /* Lines 1361-1367 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"composite\"\n\n    CATEGORY = \"latent\"\n\n    def composite(self, samples_to, samples_from, x, y, composite_method=\"normal\", feather=0):\n        \n\nclass LatentBlend:\n    @classmethod\n    /* Lines 1403-1413 omitted */\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"blend\"\n\n    CATEGORY = \"_for_testing\"\n\n    def blend(self, samples1, samples2, blend_factor:float, blend_mode: str=\"normal\"):\n\n        /* Lines 1422-1434 omitted */\n\n    def blend_mode(self, img1, img2, mode):\n        \n\nclass LatentCrop:\n    @classmethod\n    /* Lines 1444-1450 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"crop\"\n\n    CATEGORY = \"latent/transform\"\n\n    def crop(self, samples, width, height, x, y):\n        \n\nclass SetLatentNoiseMask:\n    @classmethod\n    /* Lines 1477-1480 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"set_mask\"\n\n    CATEGORY = \"latent/inpaint\"\n\n    def set_mask(self, samples, mask):\n        \n\ndef common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent, denoise=1.0, disable_noise=False, start_step=None, last_step=None, force_full_denoise=False):\n    latent_image = latent[\"samples\"]\n    latent_image = comfy.sample.fix_empty_latent_channels(model, latent_image)\n\n    if disable_noise:\n        /* Line 1496 omitted */\n    else:\n        /* Lines 1498-1499 omitted */\n\n    noise_mask = None\n    if \"noise_mask\" in latent:\n        /* Line 1503 omitted */\n\n    callback = latent_preview.prepare_callback(model, steps)\n    disable_pbar = not comfy.utils.PROGRESS_BAR_ENABLED\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n                                  denoise=denoise, disable_noise=disable_noise, start_step=start_step, last_step=last_step,\n                                  force_full_denoise=force_full_denoise, noise_mask=noise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n    out = latent.copy()\n    out[\"samples\"] = samples\n    return (out, )\n\nclass KSampler:\n    @classmethod\n    /* Lines 1516-1530 omitted */\n\n    RETURN_TYPES = (\"LATENT\",)\n    OUTPUT_TOOLTIPS = (\"The denoised latent.\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n    DESCRIPTION = \"Uses the provided model, positive and negative conditioning to denoise the latent image.\"\n\n    def sample(self, model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0):\n        \n\nclass KSamplerAdvanced:\n    @classmethod\n    /* Lines 1544-1560 omitted */\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n\n    def sample(self, model, add_noise, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, start_at_step, end_at_step, return_with_leftover_noise, denoise=1.0):\n        \n\nclass SaveImage:\n    def __init__(self):\n        /* Lines 1578-1581 omitted */\n\n    @classmethod\n    /* Lines 1584-1593 omitted */\n\n    RETURN_TYPES = ()\n    FUNCTION = \"save_images\"\n\n    OUTPUT_NODE = True\n\n    CATEGORY = \"image\"\n    DESCRIPTION = \"Saves the input images to your ComfyUI output directory.\"\n\n    def save_images(self, images, filename_prefix=\"ComfyUI\", prompt=None, extra_pnginfo=None):\n        \n\nclass PreviewImage(SaveImage):\n    def __init__(self):\n        /* Lines 1633-1636 omitted */\n\n    @classmethod\n\n\nclass LoadImage:\n    @classmethod\n    /* Lines 1647-1653 omitted */\n\n    CATEGORY = \"image\"\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"load_image\"\n    def load_image(self, image):\n        /* Lines 1660-1704 omitted */\n\n    @classmethod\n    /* Lines 1707-1712 omitted */\n\n    @classmethod\n\n\nclass LoadImageMask:\n    _color_channels = [\"alpha\", \"red\", \"green\", \"blue\"]\n    @classmethod\n    /* Lines 1724-1730 omitted */\n\n    CATEGORY = \"mask\"\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"load_image\"\n    def load_image(self, image, channel):\n        /* Lines 1737-1753 omitted */\n\n    @classmethod\n    /* Lines 1756-1761 omitted */\n\n    @classmethod\n\n\n\nclass LoadImageOutput(LoadImage):\n    @classmethod\n    /* Lines 1773-1786 omitted */\n\n    DESCRIPTION = \"Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.\"\n    EXPERIMENTAL = True\n    FUNCTION = \"load_image\"\n\n\nclass ImageScale:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n    crop_methods = [\"disabled\", \"center\"]\n\n    @classmethod\n    /* Lines 1798-1802 omitted */\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, width, height, crop):\n        \n\nclass ImageScaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n\n    @classmethod\n    /* Lines 1827-1829 omitted */\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, scale_by):\n        \n\nclass ImageInvert:\n\n    @classmethod\n    /* Lines 1846-1847 omitted */\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"invert\"\n\n    CATEGORY = \"image\"\n\n    def invert(self, image):\n        \n\nclass ImageBatch:\n\n    @classmethod\n    /* Lines 1861-1862 omitted */\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"batch\"\n\n    CATEGORY = \"image\"\n\n    def batch(self, image1, image2):\n        \n\nclass EmptyImage:\n    def __init__(self, device=\"cpu\"):\n        /* Line 1882 omitted */\n\n    @classmethod\n    /* Lines 1885-1890 omitted */\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"image\"\n\n    def generate(self, width, height, batch_size=1, color=0):\n        \n\nclass ImagePadForOutpaint:\n\n    @classmethod\n    /* Lines 1905-1915 omitted */\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"expand_image\"\n\n    CATEGORY = \"image\"\n\n    def expand_image(self, image, left, top, right, bottom, feathering):\n        \n\n\n# NODE_CLASS_MAPPINGS = {\n#     \"KSampler\": KSampler,\n#     \"CheckpointLoaderSimple\": CheckpointLoaderSimple,\n#     \"CLIPTextEncode\": CLIPTextEncode,\n#     \"CLIPSetLastLayer\": CLIPSetLastLayer,\n#     \"VAEDecode\": VAEDecode,\n#     \"VAEEncode\": VAEEncode,\n#     \"VAEEncodeForInpaint\": VAEEncodeForInpaint,\n#     \"VAELoader\": VAELoader,\n#     \"EmptyLatentImage\": EmptyLatentImage,\n#     \"LatentUpscale\": LatentUpscale,\n#     \"LatentUpscaleBy\": LatentUpscaleBy,\n#     \"LatentFromBatch\": LatentFromBatch,\n#     \"RepeatLatentBatch\": RepeatLatentBatch,\n#     \"SaveImage\": SaveImage,\n#     \"PreviewImage\": PreviewImage,\n#     \"LoadImage\": LoadImage,\n#     \"LoadImageMask\": LoadImageMask,\n#     \"LoadImageOutput\": LoadImageOutput,\n#     \"ImageScale\": ImageScale,\n#     \"ImageScaleBy\": ImageScaleBy,\n#     \"ImageInvert\": ImageInvert,\n#     \"ImageBatch\": ImageBatch,\n#     \"ImagePadForOutpaint\": ImagePadForOutpaint,\n#     \"EmptyImage\": EmptyImage,\n#     \"ConditioningAverage\": ConditioningAverage ,\n#     \"ConditioningCombine\": ConditioningCombine,\n#     \"ConditioningConcat\": ConditioningConcat,\n#     \"ConditioningSetArea\": ConditioningSetArea,\n#     \"ConditioningSetAreaPercentage\": ConditioningSetAreaPercentage,\n#     \"ConditioningSetAreaStrength\": ConditioningSetAreaStrength,\n#     \"ConditioningSetMask\": ConditioningSetMask,\n#     \"KSamplerAdvanced\": KSamplerAdvanced,\n#     \"SetLatentNoiseMask\": SetLatentNoiseMask,\n#     \"LatentComposite\": LatentComposite,\n#     \"LatentBlend\": LatentBlend,\n#     \"LatentRotate\": LatentRotate,\n#     \"LatentFlip\": LatentFlip,\n#     \"LatentCrop\": LatentCrop,\n#     \"LoraLoader\": LoraLoader,\n#     \"CLIPLoader\": CLIPLoader,\n#     \"UNETLoader\": UNETLoader,\n#     \"DualCLIPLoader\": DualCLIPLoader,\n#     \"CLIPVisionEncode\": CLIPVisionEncode,\n#     \"StyleModelApply\": StyleModelApply,\n#     \"unCLIPConditioning\": unCLIPConditioning,\n#     \"ControlNetApply\": ControlNetApply,\n#     \"ControlNetApplyAdvanced\": ControlNetApplyAdvanced,\n#     \"ControlNetLoader\": ControlNetLoader,\n#     \"DiffControlNetLoader\": DiffControlNetLoader,\n#     \"StyleModelLoader\": StyleModelLoader,\n#     \"CLIPVisionLoader\": CLIPVisionLoader,\n#     \"VAEDecodeTiled\": VAEDecodeTiled,\n#     \"VAEEncodeTiled\": VAEEncodeTiled,\n#     \"unCLIPCheckpointLoader\": unCLIPCheckpointLoader,\n#     \"GLIGENLoader\": GLIGENLoader,\n#     \"GLIGENTextBoxApply\": GLIGENTextBoxApply,\n#     \"InpaintModelConditioning\": InpaintModelConditioning,\n\n#     \"CheckpointLoader\": CheckpointLoader,\n#     \"DiffusersLoader\": DiffusersLoader,\n\n#     \"LoadLatent\": LoadLatent,\n#     \"SaveLatent\": SaveLatent,\n\n#     \"ConditioningZeroOut\": ConditioningZeroOut,\n#     \"ConditioningSetTimestepRange\": ConditioningSetTimestepRange,\n#     \"LoraLoaderModelOnly\": LoraLoaderModelOnly,\n# }\nNODE_CLASS_MAPPINGS = {}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    # Sampling\n    \"KSampler\": \"KSampler\",\n    \"KSamplerAdvanced\": \"KSampler (Advanced)\",\n    # Loaders\n    \"CheckpointLoader\": \"Load Checkpoint With Config (DEPRECATED)\",\n    \"CheckpointLoaderSimple\": \"Load Checkpoint\",\n    \"VAELoader\": \"Load VAE\",\n    \"LoraLoader\": \"Load LoRA\",\n    \"CLIPLoader\": \"Load CLIP\",\n    \"ControlNetLoader\": \"Load ControlNet Model\",\n    \"DiffControlNetLoader\": \"Load ControlNet Model (diff)\",\n    \"StyleModelLoader\": \"Load Style Model\",\n    \"CLIPVisionLoader\": \"Load CLIP Vision\",\n    \"UNETLoader\": \"Load Diffusion Model\",\n    # Conditioning\n    \"CLIPVisionEncode\": \"CLIP Vision Encode\",\n    \"StyleModelApply\": \"Apply Style Model\",\n    \"CLIPTextEncode\": \"CLIP Text Encode (Prompt)\",\n    \"CLIPSetLastLayer\": \"CLIP Set Last Layer\",\n    \"ConditioningCombine\": \"Conditioning (Combine)\",\n    \"ConditioningAverage \": \"Conditioning (Average)\",\n    \"ConditioningConcat\": \"Conditioning (Concat)\",\n    \"ConditioningSetArea\": \"Conditioning (Set Area)\",\n    \"ConditioningSetAreaPercentage\": \"Conditioning (Set Area with Percentage)\",\n    \"ConditioningSetMask\": \"Conditioning (Set Mask)\",\n    \"ControlNetApply\": \"Apply ControlNet (OLD)\",\n    \"ControlNetApplyAdvanced\": \"Apply ControlNet\",\n    # Latent\n    \"VAEEncodeForInpaint\": \"VAE Encode (for Inpainting)\",\n    \"SetLatentNoiseMask\": \"Set Latent Noise Mask\",\n    \"VAEDecode\": \"VAE Decode\",\n    \"VAEEncode\": \"VAE Encode\",\n    \"LatentRotate\": \"Rotate Latent\",\n    \"LatentFlip\": \"Flip Latent\",\n    \"LatentCrop\": \"Crop Latent\",\n    \"EmptyLatentImage\": \"Empty Latent Image\",\n    \"LatentUpscale\": \"Upscale Latent\",\n    \"LatentUpscaleBy\": \"Upscale Latent By\",\n    \"LatentComposite\": \"Latent Composite\",\n    \"LatentBlend\": \"Latent Blend\",\n    \"LatentFromBatch\" : \"Latent From Batch\",\n    \"RepeatLatentBatch\": \"Repeat Latent Batch\",\n    # Image\n    \"SaveImage\": \"Save Image\",\n    \"PreviewImage\": \"Preview Image\",\n    \"LoadImage\": \"Load Image\",\n    \"LoadImageMask\": \"Load Image (as Mask)\",\n    \"LoadImageOutput\": \"Load Image (from Outputs)\",\n    \"ImageScale\": \"Upscale Image\",\n    \"ImageScaleBy\": \"Upscale Image By\",\n    \"ImageInvert\": \"Invert Image\",\n    \"ImagePadForOutpaint\": \"Pad Image for Outpainting\",\n    \"ImageBatch\": \"Batch Images\",\n    \"ImageCrop\": \"Image Crop\",\n    \"ImageStitch\": \"Image Stitch\",\n    \"ImageBlend\": \"Image Blend\",\n    \"ImageBlur\": \"Image Blur\",\n    \"ImageQuantize\": \"Image Quantize\",\n    \"ImageSharpen\": \"Image Sharpen\",\n    \"ImageScaleToTotalPixels\": \"Scale Image to Total Pixels\",\n    \"GetImageSize\": \"Get Image Size\",\n    # _for_testing\n    \"VAEDecodeTiled\": \"VAE Decode (Tiled)\",\n    \"VAEEncodeTiled\": \"VAE Encode (Tiled)\",\n}\n\nif args.fast_load:\n    NODE_CLASS_MAPPINGS = {}\n    NODE_DISPLAY_NAME_MAPPINGS = {}\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\ndef get_module_name(module_path: str) -> str:\n    \"\"\"\n    Returns the module name based on the given module path.\n    Examples:\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.disabled\") -> \"custom_nodes\n    Args:\n        module_path (str): The path of the module.\n    Returns:\n        str: The module name.\n    \"\"\"\n    base_path = os.path.basename(module_path)\n    if os.path.isfile(module_path):\n        /* Line 2132 omitted */\n    return base_path\n\n\nasync def load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    module_name = get_module_name(module_path)\n    if os.path.isfile(module_path):\n        /* Lines 2139-2141 omitted */\n    elif os.path.isdir(module_path):\n        /* Line 2143 omitted */\n\n    try:\n        /* Lines 2146-2225 omitted */\n    except Exception as e:\n        \n\nasync def init_external_custom_nodes():\n    \"\"\"\n    Initializes the external custom nodes.\n\n    This function loads custom nodes from the specified folder paths and imports them into the application.\n    It measures the import times for each custom node and logs the results.\n\n    Returns:\n        None\n    \"\"\"\n    base_node_names = set(NODE_CLASS_MAPPINGS.keys())\n    node_paths = folder_paths.get_folder_paths(\"custom_nodes\")\n    node_import_times = []\n    for custom_node_path in node_paths:\n        /* Lines 2245-2258 omitted */\n\n    if len(node_import_times) > 0:\n        \n\nasync def init_builtin_extra_nodes():\n    \"\"\"\n    Initializes the built-in extra nodes in ComfyUI.\n\n    This function loads the extra node files located in the \"comfy_extras\" directory and imports them into ComfyUI.\n    If any of the extra node files fail to import, a warning message is logged.\n\n    Returns:\n        None\n    \"\"\"\n    extras_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_extras\")\n    extras_files = [\n        \"nodes_latent.py\",\n        \"nodes_hypernetwork.py\",\n        \"nodes_upscale_model.py\",\n        \"nodes_post_processing.py\",\n        \"nodes_mask.py\",\n        \"nodes_compositing.py\",\n        \"nodes_rebatch.py\",\n        \"nodes_model_merging.py\",\n        \"nodes_tomesd.py\",\n        \"nodes_clip_sdxl.py\",\n        \"nodes_canny.py\",\n        \"nodes_freelunch.py\",\n        \"nodes_custom_sampler.py\",\n        \"nodes_hypertile.py\",\n        \"nodes_model_advanced.py\",\n        \"nodes_model_downscale.py\",\n        \"nodes_images.py\",\n        \"nodes_video_model.py\",\n        \"nodes_train.py\",\n        \"nodes_sag.py\",\n        \"nodes_perpneg.py\",\n        \"nodes_stable3d.py\",\n        \"nodes_sdupscale.py\",\n        \"nodes_photomaker.py\",\n        \"nodes_pixart.py\",\n        \"nodes_cond.py\",\n        \"nodes_morphology.py\",\n        \"nodes_stable_cascade.py\",\n        \"nodes_differential_diffusion.py\",\n        \"nodes_ip2p.py\",\n        \"nodes_model_merging_model_specific.py\",\n        \"nodes_pag.py\",\n        \"nodes_align_your_steps.py\",\n        \"nodes_attention_multiply.py\",\n        \"nodes_advanced_samplers.py\",\n        \"nodes_webcam.py\",\n        \"nodes_audio.py\",\n        \"nodes_sd3.py\",\n        \"nodes_gits.py\",\n        \"nodes_controlnet.py\",\n        \"nodes_hunyuan.py\",\n        \"nodes_eps.py\",\n        \"nodes_flux.py\",\n        \"nodes_lora_extract.py\",\n        \"nodes_torch_compile.py\",\n        \"nodes_mochi.py\",\n        \"nodes_slg.py\",\n        \"nodes_mahiro.py\",\n        \"nodes_lt.py\",\n        \"nodes_hooks.py\",\n        \"nodes_load_3d.py\",\n        \"nodes_cosmos.py\",\n        \"nodes_video.py\",\n        \"nodes_lumina2.py\",\n        \"nodes_wan.py\",\n        \"nodes_lotus.py\",\n        \"nodes_hunyuan3d.py\",\n        \"nodes_primitive.py\",\n        \"nodes_cfg.py\",\n        \"nodes_optimalsteps.py\",\n        \"nodes_hidream.py\",\n        \"nodes_fresca.py\",\n        \"nodes_apg.py\",\n        \"nodes_preview_any.py\",\n        \"nodes_ace.py\",\n        \"nodes_string.py\",\n        \"nodes_camera_trajectory.py\",\n        \"nodes_edit_model.py\",\n        \"nodes_tcfg.py\",\n        \"nodes_context_windows.py\",\n        \"nodes_qwen.py\",\n        \"nodes_chroma_radiance.py\",\n        \"nodes_model_patch.py\",\n        \"nodes_easycache.py\",\n        \"nodes_audio_encoder.py\",\n        \"nodes_rope.py\",\n        \"nodes_nop.py\",\n    ]\n\n    import_failed = []\n    for node_file in extras_files:\n        /* Lines 2363-2364 omitted */\n\n    return import_failed\n\n\nasync def init_builtin_api_nodes():\n    api_nodes_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_api_nodes\")\n    api_nodes_files = [\n        \"nodes_ideogram.py\",\n        \"nodes_openai.py\",\n        \"nodes_minimax.py\",\n        \"nodes_veo2.py\",\n        \"nodes_kling.py\",\n        \"nodes_bfl.py\",\n        \"nodes_bytedance.py\",\n        \"nodes_ltxv.py\",\n        \"nodes_luma.py\",\n        \"nodes_recraft.py\",\n        \"nodes_pixverse.py\",\n        \"nodes_stability.py\",\n        \"nodes_pika.py\",\n        \"nodes_runway.py\",\n        \"nodes_sora.py\",\n        \"nodes_topaz.py\",\n        \"nodes_tripo.py\",\n        \"nodes_moonvalley.py\",\n        \"nodes_rodin.py\",\n        \"nodes_gemini.py\",\n        \"nodes_vidu.py\",\n        \"nodes_wan.py\",\n    ]\n    /* Lines 2395-2404 omitted */\n\nasync def init_public_apis():\n    /* Lines 2407-2412 omitted */\n\nasync def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n</attachment>\n<attachment id=\"file:nodes.py\">\nUser's active selection:\nExcerpt from nodes.py, lines 2417 to 2417:\n```python\nimport_failed = await init_builtin_extra_nodes()\n```\n</attachment>\n<attachment isSummarized=\"true\" filePath=\"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\">\nUser's active file for additional context:\nclass StyleModelApply:\n    /* Lines 1053-1111 omitted */\n\nclass unCLIPConditioning:\n    /* Lines 1114-1131 omitted */\n\nclass GLIGENLoader:\n    /* Lines 1134-1146 omitted */\n\nclass GLIGENTextBoxApply:\n    /* Lines 1149-1177 omitted */\n\nclass EmptyLatentImage:\n    /* Lines 1180-1201 omitted */\n\n\nclass LatentFromBatch:\n    /* Lines 1205-1234 omitted */\n\nclass RepeatLatentBatch:\n    /* Lines 1237-1260 omitted */\n\nclass LatentUpscale:\n    /* Lines 1263-1276 omitted */\n\n    def upscale(self, samples, upscale_method, width, height, crop):\n        \n\nclass LatentUpscaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"bislerp\"]\n\n    @classmethod\n    /* Lines 1300-1302 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"latent\"\n\n    def upscale(self, samples, upscale_method, scale_by):\n        \n\nclass LatentRotate:\n    @classmethod\n    /* Lines 1317-1320 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"rotate\"\n\n    CATEGORY = \"latent/transform\"\n\n    def rotate(self, samples, rotation):\n        \n\nclass LatentFlip:\n    @classmethod\n    /* Lines 1341-1344 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"flip\"\n\n    CATEGORY = \"latent/transform\"\n\n    def flip(self, samples, flip_method):\n        \n\nclass LatentComposite:\n    @classmethod\n    /* Lines 1361-1367 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"composite\"\n\n    CATEGORY = \"latent\"\n\n    def composite(self, samples_to, samples_from, x, y, composite_method=\"normal\", feather=0):\n        \n\nclass LatentBlend:\n    @classmethod\n    /* Lines 1403-1413 omitted */\n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"blend\"\n\n    CATEGORY = \"_for_testing\"\n\n    def blend(self, samples1, samples2, blend_factor:float, blend_mode: str=\"normal\"):\n\n        /* Lines 1422-1434 omitted */\n\n    def blend_mode(self, img1, img2, mode):\n        \n\nclass LatentCrop:\n    @classmethod\n    /* Lines 1444-1450 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"crop\"\n\n    CATEGORY = \"latent/transform\"\n\n    def crop(self, samples, width, height, x, y):\n        \n\nclass SetLatentNoiseMask:\n    @classmethod\n    /* Lines 1477-1480 omitted */\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"set_mask\"\n\n    CATEGORY = \"latent/inpaint\"\n\n    def set_mask(self, samples, mask):\n        \n\ndef common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent, denoise=1.0, disable_noise=False, start_step=None, last_step=None, force_full_denoise=False):\n    latent_image = latent[\"samples\"]\n    latent_image = comfy.sample.fix_empty_latent_channels(model, latent_image)\n\n    if disable_noise:\n        /* Line 1496 omitted */\n    else:\n        /* Lines 1498-1499 omitted */\n\n    noise_mask = None\n    if \"noise_mask\" in latent:\n        /* Line 1503 omitted */\n\n    callback = latent_preview.prepare_callback(model, steps)\n    disable_pbar = not comfy.utils.PROGRESS_BAR_ENABLED\n    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n                                  denoise=denoise, disable_noise=disable_noise, start_step=start_step, last_step=last_step,\n                                  force_full_denoise=force_full_denoise, noise_mask=noise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n    out = latent.copy()\n    out[\"samples\"] = samples\n    return (out, )\n\nclass KSampler:\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    RETURN_TYPES = (\"LATENT\",)\n    OUTPUT_TOOLTIPS = (\"The denoised latent.\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n    DESCRIPTION = \"Uses the provided model, positive and negative conditioning to denoise the latent image.\"\n\n    def sample(self, model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=1.0):\n        return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n\nclass KSamplerAdvanced:\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    RETURN_TYPES = (\"LATENT\",)\n    FUNCTION = \"sample\"\n\n    CATEGORY = \"sampling\"\n\n    def sample(self, model, add_noise, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, start_at_step, end_at_step, return_with_leftover_noise, denoise=1.0):\n        force_full_denoise = True\n        if return_with_leftover_noise == \"enable\":\n            /* Line 1570 omitted */\n        disable_noise = False\n        if add_noise == \"disable\":\n            /* Line 1573 omitted */\n        return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)\n\nclass SaveImage:\n    def __init__(self):\n        self.output_dir = folder_paths.get_output_directory()\n        self.type = \"output\"\n        self.prefix_append = \"\"\n        self.compress_level = 4\n\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    RETURN_TYPES = ()\n    FUNCTION = \"save_images\"\n\n    OUTPUT_NODE = True\n\n    CATEGORY = \"image\"\n    DESCRIPTION = \"Saves the input images to your ComfyUI output directory.\"\n\n    def save_images(self, images, filename_prefix=\"ComfyUI\", prompt=None, extra_pnginfo=None):\n        filename_prefix += self.prefix_append\n        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(filename_prefix, self.output_dir, images[0].shape[1], images[0].shape[0])\n        results = list()\n        for (batch_number, image) in enumerate(images):\n            /* Lines 1608-1627 omitted */\n\n        return { \"ui\": { \"images\": results } }\n\nclass PreviewImage(SaveImage):\n    def __init__(self):\n        self.output_dir = folder_paths.get_temp_directory()\n        self.type = \"temp\"\n        self.prefix_append = \"_temp_\" + ''.join(random.choice(\"abcdefghijklmnopqrstupvxyz\") for x in range(5))\n        self.compress_level = 1\n\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\nclass LoadImage:\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    CATEGORY = \"image\"\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"load_image\"\n    def load_image(self, image):\n        image_path = folder_paths.get_annotated_filepath(image)\n\n        img = node_helpers.pillow(Image.open, image_path)\n\n        output_images = []\n        output_masks = []\n        w, h = /* Line 1666 omitted */\n\n        excluded_formats = ['MPO']\n\n        for i in ImageSequence.Iterator(img):\n            /* Lines 1671-1695 omitted */\n\n        if len(output_images) > 1 and img.format not in excluded_formats:\n            /* Lines 1698-1699 omitted */\n        else:\n            /* Lines 1701-1702 omitted */\n\n        return (output_image, output_mask)\n\n    @classmethod\n    def IS_CHANGED(s, image):\n        \n\n    @classmethod\n    def VALIDATE_INPUTS(s, image):\n        \n\nclass LoadImageMask:\n    _color_channels = [\"alpha\", \"red\", \"green\", \"blue\"]\n    @classmethod\n    def INPUT_TYPES(s):\n        \n\n    CATEGORY = \"mask\"\n\n    RETURN_TYPES = (\"MASK\",)\n    FUNCTION = \"load_image\"\n    def load_image(self, image, channel):\n        image_path = folder_paths.get_annotated_filepath(image)\n        i = node_helpers.pillow(Image.open, image_path)\n        i = node_helpers.pillow(ImageOps.exif_transpose, i)\n        if i.getbands() != (\"R\", \"G\", \"B\", \"A\"):\n            /* Lines 1741-1743 omitted */\n        mask = None\n        c = channel[0].upper()\n        if c in i.getbands():\n            /* Lines 1747-1748 omitted */\n            mask = torch.from_numpy(mask)\n            if c == 'A':\n                \n        else:\n            mask = torch.zeros((64,64), dtype=torch.float32, device=\"cpu\")\n        return (mask.unsqueeze(0),)\n\n    @classmethod\n    def IS_CHANGED(s, image, channel):\n        image_path = folder_paths.get_annotated_filepath(image)\n        m = hashlib.sha256()\n        with open(image_path, 'rb') as f:\n            /* Line 1760 omitted */\n        return m.digest().hex()\n\n    @classmethod\n    def VALIDATE_INPUTS(s, image):\n        if not folder_paths.exists_annotated_filepath(image):\n            /* Line 1766 omitted */\n\n        return True\n\n\nclass LoadImageOutput(LoadImage):\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (\"COMBO\", {\n                    \"image_upload\": True,\n                    \"image_folder\": \"output\",\n                    \"remote\": {\n                        \"route\": \"/internal/files/output\",\n                        \"refresh_button\": True,\n                        \"control_after_refresh\": \"first\",\n                    },\n                }),\n            }\n        }\n\n    DESCRIPTION = \"Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.\"\n    EXPERIMENTAL = True\n    FUNCTION = \"load_image\"\n\n\nclass ImageScale:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n    crop_methods = [\"disabled\", \"center\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",), \"upscale_method\": (s.upscale_methods,),\n                              \"width\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"crop\": (s.crop_methods,)}}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, width, height, crop):\n        if width == 0 and height == 0:\n            s = image\n        else:\n            samples = image.movedim(-1,1)\n\n            if width == 0:\n                /* Line 1815 omitted */\n            elif height == 0:\n                /* Line 1817 omitted */\n\n            s = comfy.utils.common_upscale(samples, width, height, upscale_method, crop)\n            s = s.movedim(1,-1)\n        return (s,)\n\nclass ImageScaleBy:\n    upscale_methods = [\"nearest-exact\", \"bilinear\", \"area\", \"bicubic\", \"lanczos\"]\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",), \"upscale_method\": (s.upscale_methods,),\n                              \"scale_by\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.01, \"max\": 8.0, \"step\": 0.01}),}}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"upscale\"\n\n    CATEGORY = \"image/upscaling\"\n\n    def upscale(self, image, upscale_method, scale_by):\n        samples = image.movedim(-1,1)\n        width = round(samples.shape[3] * scale_by)\n        height = round(samples.shape[2] * scale_by)\n        s = comfy.utils.common_upscale(samples, width, height, upscale_method, \"disabled\")\n        s = s.movedim(1,-1)\n        return (s,)\n\nclass ImageInvert:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"invert\"\n\n    CATEGORY = \"image\"\n\n    def invert(self, image):\n        s = 1.0 - image\n        return (s,)\n\nclass ImageBatch:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"image1\": (\"IMAGE\",), \"image2\": (\"IMAGE\",)}}\n\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"batch\"\n\n    CATEGORY = \"image\"\n\n    def batch(self, image1, image2):\n        if image1.shape[-1] != image2.shape[-1]:\n            if image1.shape[-1] > image2.shape[-1]:\n                /* Line 1872 omitted */\n            else:\n                \n        if image1.shape[1:] != image2.shape[1:]:\n            image2 = comfy.utils.common_upscale(image2.movedim(-1,1), image1.shape[2], image1.shape[1], \"bilinear\", \"center\").movedim(1,-1)\n        s = torch.cat((image1, image2), dim=0)\n        return (s,)\n\nclass EmptyImage:\n    def __init__(self, device=\"cpu\"):\n        self.device = device\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\"required\": { \"width\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"height\": (\"INT\", {\"default\": 512, \"min\": 1, \"max\": MAX_RESOLUTION, \"step\": 1}),\n                              \"batch_size\": (\"INT\", {\"default\": 1, \"min\": 1, \"max\": 4096}),\n                              \"color\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": 0xFFFFFF, \"step\": 1, \"display\": \"color\"}),\n                              }}\n    RETURN_TYPES = (\"IMAGE\",)\n    FUNCTION = \"generate\"\n\n    CATEGORY = \"image\"\n\n    def generate(self, width, height, batch_size=1, color=0):\n        r = torch.full([batch_size, height, width, 1], ((color >> 16) & 0xFF) / 0xFF)\n        g = torch.full([batch_size, height, width, 1], ((color >> 8) & 0xFF) / 0xFF)\n        b = torch.full([batch_size, height, width, 1], ((color) & 0xFF) / 0xFF)\n        return (torch.cat((r, g, b), dim=-1), )\n\nclass ImagePadForOutpaint:\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"left\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"top\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"right\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"bottom\": (\"INT\", {\"default\": 0, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 8}),\n                \"feathering\": (\"INT\", {\"default\": 40, \"min\": 0, \"max\": MAX_RESOLUTION, \"step\": 1}),\n            }\n        }\n\n    RETURN_TYPES = (\"IMAGE\", \"MASK\")\n    FUNCTION = \"expand_image\"\n\n    CATEGORY = \"image\"\n\n    def expand_image(self, image, left, top, right, bottom, feathering):\n        d1, d2, d3, d4 = image.size()\n\n        new_image = torch.ones(\n            (d1, d2 + top + bottom, d3 + left + right, d4),\n            dtype=torch.float32,\n        ) * 0.5\n\n        new_image[:, top:top + d2, left:left + d3, :] = image\n\n        mask = torch.ones(\n            (d2 + top + bottom, d3 + left + right),\n            dtype=torch.float32,\n        )\n\n        t = torch.zeros(\n            (d2, d3),\n            dtype=torch.float32\n        )\n\n        if feathering > 0 and feathering * 2 < d2 and feathering * 2 < d3:\n\n            for i in range(d2):\n                \n\n        mask[top:top + d2, left:left + d3] = t\n\n        return (new_image, mask.unsqueeze(0))\n\n\n# NODE_CLASS_MAPPINGS = {\n#     \"KSampler\": KSampler,\n#     \"CheckpointLoaderSimple\": CheckpointLoaderSimple,\n#     \"CLIPTextEncode\": CLIPTextEncode,\n#     \"CLIPSetLastLayer\": CLIPSetLastLayer,\n#     \"VAEDecode\": VAEDecode,\n#     \"VAEEncode\": VAEEncode,\n#     \"VAEEncodeForInpaint\": VAEEncodeForInpaint,\n#     \"VAELoader\": VAELoader,\n#     \"EmptyLatentImage\": EmptyLatentImage,\n#     \"LatentUpscale\": LatentUpscale,\n#     \"LatentUpscaleBy\": LatentUpscaleBy,\n#     \"LatentFromBatch\": LatentFromBatch,\n#     \"RepeatLatentBatch\": RepeatLatentBatch,\n#     \"SaveImage\": SaveImage,\n#     \"PreviewImage\": PreviewImage,\n#     \"LoadImage\": LoadImage,\n#     \"LoadImageMask\": LoadImageMask,\n#     \"LoadImageOutput\": LoadImageOutput,\n#     \"ImageScale\": ImageScale,\n#     \"ImageScaleBy\": ImageScaleBy,\n#     \"ImageInvert\": ImageInvert,\n#     \"ImageBatch\": ImageBatch,\n#     \"ImagePadForOutpaint\": ImagePadForOutpaint,\n#     \"EmptyImage\": EmptyImage,\n#     \"ConditioningAverage\": ConditioningAverage ,\n#     \"ConditioningCombine\": ConditioningCombine,\n#     \"ConditioningConcat\": ConditioningConcat,\n#     \"ConditioningSetArea\": ConditioningSetArea,\n#     \"ConditioningSetAreaPercentage\": ConditioningSetAreaPercentage,\n#     \"ConditioningSetAreaStrength\": ConditioningSetAreaStrength,\n#     \"ConditioningSetMask\": ConditioningSetMask,\n#     \"KSamplerAdvanced\": KSamplerAdvanced,\n#     \"SetLatentNoiseMask\": SetLatentNoiseMask,\n#     \"LatentComposite\": LatentComposite,\n#     \"LatentBlend\": LatentBlend,\n#     \"LatentRotate\": LatentRotate,\n#     \"LatentFlip\": LatentFlip,\n#     \"LatentCrop\": LatentCrop,\n#     \"LoraLoader\": LoraLoader,\n#     \"CLIPLoader\": CLIPLoader,\n#     \"UNETLoader\": UNETLoader,\n#     \"DualCLIPLoader\": DualCLIPLoader,\n#     \"CLIPVisionEncode\": CLIPVisionEncode,\n#     \"StyleModelApply\": StyleModelApply,\n#     \"unCLIPConditioning\": unCLIPConditioning,\n#     \"ControlNetApply\": ControlNetApply,\n#     \"ControlNetApplyAdvanced\": ControlNetApplyAdvanced,\n#     \"ControlNetLoader\": ControlNetLoader,\n#     \"DiffControlNetLoader\": DiffControlNetLoader,\n#     \"StyleModelLoader\": StyleModelLoader,\n#     \"CLIPVisionLoader\": CLIPVisionLoader,\n#     \"VAEDecodeTiled\": VAEDecodeTiled,\n#     \"VAEEncodeTiled\": VAEEncodeTiled,\n#     \"unCLIPCheckpointLoader\": unCLIPCheckpointLoader,\n#     \"GLIGENLoader\": GLIGENLoader,\n#     \"GLIGENTextBoxApply\": GLIGENTextBoxApply,\n#     \"InpaintModelConditioning\": InpaintModelConditioning,\n\n#     \"CheckpointLoader\": CheckpointLoader,\n#     \"DiffusersLoader\": DiffusersLoader,\n\n#     \"LoadLatent\": LoadLatent,\n#     \"SaveLatent\": SaveLatent,\n\n#     \"ConditioningZeroOut\": ConditioningZeroOut,\n#     \"ConditioningSetTimestepRange\": ConditioningSetTimestepRange,\n#     \"LoraLoaderModelOnly\": LoraLoaderModelOnly,\n# }\nNODE_CLASS_MAPPINGS = {}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    # Sampling\n    \"KSampler\": \"KSampler\",\n    \"KSamplerAdvanced\": \"KSampler (Advanced)\",\n    # Loaders\n    \"CheckpointLoader\": \"Load Checkpoint With Config (DEPRECATED)\",\n    \"CheckpointLoaderSimple\": \"Load Checkpoint\",\n    \"VAELoader\": \"Load VAE\",\n    \"LoraLoader\": \"Load LoRA\",\n    \"CLIPLoader\": \"Load CLIP\",\n    \"ControlNetLoader\": \"Load ControlNet Model\",\n    \"DiffControlNetLoader\": \"Load ControlNet Model (diff)\",\n    \"StyleModelLoader\": \"Load Style Model\",\n    \"CLIPVisionLoader\": \"Load CLIP Vision\",\n    \"UNETLoader\": \"Load Diffusion Model\",\n    # Conditioning\n    \"CLIPVisionEncode\": \"CLIP Vision Encode\",\n    \"StyleModelApply\": \"Apply Style Model\",\n    \"CLIPTextEncode\": \"CLIP Text Encode (Prompt)\",\n    \"CLIPSetLastLayer\": \"CLIP Set Last Layer\",\n    \"ConditioningCombine\": \"Conditioning (Combine)\",\n    \"ConditioningAverage \": \"Conditioning (Average)\",\n    \"ConditioningConcat\": \"Conditioning (Concat)\",\n    \"ConditioningSetArea\": \"Conditioning (Set Area)\",\n    \"ConditioningSetAreaPercentage\": \"Conditioning (Set Area with Percentage)\",\n    \"ConditioningSetMask\": \"Conditioning (Set Mask)\",\n    \"ControlNetApply\": \"Apply ControlNet (OLD)\",\n    \"ControlNetApplyAdvanced\": \"Apply ControlNet\",\n    # Latent\n    \"VAEEncodeForInpaint\": \"VAE Encode (for Inpainting)\",\n    \"SetLatentNoiseMask\": \"Set Latent Noise Mask\",\n    \"VAEDecode\": \"VAE Decode\",\n    \"VAEEncode\": \"VAE Encode\",\n    \"LatentRotate\": \"Rotate Latent\",\n    \"LatentFlip\": \"Flip Latent\",\n    \"LatentCrop\": \"Crop Latent\",\n    \"EmptyLatentImage\": \"Empty Latent Image\",\n    \"LatentUpscale\": \"Upscale Latent\",\n    \"LatentUpscaleBy\": \"Upscale Latent By\",\n    \"LatentComposite\": \"Latent Composite\",\n    \"LatentBlend\": \"Latent Blend\",\n    \"LatentFromBatch\" : \"Latent From Batch\",\n    \"RepeatLatentBatch\": \"Repeat Latent Batch\",\n    # Image\n    \"SaveImage\": \"Save Image\",\n    \"PreviewImage\": \"Preview Image\",\n    \"LoadImage\": \"Load Image\",\n    \"LoadImageMask\": \"Load Image (as Mask)\",\n    \"LoadImageOutput\": \"Load Image (from Outputs)\",\n    \"ImageScale\": \"Upscale Image\",\n    \"ImageScaleBy\": \"Upscale Image By\",\n    \"ImageInvert\": \"Invert Image\",\n    \"ImagePadForOutpaint\": \"Pad Image for Outpainting\",\n    \"ImageBatch\": \"Batch Images\",\n    \"ImageCrop\": \"Image Crop\",\n    \"ImageStitch\": \"Image Stitch\",\n    \"ImageBlend\": \"Image Blend\",\n    \"ImageBlur\": \"Image Blur\",\n    \"ImageQuantize\": \"Image Quantize\",\n    \"ImageSharpen\": \"Image Sharpen\",\n    \"ImageScaleToTotalPixels\": \"Scale Image to Total Pixels\",\n    \"GetImageSize\": \"Get Image Size\",\n    # _for_testing\n    \"VAEDecodeTiled\": \"VAE Decode (Tiled)\",\n    \"VAEEncodeTiled\": \"VAE Encode (Tiled)\",\n}\n\nif args.fast_load:\n    NODE_CLASS_MAPPINGS = {}\n    NODE_DISPLAY_NAME_MAPPINGS = {}\n\nEXTENSION_WEB_DIRS = {}\n\n# Dictionary of successfully loaded module names and associated directories.\nLOADED_MODULE_DIRS = {}\n\n\ndef get_module_name(module_path: str) -> str:\n    \"\"\"\n    Returns the module name based on the given module path.\n    Examples:\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__.py\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node/__init__/\") -> \"my_custom_node\"\n        get_module_name(\"C:/Users/username/ComfyUI/custom_nodes/my_custom_node.disabled\") -> \"custom_nodes\n    Args:\n        module_path (str): The path of the module.\n    Returns:\n        str: The module name.\n    \"\"\"\n    base_path = os.path.basename(module_path)\n    if os.path.isfile(module_path):\n        base_path = os.path.splitext(base_path)[0]\n    return base_path\n\n\nasync def load_custom_node(module_path: str, ignore=set(), module_parent=\"custom_nodes\") -> bool:\n    module_name = get_module_name(module_path)\n    if os.path.isfile(module_path):\n        sp = os.path.splitext(module_path)\n        module_name = sp[0]\n        sys_module_name = module_name\n    elif os.path.isdir(module_path):\n        sys_module_name = module_path.replace(\".\", \"_x_\")\n\n    try:\n        logging.debug(\"Trying to load custom node {}\".format(module_path))\n        if os.path.isfile(module_path):\n            module_spec = importlib.util.spec_from_file_location(sys_module_name, module_path)\n            module_dir = os.path.split(module_path)[0]\n        else:\n            module_spec = importlib.util.spec_from_file_location(sys_module_name, os.path.join(module_path, \"__init__.py\"))\n            module_dir = module_path\n\n        module = importlib.util.module_from_spec(module_spec)\n        sys.modules[sys_module_name] = module\n        module_spec.loader.exec_module(module)\n\n        LOADED_MODULE_DIRS[module_name] = os.path.abspath(module_dir)\n\n        try:\n            from comfy_config import config_parser\n\n            project_config = config_parser.extract_node_configuration(module_path)\n\n            web_dir_name = project_config.tool_comfy.web\n\n            if web_dir_name:\n                web_dir_path = os.path.join(module_path, web_dir_name)\n\n                if os.path.isdir(web_dir_path):\n                    \n        except Exception as e:\n            logging.warning(f\"Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': {e}\")\n\n        if hasattr(module, \"WEB_DIRECTORY\") and getattr(module, \"WEB_DIRECTORY\") is not None:\n            web_dir = os.path.abspath(os.path.join(module_dir, getattr(module, \"WEB_DIRECTORY\")))\n            if os.path.isdir(web_dir):\n                EXTENSION_WEB_DIRS[module_name] = web_dir\n\n        # V1 node definition\n        if hasattr(module, \"NODE_CLASS_MAPPINGS\") and getattr(module, \"NODE_CLASS_MAPPINGS\") is not None:\n            for name, node_cls in module.NODE_CLASS_MAPPINGS.items():\n                if name not in ignore:\n                    \n            if hasattr(module, \"NODE_DISPLAY_NAME_MAPPINGS\") and getattr(module, \"NODE_DISPLAY_NAME_MAPPINGS\") is not None:\n                NODE_DISPLAY_NAME_MAPPINGS.update(module.NODE_DISPLAY_NAME_MAPPINGS)\n            return True\n        # V3 Extension Definition\n        elif hasattr(module, \"comfy_entrypoint\"):\n            entrypoint = getattr(module, \"comfy_entrypoint\")\n            if not callable(entrypoint):\n                logging.warning(f\"comfy_entrypoint in {module_path} is not callable, skipping.\")\n                return False\n            try:\n                if inspect.iscoroutinefunction(entrypoint):\n                    /* Line 2201 omitted */\n                else:\n                    /* Line 2203 omitted */\n                if not isinstance(extension, ComfyExtension):\n                    /* Lines 2205-2206 omitted */\n                node_list = await extension.get_node_list()\n                if not isinstance(node_list, list):\n                    /* Lines 2209-2210 omitted */\n                for node_cls in node_list:\n                    /* Lines 2212-2218 omitted */\n                return True\n            except Exception as e:\n                logging.warning(f\"Error while calling comfy_entrypoint in {module_path}: {e}\")\n                return False\n        else:\n            logging.warning(f\"Skip {module_path} module for custom nodes due to the lack of NODE_CLASS_MAPPINGS or NODES_LIST (need one).\")\n            return False\n    except Exception as e:\n        logging.warning(traceback.format_exc())\n        logging.warning(f\"Cannot import {module_path} module for custom nodes: {e}\")\n        return False\n\nasync def init_external_custom_nodes():\n    \"\"\"\n    Initializes the external custom nodes.\n\n    This function loads custom nodes from the specified folder paths and imports them into the application.\n    It measures the import times for each custom node and logs the results.\n\n    Returns:\n        None\n    \"\"\"\n    base_node_names = set(NODE_CLASS_MAPPINGS.keys())\n    node_paths = folder_paths.get_folder_paths(\"custom_nodes\")\n    node_import_times = []\n    for custom_node_path in node_paths:\n        possible_modules = os.listdir(os.path.realpath(custom_node_path))\n        if \"__pycache__\" in possible_modules:\n            possible_modules.remove(\"__pycache__\")\n\n        for possible_module in possible_modules:\n            module_path = os.path.join(custom_node_path, possible_module)\n            if os.path.isfile(module_path) and os.path.splitext(module_path)[1] != \".py\": continue\n            if module_path.endswith(\".disabled\"): continue\n            if args.disable_all_custom_nodes and possible_module not in args.whitelist_custom_nodes:\n                logging.info(f\"Skipping {possible_module} due to disable_all_custom_nodes and whitelist_custom_nodes\")\n                continue\n            time_before = time.perf_counter()\n            success = await load_custom_node(module_path, base_node_names, module_parent=\"custom_nodes\")\n            node_import_times.append((time.perf_counter() - time_before, module_path, success))\n\n    if len(node_import_times) > 0:\n        logging.info(\"\\nImport times for custom nodes:\")\n        for n in sorted(node_import_times):\n            if n[2]:\n                import_message = \"\"\n            else:\n                import_message = \" (IMPORT FAILED)\"\n            logging.info(\"{:6.1f} seconds{}: {}\".format(n[0], import_message, n[1]))\n        logging.info(\"\")\n\nasync def init_builtin_extra_nodes():\n    \"\"\"\n    Initializes the built-in extra nodes in ComfyUI.\n\n    This function loads the extra node files located in the \"comfy_extras\" directory and imports them into ComfyUI.\n    If any of the extra node files fail to import, a warning message is logged.\n\n    Returns:\n        None\n    \"\"\"\n    extras_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_extras\")\n    extras_files = [\n        \"nodes_latent.py\",\n        \"nodes_hypernetwork.py\",\n        \"nodes_upscale_model.py\",\n        \"nodes_post_processing.py\",\n        \"nodes_mask.py\",\n        \"nodes_compositing.py\",\n        \"nodes_rebatch.py\",\n        \"nodes_model_merging.py\",\n        \"nodes_tomesd.py\",\n        \"nodes_clip_sdxl.py\",\n        \"nodes_canny.py\",\n        \"nodes_freelunch.py\",\n        \"nodes_custom_sampler.py\",\n        \"nodes_hypertile.py\",\n        \"nodes_model_advanced.py\",\n        \"nodes_model_downscale.py\",\n        \"nodes_images.py\",\n        \"nodes_video_model.py\",\n        \"nodes_train.py\",\n        \"nodes_sag.py\",\n        \"nodes_perpneg.py\",\n        \"nodes_stable3d.py\",\n        \"nodes_sdupscale.py\",\n        \"nodes_photomaker.py\",\n        \"nodes_pixart.py\",\n        \"nodes_cond.py\",\n        \"nodes_morphology.py\",\n        \"nodes_stable_cascade.py\",\n        \"nodes_differential_diffusion.py\",\n        \"nodes_ip2p.py\",\n        \"nodes_model_merging_model_specific.py\",\n        \"nodes_pag.py\",\n        \"nodes_align_your_steps.py\",\n        \"nodes_attention_multiply.py\",\n        \"nodes_advanced_samplers.py\",\n        \"nodes_webcam.py\",\n        \"nodes_audio.py\",\n        \"nodes_sd3.py\",\n        \"nodes_gits.py\",\n        \"nodes_controlnet.py\",\n        \"nodes_hunyuan.py\",\n        \"nodes_eps.py\",\n        \"nodes_flux.py\",\n        \"nodes_lora_extract.py\",\n        \"nodes_torch_compile.py\",\n        \"nodes_mochi.py\",\n        \"nodes_slg.py\",\n        \"nodes_mahiro.py\",\n        \"nodes_lt.py\",\n        \"nodes_hooks.py\",\n        \"nodes_load_3d.py\",\n        \"nodes_cosmos.py\",\n        \"nodes_video.py\",\n        \"nodes_lumina2.py\",\n        \"nodes_wan.py\",\n        \"nodes_lotus.py\",\n        \"nodes_hunyuan3d.py\",\n        \"nodes_primitive.py\",\n        \"nodes_cfg.py\",\n        \"nodes_optimalsteps.py\",\n        \"nodes_hidream.py\",\n        \"nodes_fresca.py\",\n        \"nodes_apg.py\",\n        \"nodes_preview_any.py\",\n        \"nodes_ace.py\",\n        \"nodes_string.py\",\n        \"nodes_camera_trajectory.py\",\n        \"nodes_edit_model.py\",\n        \"nodes_tcfg.py\",\n        \"nodes_context_windows.py\",\n        \"nodes_qwen.py\",\n        \"nodes_chroma_radiance.py\",\n        \"nodes_model_patch.py\",\n        \"nodes_easycache.py\",\n        \"nodes_audio_encoder.py\",\n        \"nodes_rope.py\",\n        \"nodes_nop.py\",\n    ]\n\n    import_failed = []\n    for node_file in extras_files:\n        if not await load_custom_node(os.path.join(extras_dir, node_file), module_parent=\"comfy_extras\"):\n            import_failed.append(node_file)\n\n    return import_failed\n\n\nasync def init_builtin_api_nodes():\n    api_nodes_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"comfy_api_nodes\")\n    api_nodes_files = [\n        \"nodes_ideogram.py\",\n        \"nodes_openai.py\",\n        \"nodes_minimax.py\",\n        \"nodes_veo2.py\",\n        \"nodes_kling.py\",\n        \"nodes_bfl.py\",\n        \"nodes_bytedance.py\",\n        \"nodes_ltxv.py\",\n        \"nodes_luma.py\",\n        \"nodes_recraft.py\",\n        \"nodes_pixverse.py\",\n        \"nodes_stability.py\",\n        \"nodes_pika.py\",\n        \"nodes_runway.py\",\n        \"nodes_sora.py\",\n        \"nodes_topaz.py\",\n        \"nodes_tripo.py\",\n        \"nodes_moonvalley.py\",\n        \"nodes_rodin.py\",\n        \"nodes_gemini.py\",\n        \"nodes_vidu.py\",\n        \"nodes_wan.py\",\n    ]\n\n    if not await load_custom_node(os.path.join(api_nodes_dir, \"canary.py\"), module_parent=\"comfy_api_nodes\"):\n        return api_nodes_files\n\n    import_failed = []\n    for node_file in api_nodes_files:\n        if not await load_custom_node(os.path.join(api_nodes_dir, node_file), module_parent=\"comfy_api_nodes\"):\n            import_failed.append(node_file)\n\n    return import_failed\n\nasync def init_public_apis():\n    register_versions([\n        ComfyAPIWithVersion(\n            version=getattr(v, \"VERSION\"),\n            api_class=v\n        ) for v in supported_versions\n    ])\n\nasync def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n    await init_public_apis()\n\n    import_failed = await init_builtin_extra_nodes()\n\n    import_failed_api = []\n    if init_api_nodes:\n        import_failed_api = await init_builtin_api_nodes()\n\n    if init_custom_nodes:\n        await init_external_custom_nodes()\n    else:\n        logging.info(\"Skipping loading of custom nodes\")\n\n    if len(import_failed_api) > 0:\n        logging.warning(\"WARNING: some comfy_api_nodes/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed_api:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    if len(import_failed) > 0:\n        logging.warning(\"WARNING: some comfy_extras/ nodes did not import correctly. This may be because they are missing some dependencies.\\n\")\n        for node in import_failed:\n            logging.warning(\"IMPORT FAILED: {}\".format(node))\n        logging.warning(\"\\nThis issue might be caused by new missing dependencies added the last time you updated ComfyUI.\")\n        if args.windows_standalone_build:\n            logging.warning(\"Please run the update script: update/update_comfyui.bat\")\n        else:\n            logging.warning(\"Please do a: pip install -r requirements.txt\")\n        logging.warning(\"\")\n\n    return import_failed\n</attachment>\n\n</attachments>\n<context>\nThe current date is 2025ë…„ 12ì›” 16ì¼.\nTerminals:\nTerminal: bash\nTerminal: bash\nLast Command: ll\nCwd: C:/Workbench/20_Projects/hvppycoding_ComfyUI\nExit Code: 0\nTerminal: bash\nLast Command: ll\nCwd: C:/Workbench/20_Projects/hvppycoding_ComfyUI\nExit Code: 0\n\n</context>\n<editorContext>\nThe user's current file is chat-editing-snapshot-text-model:/c%3A/Workbench/20_Projects/hvppycoding_ComfyUI/nodes.py?%7B%22session%22%3A%7B%22%24mid%22%3A1%2C%22external%22%3A%22vscode-chat-session%3A%2F%2Flocal%2FNjFmYWIwMWItZjdjNi00ZjBmLWI4YjQtMGY2MWU1NjZiNGQ5%22%2C%22path%22%3A%22%2FNjFmYWIwMWItZjdjNi00ZjBmLWI4YjQtMGY2MWU1NjZiNGQ5%22%2C%22scheme%22%3A%22vscode-chat-session%22%2C%22authority%22%3A%22local%22%7D%2C%22requestId%22%3A%22request_c6a4ef61-7b95-49ed-b77b-69b27346af0e%22%2C%22undoStop%22%3A%22__epoch_92%22%7D. The current selection is from line 2362 to line 2362.\n</editorContext>\n<reminderInstructions>\nYou are an agentâ€”keep going until the user's query is completely resolved before ending your turn. ONLY stop if solved or genuinely blocked.\nTake action when possible; the user expects you to do useful work without unnecessary questions.\nAfter any parallel, read-only context gathering, give a concise progress update and what's next.\nAvoid repetition across turns: don't restate unchanged plans or sections (like the todo list) verbatim; provide delta updates or only the parts that changed.\nTool batches: You MUST preface each batch with a one-sentence why/what/outcome preamble.\nProgress cadence: After 3 to 5 tool calls, or when you create/edit > ~3 files in a burst, report progress.\nRequirements coverage: Read the user's ask in full and think carefully. Do not omit a requirement. If something cannot be done with available tools, note why briefly and propose a viable alternative.\nWhen using the replace_string_in_file tool, include 3-5 lines of unchanged code before and after the string you want to replace, to make it unambiguous which part of the file should be edited.\nFor maximum efficiency, whenever you plan to perform multiple independent edit operations, invoke them simultaneously using multi_replace_string_in_file tool rather than sequentially. This will greatly improve user's cost and time efficiency leading to a better user experience. Do not announce which tool you're using (for example, avoid saying \"I'll implement all the changes using multi_replace_string_in_file\").\nSkip filler acknowledgements like \"Sounds good\" or \"Okay, I willâ€¦\". Open with a purposeful one-liner about what you're doing next.\nWhen sharing setup or run steps, present terminal commands in fenced code blocks with the correct language tag. Keep commands copyable and on separate lines.\nAvoid definitive claims about the build or runtime setup unless verified from the provided context (or quick tool checks). If uncertain, state what's known from attachments and proceed with minimal steps you can adapt later.\nWhen you create or edit runnable code, run a test yourself to confirm it works; then share optional fenced commands for more advanced runs.\nFor non-trivial code generation, produce a complete, runnable solution: necessary source files, a tiny runner or test/benchmark harness, a minimal `README.md`, and updated dependency manifests (e.g., `package.json`, `requirements.txt`, `pyproject.toml`). Offer quick \"try it\" commands and optional platform-specific speed-ups when relevant.\nYour goal is to act like a pair programmer: be friendly and helpful. If you can do more, do more. Be proactive with your solutions, think about what the user needs and what they want, and implement it proactively.\n<importantReminders>\nDo NOT volunteer your model name unless the user explicitly asks you about it. \nYou MUST use the todo list tool to plan and track your progress. NEVER skip this step, and START with this step whenever the task is multi-step. This is essential for maintaining visibility and proper execution of large tasks.\nWhen referring to a filename or symbol in the user's workspace, wrap it in backticks.\n\n</importantReminders>\n\n</reminderInstructions>\n<userRequest>\nì•„ì§ë„ í•„ìš”ì—†ëŠ” ë…¸ë“œë“¤ì´ ë§Žì´ ìžˆì–´. ë‚˜ëŠ” ê¸°ë³¸ ë…¸ë“œë“¤(String ê´€ë ¨ ë“±) ì œì™¸í•˜ê³  ë‹¤ ë¡œë“œê°€ ì•ˆë˜ë©´ ì¢‹ê² ì–´. (See <attachments> above for file contents. You may not need to search or read the file again.)\n</userRequest>\n\n\n[copilot_cache_control: { type: 'ephemeral' }]\nResponse\nAssistant\në‹¤ìŒìœ¼ë¡œ `nodes.py`ì— ì„¸ ê°€ì§€ ë³€ê²½ì„ ì ìš©í•˜ê² ìŠµë‹ˆë‹¤: (1) `--fast-load`ì¼ ë•Œ í•µì‹¬ ì½”ì–´ ë…¸ë“œë§Œ ë‚¨ê¸°ê¸°, (2) `--fast-load`ì¼ ë•Œ `comfy_extras` ëª©ë¡ì„ í•„í„°ë§, (3) `--fast-load`ì¼ ë•Œ API ë…¸ë“œ ë¡œë“œë¥¼ ê±´ë„ˆë›°ê²Œ í•˜ê¸°. ë³€ê²½ í›„ ë¹ ë¥¸ ë¡œë“œ ë™ìž‘ì„ ë¡œê¹…í•©ë‹ˆë‹¤.\nðŸ› ï¸ multi_replace_string_in_file (call_gg3ALQJC1HOfLgK4Hwnbi3e5) {\n  \"explanation\": \"Keep a minimal set of core nodes for fast-load, filter extras files list when fast-load, and disable API nodes when fast-load.\",\n  \"replacements\": [\n    {\n      \"explanation\": \"Replace the tiny fast_load reset with a curated whitelist mapping and update display names.\",\n      \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\",\n      \"oldString\": \"if args.fast_load:\n    NODE_CLASS_MAPPINGS = {}\n    NODE_DISPLAY_NAME_MAPPINGS = {}\n\nEXTENSION_WEB_DIRS = {}\n\",\n      \"newString\": \"if args.fast_load:\n    # Minimal core nodes allowed during fast-load (lightweight, no heavy model ops)\n    NODE_CLASS_MAPPINGS = {\n        \\\"SaveImage\\\": SaveImage,\n        \\\"PreviewImage\\\": PreviewImage,\n        \\\"LoadImage\\\": LoadImage,\n        \\\"LoadImageMask\\\": LoadImageMask,\n        \\\"LoadImageOutput\\\": LoadImageOutput,\n        \\\"ImageScale\\\": ImageScale,\n        \\\"ImageScaleBy\\\": ImageScaleBy,\n        \\\"ImageInvert\\\": ImageInvert,\n        \\\"ImageBatch\\\": ImageBatch,\n        \\\"EmptyImage\\\": EmptyImage,\n    }\n    # Keep only display names for the whitelist\n    NODE_DISPLAY_NAME_MAPPINGS = {k: NODE_DISPLAY_NAME_MAPPINGS.get(k, k) for k in NODE_CLASS_MAPPINGS.keys()}\n\n    logging.info(\\\"Fast-load enabled: loading minimal core nodes only\\\")\n\nEXTENSION_WEB_DIRS = {}\n\"\n    },\n    {\n      \"explanation\": \"When fast-load is active, only keep a very small set of comfy_extras files (string, nop, images) to speed startup.\",\n      \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\",\n      \"oldString\": \"    extras_files = [\n        \\\"nodes_latent.py\\\",\n        \\\"nodes_hypernetwork.py\\\",\n        \\\"nodes_upscale_model.py\\\",\n        \\\"nodes_post_processing.py\\\",\n        \\\"nodes_mask.py\\\",\n        \\\"nodes_compositing.py\\\",\n        \\\"nodes_rebatch.py\\\",\n        \\\"nodes_model_merging.py\\\",\n        \\\"nodes_tomesd.py\\\",\n        \\\"nodes_clip_sdxl.py\\\",\n        \\\"nodes_canny.py\\\",\n        \\\"nodes_freelunch.py\\\",\n        \\\"nodes_custom_sampler.py\\\",\n        \\\"nodes_hypertile.py\\\",\n        \\\"nodes_model_advanced.py\\\",\n        \\\"nodes_model_downscale.py\\\",\n        \\\"nodes_images.py\\\",\n        \\\"nodes_video_model.py\\\",\n        \\\"nodes_train.py\\\",\n        \\\"nodes_sag.py\\\",\n        \\\"nodes_perpneg.py\\\",\n        \\\"nodes_stable3d.py\\\",\n        \\\"nodes_sdupscale.py\\\",\n        \\\"nodes_photomaker.py\\\",\n        \\\"nodes_pixart.py\\\",\n        \\\"nodes_cond.py\\\",\n        \\\"nodes_morphology.py\\\",\n        \\\"nodes_stable_cascade.py\\\",\n        \\\"nodes_differential_diffusion.py\\\",\n        \\\"nodes_ip2p.py\\\",\n        \\\"nodes_model_merging_model_specific.py\\\",\n        \\\"nodes_pag.py\\\",\n        \\\"nodes_align_your_steps.py\\\",\n        \\\"nodes_attention_multiply.py\\\",\n        \\\"nodes_advanced_samplers.py\\\",\n        \\\"nodes_webcam.py\\\",\n        \\\"nodes_audio.py\\\",\n        \\\"nodes_sd3.py\\\",\n        \\\"nodes_gits.py\\\",\n        \\\"nodes_controlnet.py\\\",\n        \\\"nodes_hunyuan.py\\\",\n        \\\"nodes_eps.py\\\",\n        \\\"nodes_flux.py\\\",\n        \\\"nodes_lora_extract.py\\\",\n        \\\"nodes_torch_compile.py\\\",\n        \\\"nodes_mochi.py\\\",\n        \\\"nodes_slg.py\\\",\n        \\\"nodes_mahiro.py\\\",\n        \\\"nodes_lt.py\\\",\n        \\\"nodes_hooks.py\\\",\n        \\\"nodes_load_3d.py\\\",\n        \\\"nodes_cosmos.py\\\",\n        \\\"nodes_video.py\\\",\n        \\\"nodes_lumina2.py\\\",\n        \\\"nodes_wan.py\\\",\n        \\\"nodes_lotus.py\\\",\n        \\\"nodes_hunyuan3d.py\\\",\n        \\\"nodes_primitive.py\\\",\n        \\\"nodes_cfg.py\\\",\n        \\\"nodes_optimalsteps.py\\\",\n        \\\"nodes_hidream.py\\\",\n        \\\"nodes_fresca.py\\\",\n        \\\"nodes_apg.py\\\",\n        \\\"nodes_preview_any.py\\\",\n        \\\"nodes_ace.py\\\",\n        \\\"nodes_string.py\\\",\n        \\\"nodes_camera_trajectory.py\\\",\n        \\\"nodes_edit_model.py\\\",\n        \\\"nodes_tcfg.py\\\",\n        \\\"nodes_context_windows.py\\\",\n        \\\"nodes_qwen.py\\\",\n        \\\"nodes_chroma_radiance.py\\\",\n        \\\"nodes_model_patch.py\\\",\n        \\\"nodes_easycache.py\\\",\n        \\\"nodes_audio_encoder.py\\\",\n        \\\"nodes_rope.py\\\",\n        \\\"nodes_nop.py\\\",\n    ]\n\n    import_failed = []\n    for node_file in extras_files:\n        if not await load_custom_node(os.path.join(extras_dir, node_file), module_parent=\\\"comfy_extras\\\"):\n            import_failed.append(node_file)\n\",\n      \"newString\": \"    extras_files = [\n        \\\"nodes_latent.py\\\",\n        \\\"nodes_hypernetwork.py\\\",\n        \\\"nodes_upscale_model.py\\\",\n        \\\"nodes_post_processing.py\\\",\n        \\\"nodes_mask.py\\\",\n        \\\"nodes_compositing.py\\\",\n        \\\"nodes_rebatch.py\\\",\n        \\\"nodes_model_merging.py\\\",\n        \\\"nodes_tomesd.py\\\",\n        \\\"nodes_clip_sdxl.py\\\",\n        \\\"nodes_canny.py\\\",\n        \\\"nodes_freelunch.py\\\",\n        \\\"nodes_custom_sampler.py\\\",\n        \\\"nodes_hypertile.py\\\",\n        \\\"nodes_model_advanced.py\\\",\n        \\\"nodes_model_downscale.py\\\",\n        \\\"nodes_images.py\\\",\n        \\\"nodes_video_model.py\\\",\n        \\\"nodes_train.py\\\",\n        \\\"nodes_sag.py\\\",\n        \\\"nodes_perpneg.py\\\",\n        \\\"nodes_stable3d.py\\\",\n        \\\"nodes_sdupscale.py\\\",\n        \\\"nodes_photomaker.py\\\",\n        \\\"nodes_pixart.py\\\",\n        \\\"nodes_cond.py\\\",\n        \\\"nodes_morphology.py\\\",\n        \\\"nodes_stable_cascade.py\\\",\n        \\\"nodes_differential_diffusion.py\\\",\n        \\\"nodes_ip2p.py\\\",\n        \\\"nodes_model_merging_model_specific.py\\\",\n        \\\"nodes_pag.py\\\",\n        \\\"nodes_align_your_steps.py\\\",\n        \\\"nodes_attention_multiply.py\\\",\n        \\\"nodes_advanced_samplers.py\\\",\n        \\\"nodes_webcam.py\\\",\n        \\\"nodes_audio.py\\\",\n        \\\"nodes_sd3.py\\\",\n        \\\"nodes_gits.py\\\",\n        \\\"nodes_controlnet.py\\\",\n        \\\"nodes_hunyuan.py\\\",\n        \\\"nodes_eps.py\\\",\n        \\\"nodes_flux.py\\\",\n        \\\"nodes_lora_extract.py\\\",\n        \\\"nodes_torch_compile.py\\\",\n        \\\"nodes_mochi.py\\\",\n        \\\"nodes_slg.py\\\",\n        \\\"nodes_mahiro.py\\\",\n        \\\"nodes_lt.py\\\",\n        \\\"nodes_hooks.py\\\",\n        \\\"nodes_load_3d.py\\\",\n        \\\"nodes_cosmos.py\\\",\n        \\\"nodes_video.py\\\",\n        \\\"nodes_lumina2.py\\\",\n        \\\"nodes_wan.py\\\",\n        \\\"nodes_lotus.py\\\",\n        \\\"nodes_hunyuan3d.py\\\",\n        \\\"nodes_primitive.py\\\",\n        \\\"nodes_cfg.py\\\",\n        \\\"nodes_optimalsteps.py\\\",\n        \\\"nodes_hidream.py\\\",\n        \\\"nodes_fresca.py\\\",\n        \\\"nodes_apg.py\\\",\n        \\\"nodes_preview_any.py\\\",\n        \\\"nodes_ace.py\\\",\n        \\\"nodes_string.py\\\",\n        \\\"nodes_camera_trajectory.py\\\",\n        \\\"nodes_edit_model.py\\\",\n        \\\"nodes_tcfg.py\\\",\n        \\\"nodes_context_windows.py\\\",\n        \\\"nodes_qwen.py\\\",\n        \\\"nodes_chroma_radiance.py\\\",\n        \\\"nodes_model_patch.py\\\",\n        \\\"nodes_easycache.py\\\",\n        \\\"nodes_audio_encoder.py\\\",\n        \\\"nodes_rope.py\\\",\n        \\\"nodes_nop.py\\\",\n    ]\n\n    # If fast-load is enabled, only keep a tiny set of extras that are lightweight (string, nop, and basic images)\n    if args.fast_load:\n        allowed_extras = {\\\"nodes_string.py\\\", \\\"nodes_nop.py\\\", \\\"nodes_images.py\\\"}\n        extras_files = [f for f in extras_files if f in allowed_extras]\n        logging.info(f\\\"Fast-load enabled: filtered comfy_extras to: {extras_files}\\\")\n\n    import_failed = []\n    for node_file in extras_files:\n        if not await load_custom_node(os.path.join(extras_dir, node_file), module_parent=\\\"comfy_extras\\\"):\n            import_failed.append(node_file)\n\"\n    },\n    {\n      \"explanation\": \"When fast-load is active, skip API nodes entirely (faster startup).\",\n      \"filePath\": \"c:\\\\Workbench\\\\20_Projects\\\\hvppycoding_ComfyUI\\\\nodes.py\",\n      \"oldString\": \"async def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n    await init_public_apis()\n\",\n      \"newString\": \"async def init_extra_nodes(init_custom_nodes=True, init_api_nodes=True):\n    # Fast-load should avoid initializing heavier API nodes\n    if args.fast_load:\n        init_api_nodes = False\n    await init_public_apis()\n\"\n    }\n  ]\n}\n"
}